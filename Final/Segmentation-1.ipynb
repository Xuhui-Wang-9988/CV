{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Semantic Segmentation Competition (40%)**\n",
        "\n",
        "For this competition, we will use a small autonomous driving dataset. The dataset contains 150 training images and 50 testing images. It can be download from https://drive.google.com/drive/folders/1UyGysAa9S7Jw-BRgouwNoSNgIZqEx7EX?usp=sharing or https://cloudstor.aarnet.edu.au/plus/s/qtk9MB74r0q1cVh\n",
        "\n",
        "We provide a baseline by the following steps:\n",
        "\n",
        "*    Loading the dataset using PyTorch.\n",
        "*    Defining a simple convolutional neural network for semantic segmentation.\n",
        "*    How to use existing loss function for the model learning.\n",
        "*    Train the network on the training data.\n",
        "*    Test the trained network on the testing data.\n",
        "\n",
        "The following trick/tweak(s) could be considered:\n",
        "-------\n",
        "1. Data augmentation\n",
        "2. Change of advanced training parameters: Learning Rate, Optimizer, Batch-size, and Drop-out. \n",
        "3. Architectural changes: Batch Normalization, Residual layers, Attention Block, and other varients.\n",
        "4. Use of a new loss function.\n",
        "\n",
        "Your code should be modified from the provided baseline. A pdf report is required to explain the tricks you employed, and the imporvements they achieved.\n",
        "Marking Rules:\n",
        "-------\n",
        "We will mark the competition based on the final test accuracy on testing images and your report.\n",
        "\n",
        "Final mark = acc_mark + efficiency mark + report mark + bonus mark\n",
        "###Acc_mark 15:\n",
        "\n",
        "We will rank all the submission results based on their test accuracy. The top 30% of the students will get full marks.\n",
        "\n",
        "\n",
        "|Accuracy|Mark|\n",
        "|---|---|\n",
        "| Top 30% in the class|          15|\n",
        "|30%-50%|         11|\n",
        "|50%-80%  |        7|\n",
        "| 80%-90%  |      3|\n",
        "| 90%-100%  |      1|\n",
        "|Not implemented| 0|\n",
        "\n",
        "###Efficiency mark 5:\n",
        "\n",
        "Efficiency is evaluated by the computational costs (flops: https://en.wikipedia.org/wiki/FLOPS). Please report the computational costs for your final model. We provide an evaluation code to calculate flops. \n",
        "\n",
        "|Efficiency|Mark|\n",
        "|---|---|\n",
        "| Top 30% in the class|          5|\n",
        "|30%-50%|         4|\n",
        "|50%-80%  |        3|\n",
        "| 80%-90%  |      2|\n",
        "| 90%-100%  |      2|\n",
        "|Not implemented| 0|\n",
        "\n",
        "###Report mark 20:\n",
        "1. Introduction and your understanding to the baseline model: 2 points\n",
        "\n",
        "2. Employed more than three tricks with ablation studies to improve the accuracy: 6 points\n",
        "\n",
        "Clearly explain the reference, motivation and design choice for each trick/tweak(s). Providing the experimental results in tables.\n",
        "Example table:\n",
        "\n",
        "|Trick1|Trick2|Trick3|Accuracy|\n",
        "|---|---|---|---|\n",
        "|N|N|N|60%|\n",
        "|Y|N|N|65%|\n",
        "|Y|Y|N|77%|\n",
        "|Y|Y|Y|82%|\n",
        "\n",
        "Observation and discussion based on the experiment results.\n",
        "\n",
        "3. Expaination of the methods on reducing the computational cost and/or improve the trade-off between accuracy and efficiency: 4 points\n",
        "\n",
        "4. Explaination of the code implementationï¼š3 points\n",
        "\n",
        "5. Visulization results: segmentation examples (color images) on test set: 3 points\n",
        "\n",
        "6. Open ended:  Limitations, conclusions, failure cases analysis...: 2 points\n",
        "\n",
        "###Bonus mark:\n",
        "1. Top three results: 2 points\n",
        "2. Fancy designs: 2 points"
      ],
      "metadata": {
        "id": "bVgOlzfMdiHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Download data and set configs"
      ],
      "metadata": {
        "id": "B0dtUDczT_fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################################################################################################\n",
        "### Subject: Computer Vision \n",
        "### Year: 2022\n",
        "### Student Name: ABC, XYZ\n",
        "### Student ID: a123456, a654321\n",
        "### Comptetion Name: Semantic Segmentation Competition\n",
        "### Final Results:\n",
        "### ACC:         FLOPs:\n",
        "##################################################################################################################################"
      ],
      "metadata": {
        "id": "XCPZsWI_9s-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1.1 Download the dataset.\n",
        "!wget https://cloudstor.aarnet.edu.au/plus/s/qtk9MB74r0q1cVh/download\n",
        "!unzip download \n",
        "!rm -rf download"
      ],
      "metadata": {
        "id": "xHPzdgeP67Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1.2 Set configs\n",
        "#Use Colab or install PyTorch 1.9 on your local machine to run the code.\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision.models.segmentation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as tf\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "#--------Data path----------\n",
        "# Use your data path to replace the following path if you use Google drive.\n",
        "dataFolder = './seg_data'\n",
        "\n",
        "# To access Google Colab GPU; Go To: Edit >>> Notebook Settings >>> Hardware Accelarator: Select GPU. \n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') \n",
        "print('device: {}'.format(device))\n",
        "\n",
        "#---------Config----------\n",
        "learning_rate = 3e-4 #Tips: design a strategy to adjust the learning rate\n",
        "width = 864 # image width and height\n",
        "height = 256 #\n",
        "batchSize = 4 #can be adjusted\n",
        "epochs = 180 #can be adjusted\n",
        "\n",
        "if not os.path.exists(dataFolder):\n",
        "   print('Data Path Error! Pls check your data path') \n",
        "if not torch.cuda.is_available():\n",
        "  print('WARNING! The device is CPU NOT GPU! Pls avoid using CPU for training')"
      ],
      "metadata": {
        "id": "106OzI7yUPON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43cfdec-41d7-428c-b8d6-a01b8ebc8d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Define a dataloader to load data"
      ],
      "metadata": {
        "id": "iM0C-LdtUThm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The class to load images and labels\n",
        "class ExpDataSet(Dataset):\n",
        "    def __init__(self, dataFolder):\n",
        "        self.image_path = os.listdir(os.path.join(dataFolder, \"training/image\"))\n",
        "        self.label_path = os.listdir(os.path.join(dataFolder, \"training/image\"))#Image name only\n",
        "        print('load info for {} images'.format(len(self.image_path)))\n",
        "        assert len(self.image_path) == 150\n",
        "        for idx in range(0, len(self.image_path)):\n",
        "            assert self.image_path[idx] == self.label_path[idx] #same\n",
        "            self.image_path[idx] = os.path.join(dataFolder, \"training/image\", self.image_path[idx])\n",
        "            self.label_path[idx] = os.path.join(dataFolder, \"training/label\", self.label_path[idx])\n",
        "        # --------------------Transformation functions----------------\n",
        "        #-------------Tips: data augmentation can be used (for example flip, resize)-------------\n",
        "        self.transformImg = tf.Compose([tf.ToPILImage(), tf.Resize((height, width)), tf.ToTensor(),\n",
        "                                   tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "        self.transformLabel = tf.Compose([tf.ToPILImage(), tf.Resize((height, width), tf.InterpolationMode.NEAREST)])\n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.image_path[idx])[:, :, 0:3]\n",
        "        label = cv2.imread(self.label_path[idx], 0)\n",
        "        img = self.transformImg(img)  #3*H*W\n",
        "        label = self.transformLabel(label)\n",
        "        label = torch.tensor(np.array(label))  #H*W\n",
        "        return img, label\n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "\n",
        "#Get the predefined dataloader\n",
        "exp_data = ExpDataSet(dataFolder)  \n",
        "train_loader = DataLoader(exp_data, batch_size=batchSize, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "_5dna2XkVHIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fb4133-b564-4558-d21f-7ce2e72b0aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load info for 150 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Define a convolutional neural network"
      ],
      "metadata": {
        "id": "pwfMTxpbVVSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the semantic segmentation network. Tips: a new network can be used\n",
        "class SegNetwork(nn.Module):\n",
        "    def __init__(self, n_class=19):\n",
        "        super(SegNetwork, self).__init__()\n",
        "        #stage 1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  #1/2\n",
        "        #stage 2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  #1/4\n",
        "        #stage 3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  #1/8\n",
        "        #stage 4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  #1/16\n",
        "        #stage 5\n",
        "        self.conv5_1 = nn.Conv2d(512, 2048, 3)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.drop5_1 = nn.Dropout2d()\n",
        "        self.conv5_2 = nn.Conv2d(2048, 2048, 1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.drop5_2 = nn.Dropout2d()\n",
        "        self.conv5_3 = nn.Conv2d(2048, n_class, 1)\n",
        "        #upsample\n",
        "        self.upsample_cov1 = nn.ConvTranspose2d(n_class, n_class, 4, stride=2, output_padding=1, bias=False) #upsample\n",
        "        self.upsample_cov2 = nn.ConvTranspose2d(n_class, n_class, 4, stride=2, bias=False) #upsample  -> 1/4 \n",
        "        self.upsample_cov3 = nn.ConvTranspose2d(n_class, n_class, 4, stride=2, padding=1, bias=False)  # upsample  -> 1/2\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp_shape = x.shape[2:]\n",
        "        x = self.relu1_1(self.conv1_1(x))\n",
        "        x = self.relu1_2(self.conv1_2(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu2_1(self.conv2_1(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.relu3_1(self.conv3_1(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.relu4_1(self.conv4_1(x))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.relu5_1(self.conv5_1(x))\n",
        "        x = self.drop5_1(x)\n",
        "        x = self.relu5_2(self.conv5_2(x))\n",
        "        x = self.drop5_2(x)\n",
        "        x = self.conv5_3(x)\n",
        "\n",
        "        x = self.upsample_cov1(x)\n",
        "        x = self.upsample_cov2(x)\n",
        "        x = self.upsample_cov3(x)\n",
        "        x = F.interpolate(x, size=inp_shape, mode=\"bilinear\", align_corners=True)#resize (1/2 -> original size)\n",
        "        return x\n",
        "\n",
        "#Get the predefined network \n",
        "segNet = SegNetwork(n_class=19).to(device)"
      ],
      "metadata": {
        "id": "aX40GeSbVfOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Define a loss function and optimizer"
      ],
      "metadata": {
        "id": "PsuuIN00Wb-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "optimizer = torch.optim.Adam(params=segNet.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ubLuJmG7XXcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. The function used to compare the precision"
      ],
      "metadata": {
        "id": "RzUEUtY6aXMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------Modification of this function is ***NOT*** allowed---------------\n",
        "def cal_acc(pred_folder, gt_folder, classes=19):\n",
        "    class AverageMeter(object):\n",
        "        def __init__(self):\n",
        "            self.reset()\n",
        "        def reset(self):\n",
        "            self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
        "        def update(self, val, n=1):\n",
        "            self.val = val\n",
        "            self.sum += val * n\n",
        "            self.count += n\n",
        "            self.avg = self.sum / self.count\n",
        "    def intersectionAndUnion(output, target, K, ignore_index=255):\n",
        "        assert (output.ndim in [1, 2, 3])\n",
        "        assert output.shape == target.shape\n",
        "        output = output.reshape(output.size).copy()\n",
        "        target = target.reshape(target.size)\n",
        "        output[np.where(target == ignore_index)[0]] = ignore_index\n",
        "        intersection = output[np.where(output == target)[0]]\n",
        "        area_intersection, _ = np.histogram(intersection, bins=np.arange(K + 1))\n",
        "        area_output, _ = np.histogram(output, bins=np.arange(K + 1))\n",
        "        area_target, _ = np.histogram(target, bins=np.arange(K + 1))\n",
        "        area_union = area_output + area_target - area_intersection\n",
        "        return area_intersection, area_union, area_target\n",
        "    data_list = os.listdir(gt_folder)\n",
        "    intersection_meter = AverageMeter()\n",
        "    union_meter = AverageMeter()\n",
        "    target_meter = AverageMeter()\n",
        "    for i, image_name in enumerate(data_list):\n",
        "        pred = cv2.imread(os.path.join(pred_folder, image_name), cv2.IMREAD_GRAYSCALE)\n",
        "        target = cv2.imread(os.path.join(gt_folder, image_name), cv2.IMREAD_GRAYSCALE)\n",
        "        intersection, union, target = intersectionAndUnion(pred, target, classes)\n",
        "        intersection_meter.update(intersection)\n",
        "        union_meter.update(union)\n",
        "        target_meter.update(target)\n",
        "    iou_class = intersection_meter.sum / (union_meter.sum + 1e-10)\n",
        "    mIoU = np.mean(iou_class)\n",
        "    print('Eval result: mIoU {:.4f}.'.format(mIoU))\n",
        "    return mIoU"
      ],
      "metadata": {
        "id": "2rFg1PNNa3Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Define functions to get and save predictions"
      ],
      "metadata": {
        "id": "f2dRJ8TgboP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_folder(dir_name):#make a folder\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.makedirs(dir_name)\n",
        "\n",
        "def move_folders(grey_temp, color_temp, grey_rs, color_rs):#move folders\n",
        "    if os.path.exists(grey_temp):\n",
        "        make_folder(grey_rs)\n",
        "        for file in os.listdir(grey_temp):\n",
        "            shutil.move(os.path.join(grey_temp, file), os.path.join(grey_rs, file))\n",
        "        if os.path.exists(grey_temp):\n",
        "            shutil.rmtree(grey_temp)\n",
        "    if os.path.exists(color_temp):\n",
        "        make_folder(color_rs)\n",
        "        for file in os.listdir(color_temp):\n",
        "            shutil.move(os.path.join(color_temp, file), os.path.join(color_rs, file))\n",
        "        if os.path.exists(color_temp):\n",
        "            shutil.rmtree(color_temp)\n",
        "\n",
        "def colorize(gray, palette):#visualize predictions results\n",
        "    color = Image.fromarray(gray.astype(np.uint8)).convert('P')\n",
        "    color.putpalette(palette)\n",
        "    return color\n",
        "\n",
        "#-------Perform evaluation for a network and save prediction results--------\n",
        "def get_predictions(segNet, dataFolder, device):#params: a network, data path, device\n",
        "    gray_folder, color_folder = './temp_grey', './temp_color'\n",
        "    listImages, gt_folder = os.listdir(os.path.join(dataFolder, \"testing/image\")), os.path.join(dataFolder, \"testing/label\")\n",
        "    colors_path  = os.path.join(dataFolder, \"colors.txt\") #colors for visualizing greyscale images\n",
        "    print('Begin testing')\n",
        "    make_folder(gray_folder)\n",
        "    make_folder(color_folder)\n",
        "    colors = np.loadtxt(colors_path).astype('uint8')\n",
        "    #Tips: muti-scale testing can be used\n",
        "    transformTest = tf.Compose([tf.ToPILImage(), tf.ToTensor(),\n",
        "                                tf.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "    for idx in range(0, len(listImages)):\n",
        "        img = cv2.imread(os.path.join(dataFolder, \"testing/image\", listImages[idx]))[:, :, 0:3]\n",
        "        img = transformTest(img).unsqueeze(0)  #1*3*H*W\n",
        "        prediction = segNet(img.to(device))\n",
        "        prediction = prediction[0].cpu().detach().numpy()\n",
        "        prediction = np.argmax(prediction, axis=0)\n",
        "        gray = np.uint8(prediction)\n",
        "        color = colorize(gray, colors)\n",
        "        gray_path = os.path.join(gray_folder, listImages[idx])\n",
        "        color_path = os.path.join(color_folder, listImages[idx])\n",
        "        cv2.imwrite(gray_path, gray)\n",
        "        color.save(color_path)\n",
        "    return gray_folder, color_folder #return folders (paths) which contain grey and color predictions."
      ],
      "metadata": {
        "id": "dBcRAC2AhLzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Train the network"
      ],
      "metadata": {
        "id": "OqnC6C_YkqRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The training will take ~1 h.\n",
        "mIoU = 0.0\n",
        "evl_each = True #Perform evaluation after each epoch. You can define the false case to save training time\n",
        "for epoch in range(epochs):\n",
        "    for iter, (imgs, labels) in enumerate(train_loader):\n",
        "        pred = segNet(imgs.to(device))\n",
        "        segNet.zero_grad()\n",
        "        loss = criterion(pred, labels.long().to(device)) #calculate the loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print('epoch {} iter {} loss={}'.format(epoch, iter, loss.data.cpu().numpy()))\n",
        "\n",
        "#-----Evaluation------\n",
        "    if evl_each and epoch>100:\n",
        "        segNet.eval()  # The eval() must be called before evaluation\n",
        "        gray_folder, color_folder = get_predictions(segNet, dataFolder, device) #Temp prediction results\n",
        "        segNet.train()\n",
        "        temp_mIoU = cal_acc(gray_folder, os.path.join(dataFolder, 'testing/label'))\n",
        "        if temp_mIoU > mIoU:\n",
        "            mIoU = temp_mIoU\n",
        "            torch.save(segNet.state_dict(), './model.pth')\n",
        "            move_folders(gray_folder, color_folder, # Temp results -> final results\n",
        "                         gray_folder.replace('temp_', ''),\n",
        "                         color_folder.replace('temp_', ''))\n",
        "print('The final mIoU is : {:.4f}.'.format(mIoU)) #The final mIoU is ~0.28\n",
        "#Remember to download the results before closing the tab!"
      ],
      "metadata": {
        "id": "JvzZ3HxFkt_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e771ba52-bf60-4bbb-b445-d5f254f6a14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch 52 iter 23 loss=0.43363824486732483\n",
            "epoch 52 iter 24 loss=0.5822019577026367\n",
            "epoch 52 iter 25 loss=0.5462719798088074\n",
            "epoch 52 iter 26 loss=0.5618773698806763\n",
            "epoch 52 iter 27 loss=0.46810877323150635\n",
            "epoch 52 iter 28 loss=0.43067073822021484\n",
            "epoch 52 iter 29 loss=0.4322287142276764\n",
            "epoch 52 iter 30 loss=0.686794102191925\n",
            "epoch 52 iter 31 loss=0.7348836064338684\n",
            "epoch 52 iter 32 loss=0.5532694458961487\n",
            "epoch 52 iter 33 loss=0.4340226650238037\n",
            "epoch 52 iter 34 loss=0.49970123171806335\n",
            "epoch 52 iter 35 loss=0.5151299834251404\n",
            "epoch 52 iter 36 loss=0.8212190866470337\n",
            "epoch 52 iter 37 loss=0.371364951133728\n",
            "epoch 53 iter 0 loss=0.5545246005058289\n",
            "epoch 53 iter 1 loss=0.4457639455795288\n",
            "epoch 53 iter 2 loss=0.43548691272735596\n",
            "epoch 53 iter 3 loss=0.5912880301475525\n",
            "epoch 53 iter 4 loss=0.5345619916915894\n",
            "epoch 53 iter 5 loss=0.7613832354545593\n",
            "epoch 53 iter 6 loss=0.44521111249923706\n",
            "epoch 53 iter 7 loss=0.5437890291213989\n",
            "epoch 53 iter 8 loss=0.3827899992465973\n",
            "epoch 53 iter 9 loss=0.398563951253891\n",
            "epoch 53 iter 10 loss=0.4174002408981323\n",
            "epoch 53 iter 11 loss=0.5574278831481934\n",
            "epoch 53 iter 12 loss=0.5836997032165527\n",
            "epoch 53 iter 13 loss=0.45564019680023193\n",
            "epoch 53 iter 14 loss=0.477582186460495\n",
            "epoch 53 iter 15 loss=0.5824464559555054\n",
            "epoch 53 iter 16 loss=0.5523810386657715\n",
            "epoch 53 iter 17 loss=0.5238257050514221\n",
            "epoch 53 iter 18 loss=0.4727562367916107\n",
            "epoch 53 iter 19 loss=0.6408618688583374\n",
            "epoch 53 iter 20 loss=0.4622427523136139\n",
            "epoch 53 iter 21 loss=0.5558649301528931\n",
            "epoch 53 iter 22 loss=0.32487669587135315\n",
            "epoch 53 iter 23 loss=0.9053433537483215\n",
            "epoch 53 iter 24 loss=0.5843420028686523\n",
            "epoch 53 iter 25 loss=0.4623400568962097\n",
            "epoch 53 iter 26 loss=0.6883267760276794\n",
            "epoch 53 iter 27 loss=0.5702158212661743\n",
            "epoch 53 iter 28 loss=0.48932042717933655\n",
            "epoch 53 iter 29 loss=0.5329391360282898\n",
            "epoch 53 iter 30 loss=0.6286336779594421\n",
            "epoch 53 iter 31 loss=0.5430227518081665\n",
            "epoch 53 iter 32 loss=0.7820619940757751\n",
            "epoch 53 iter 33 loss=0.5630688667297363\n",
            "epoch 53 iter 34 loss=0.6055324673652649\n",
            "epoch 53 iter 35 loss=0.5561174154281616\n",
            "epoch 53 iter 36 loss=0.5339847207069397\n",
            "epoch 53 iter 37 loss=0.35205981135368347\n",
            "epoch 54 iter 0 loss=0.5070515275001526\n",
            "epoch 54 iter 1 loss=0.4779342710971832\n",
            "epoch 54 iter 2 loss=0.4928746819496155\n",
            "epoch 54 iter 3 loss=0.44532084465026855\n",
            "epoch 54 iter 4 loss=0.6277890205383301\n",
            "epoch 54 iter 5 loss=0.6469927430152893\n",
            "epoch 54 iter 6 loss=0.44431063532829285\n",
            "epoch 54 iter 7 loss=0.4460994303226471\n",
            "epoch 54 iter 8 loss=0.4482647180557251\n",
            "epoch 54 iter 9 loss=0.5712112784385681\n",
            "epoch 54 iter 10 loss=0.5537437200546265\n",
            "epoch 54 iter 11 loss=0.6008701324462891\n",
            "epoch 54 iter 12 loss=0.4342297613620758\n",
            "epoch 54 iter 13 loss=0.5819754600524902\n",
            "epoch 54 iter 14 loss=0.41921964287757874\n",
            "epoch 54 iter 15 loss=0.7025178670883179\n",
            "epoch 54 iter 16 loss=0.502224862575531\n",
            "epoch 54 iter 17 loss=0.41600102186203003\n",
            "epoch 54 iter 18 loss=0.5755569934844971\n",
            "epoch 54 iter 19 loss=0.5932586193084717\n",
            "epoch 54 iter 20 loss=0.5415096879005432\n",
            "epoch 54 iter 21 loss=0.6822173595428467\n",
            "epoch 54 iter 22 loss=0.48852792382240295\n",
            "epoch 54 iter 23 loss=0.6895565390586853\n",
            "epoch 54 iter 24 loss=0.5018165707588196\n",
            "epoch 54 iter 25 loss=0.5781665444374084\n",
            "epoch 54 iter 26 loss=0.5009372234344482\n",
            "epoch 54 iter 27 loss=0.7248592376708984\n",
            "epoch 54 iter 28 loss=0.44182053208351135\n",
            "epoch 54 iter 29 loss=0.5635390281677246\n",
            "epoch 54 iter 30 loss=0.5851085782051086\n",
            "epoch 54 iter 31 loss=0.6637002825737\n",
            "epoch 54 iter 32 loss=0.548302173614502\n",
            "epoch 54 iter 33 loss=0.5818859934806824\n",
            "epoch 54 iter 34 loss=0.4383966028690338\n",
            "epoch 54 iter 35 loss=0.5512769222259521\n",
            "epoch 54 iter 36 loss=0.45799463987350464\n",
            "epoch 54 iter 37 loss=0.48170262575149536\n",
            "epoch 55 iter 0 loss=0.5698304772377014\n",
            "epoch 55 iter 1 loss=0.4693586826324463\n",
            "epoch 55 iter 2 loss=0.6126860976219177\n",
            "epoch 55 iter 3 loss=0.42121168971061707\n",
            "epoch 55 iter 4 loss=0.5924472212791443\n",
            "epoch 55 iter 5 loss=0.5290687680244446\n",
            "epoch 55 iter 6 loss=0.4929793179035187\n",
            "epoch 55 iter 7 loss=0.6692094802856445\n",
            "epoch 55 iter 8 loss=0.4698121249675751\n",
            "epoch 55 iter 9 loss=0.49763068556785583\n",
            "epoch 55 iter 10 loss=0.5243070125579834\n",
            "epoch 55 iter 11 loss=0.4319196939468384\n",
            "epoch 55 iter 12 loss=0.6609786152839661\n",
            "epoch 55 iter 13 loss=0.47156739234924316\n",
            "epoch 55 iter 14 loss=0.4737665057182312\n",
            "epoch 55 iter 15 loss=0.4793880581855774\n",
            "epoch 55 iter 16 loss=0.4537116289138794\n",
            "epoch 55 iter 17 loss=0.41988813877105713\n",
            "epoch 55 iter 18 loss=0.5349118113517761\n",
            "epoch 55 iter 19 loss=0.5714017152786255\n",
            "epoch 55 iter 20 loss=0.48584839701652527\n",
            "epoch 55 iter 21 loss=0.5637890100479126\n",
            "epoch 55 iter 22 loss=0.5785545110702515\n",
            "epoch 55 iter 23 loss=0.38124915957450867\n",
            "epoch 55 iter 24 loss=0.34140393137931824\n",
            "epoch 55 iter 25 loss=0.5703668594360352\n",
            "epoch 55 iter 26 loss=0.660349428653717\n",
            "epoch 55 iter 27 loss=0.5464450716972351\n",
            "epoch 55 iter 28 loss=0.48783308267593384\n",
            "epoch 55 iter 29 loss=0.5150243043899536\n",
            "epoch 55 iter 30 loss=0.7781478762626648\n",
            "epoch 55 iter 31 loss=0.49688801169395447\n",
            "epoch 55 iter 32 loss=0.5914825797080994\n",
            "epoch 55 iter 33 loss=0.7149561047554016\n",
            "epoch 55 iter 34 loss=0.3744480311870575\n",
            "epoch 55 iter 35 loss=0.46149545907974243\n",
            "epoch 55 iter 36 loss=0.4811091423034668\n",
            "epoch 55 iter 37 loss=0.7499356865882874\n",
            "epoch 56 iter 0 loss=0.6798822283744812\n",
            "epoch 56 iter 1 loss=0.4496924877166748\n",
            "epoch 56 iter 2 loss=0.606806218624115\n",
            "epoch 56 iter 3 loss=0.4084893465042114\n",
            "epoch 56 iter 4 loss=0.4875498414039612\n",
            "epoch 56 iter 5 loss=0.6215248107910156\n",
            "epoch 56 iter 6 loss=0.37022343277931213\n",
            "epoch 56 iter 7 loss=0.40387454628944397\n",
            "epoch 56 iter 8 loss=0.438711941242218\n",
            "epoch 56 iter 9 loss=0.4394003450870514\n",
            "epoch 56 iter 10 loss=0.5889689326286316\n",
            "epoch 56 iter 11 loss=0.4913725256919861\n",
            "epoch 56 iter 12 loss=0.47452664375305176\n",
            "epoch 56 iter 13 loss=0.45148971676826477\n",
            "epoch 56 iter 14 loss=0.3775697648525238\n",
            "epoch 56 iter 15 loss=0.48628121614456177\n",
            "epoch 56 iter 16 loss=0.5354752540588379\n",
            "epoch 56 iter 17 loss=0.6059263944625854\n",
            "epoch 56 iter 18 loss=0.40207934379577637\n",
            "epoch 56 iter 19 loss=0.5929050445556641\n",
            "epoch 56 iter 20 loss=0.45257359743118286\n",
            "epoch 56 iter 21 loss=0.46319785714149475\n",
            "epoch 56 iter 22 loss=0.4377058744430542\n",
            "epoch 56 iter 23 loss=0.30039480328559875\n",
            "epoch 56 iter 24 loss=0.5614111423492432\n",
            "epoch 56 iter 25 loss=0.4567861557006836\n",
            "epoch 56 iter 26 loss=0.6425022482872009\n",
            "epoch 56 iter 27 loss=0.5469843149185181\n",
            "epoch 56 iter 28 loss=0.5168677568435669\n",
            "epoch 56 iter 29 loss=0.673557460308075\n",
            "epoch 56 iter 30 loss=0.552247166633606\n",
            "epoch 56 iter 31 loss=0.5439059138298035\n",
            "epoch 56 iter 32 loss=0.6401682496070862\n",
            "epoch 56 iter 33 loss=0.6213589906692505\n",
            "epoch 56 iter 34 loss=0.4018190801143646\n",
            "epoch 56 iter 35 loss=0.7098153233528137\n",
            "epoch 56 iter 36 loss=0.7407983541488647\n",
            "epoch 56 iter 37 loss=0.4007038474082947\n",
            "epoch 57 iter 0 loss=0.38891729712486267\n",
            "epoch 57 iter 1 loss=0.5009987354278564\n",
            "epoch 57 iter 2 loss=0.43149620294570923\n",
            "epoch 57 iter 3 loss=0.5693273544311523\n",
            "epoch 57 iter 4 loss=0.627771258354187\n",
            "epoch 57 iter 5 loss=0.388081818819046\n",
            "epoch 57 iter 6 loss=0.6512640714645386\n",
            "epoch 57 iter 7 loss=0.6426823139190674\n",
            "epoch 57 iter 8 loss=0.643024742603302\n",
            "epoch 57 iter 9 loss=0.5480092167854309\n",
            "epoch 57 iter 10 loss=0.7130756974220276\n",
            "epoch 57 iter 11 loss=0.7379789352416992\n",
            "epoch 57 iter 12 loss=0.6078231334686279\n",
            "epoch 57 iter 13 loss=0.6998220682144165\n",
            "epoch 57 iter 14 loss=0.619609534740448\n",
            "epoch 57 iter 15 loss=0.5324943661689758\n",
            "epoch 57 iter 16 loss=0.4951014816761017\n",
            "epoch 57 iter 17 loss=0.5176432728767395\n",
            "epoch 57 iter 18 loss=0.5328385829925537\n",
            "epoch 57 iter 19 loss=0.45195454359054565\n",
            "epoch 57 iter 20 loss=0.7809546589851379\n",
            "epoch 57 iter 21 loss=0.35365843772888184\n",
            "epoch 57 iter 22 loss=0.4710942506790161\n",
            "epoch 57 iter 23 loss=0.6517625451087952\n",
            "epoch 57 iter 24 loss=0.4165389835834503\n",
            "epoch 57 iter 25 loss=0.6023770570755005\n",
            "epoch 57 iter 26 loss=0.5284150838851929\n",
            "epoch 57 iter 27 loss=0.4767449200153351\n",
            "epoch 57 iter 28 loss=0.5162496566772461\n",
            "epoch 57 iter 29 loss=0.6380636692047119\n",
            "epoch 57 iter 30 loss=0.6058545112609863\n",
            "epoch 57 iter 31 loss=0.37387749552726746\n",
            "epoch 57 iter 32 loss=0.5235521197319031\n",
            "epoch 57 iter 33 loss=0.563824474811554\n",
            "epoch 57 iter 34 loss=0.47472310066223145\n",
            "epoch 57 iter 35 loss=0.5993165969848633\n",
            "epoch 57 iter 36 loss=0.4627598822116852\n",
            "epoch 57 iter 37 loss=0.7583593726158142\n",
            "epoch 58 iter 0 loss=0.5307580828666687\n",
            "epoch 58 iter 1 loss=0.5264760851860046\n",
            "epoch 58 iter 2 loss=0.4400443136692047\n",
            "epoch 58 iter 3 loss=0.5818650722503662\n",
            "epoch 58 iter 4 loss=0.4795744717121124\n",
            "epoch 58 iter 5 loss=0.4662102460861206\n",
            "epoch 58 iter 6 loss=0.5278855562210083\n",
            "epoch 58 iter 7 loss=0.41488128900527954\n",
            "epoch 58 iter 8 loss=0.6616714596748352\n",
            "epoch 58 iter 9 loss=0.5697272419929504\n",
            "epoch 58 iter 10 loss=0.5154638290405273\n",
            "epoch 58 iter 11 loss=0.5063605904579163\n",
            "epoch 58 iter 12 loss=0.3847605288028717\n",
            "epoch 58 iter 13 loss=0.4223417639732361\n",
            "epoch 58 iter 14 loss=0.4220072031021118\n",
            "epoch 58 iter 15 loss=0.4148552119731903\n",
            "epoch 58 iter 16 loss=0.46269655227661133\n",
            "epoch 58 iter 17 loss=0.413939893245697\n",
            "epoch 58 iter 18 loss=0.5339481234550476\n",
            "epoch 58 iter 19 loss=0.5219982266426086\n",
            "epoch 58 iter 20 loss=0.4508994221687317\n",
            "epoch 58 iter 21 loss=0.4642423093318939\n",
            "epoch 58 iter 22 loss=0.6273159980773926\n",
            "epoch 58 iter 23 loss=0.6514409184455872\n",
            "epoch 58 iter 24 loss=0.4387967586517334\n",
            "epoch 58 iter 25 loss=0.4901963472366333\n",
            "epoch 58 iter 26 loss=0.4157588481903076\n",
            "epoch 58 iter 27 loss=0.5895208716392517\n",
            "epoch 58 iter 28 loss=0.7228122353553772\n",
            "epoch 58 iter 29 loss=0.6004261374473572\n",
            "epoch 58 iter 30 loss=0.5067523717880249\n",
            "epoch 58 iter 31 loss=0.4803648293018341\n",
            "epoch 58 iter 32 loss=0.40617257356643677\n",
            "epoch 58 iter 33 loss=0.4768548011779785\n",
            "epoch 58 iter 34 loss=0.44947174191474915\n",
            "epoch 58 iter 35 loss=0.4910585880279541\n",
            "epoch 58 iter 36 loss=0.459025114774704\n",
            "epoch 58 iter 37 loss=0.46731916069984436\n",
            "epoch 59 iter 0 loss=0.4437364339828491\n",
            "epoch 59 iter 1 loss=0.45977410674095154\n",
            "epoch 59 iter 2 loss=0.4793246388435364\n",
            "epoch 59 iter 3 loss=0.4632461667060852\n",
            "epoch 59 iter 4 loss=0.402349591255188\n",
            "epoch 59 iter 5 loss=0.5604856014251709\n",
            "epoch 59 iter 6 loss=0.43001773953437805\n",
            "epoch 59 iter 7 loss=0.469501793384552\n",
            "epoch 59 iter 8 loss=0.6140021085739136\n",
            "epoch 59 iter 9 loss=0.4977054297924042\n",
            "epoch 59 iter 10 loss=0.6098737120628357\n",
            "epoch 59 iter 11 loss=0.4006255567073822\n",
            "epoch 59 iter 12 loss=0.586897611618042\n",
            "epoch 59 iter 13 loss=0.336291640996933\n",
            "epoch 59 iter 14 loss=0.48244303464889526\n",
            "epoch 59 iter 15 loss=0.6589956283569336\n",
            "epoch 59 iter 16 loss=0.6347757577896118\n",
            "epoch 59 iter 17 loss=0.4101981222629547\n",
            "epoch 59 iter 18 loss=0.33923351764678955\n",
            "epoch 59 iter 19 loss=0.45849868655204773\n",
            "epoch 59 iter 20 loss=0.6909607648849487\n",
            "epoch 59 iter 21 loss=0.5100944638252258\n",
            "epoch 59 iter 22 loss=0.4759106934070587\n",
            "epoch 59 iter 23 loss=0.4173123836517334\n",
            "epoch 59 iter 24 loss=0.40867891907691956\n",
            "epoch 59 iter 25 loss=0.40235620737075806\n",
            "epoch 59 iter 26 loss=0.44239699840545654\n",
            "epoch 59 iter 27 loss=0.5533003807067871\n",
            "epoch 59 iter 28 loss=0.49495503306388855\n",
            "epoch 59 iter 29 loss=0.42210397124290466\n",
            "epoch 59 iter 30 loss=0.6586114764213562\n",
            "epoch 59 iter 31 loss=0.4246967136859894\n",
            "epoch 59 iter 32 loss=0.49140283465385437\n",
            "epoch 59 iter 33 loss=0.5075578093528748\n",
            "epoch 59 iter 34 loss=0.5293421149253845\n",
            "epoch 59 iter 35 loss=0.5149052143096924\n",
            "epoch 59 iter 36 loss=0.45736658573150635\n",
            "epoch 59 iter 37 loss=0.4744749665260315\n",
            "epoch 60 iter 0 loss=0.4289431571960449\n",
            "epoch 60 iter 1 loss=0.7474120259284973\n",
            "epoch 60 iter 2 loss=0.44970402121543884\n",
            "epoch 60 iter 3 loss=0.5359152555465698\n",
            "epoch 60 iter 4 loss=0.8520960211753845\n",
            "epoch 60 iter 5 loss=0.45158687233924866\n",
            "epoch 60 iter 6 loss=0.5695269107818604\n",
            "epoch 60 iter 7 loss=0.4360799491405487\n",
            "epoch 60 iter 8 loss=0.3646495044231415\n",
            "epoch 60 iter 9 loss=0.6066306233406067\n",
            "epoch 60 iter 10 loss=0.6907614469528198\n",
            "epoch 60 iter 11 loss=0.6115206480026245\n",
            "epoch 60 iter 12 loss=0.7758677005767822\n",
            "epoch 60 iter 13 loss=0.5276378989219666\n",
            "epoch 60 iter 14 loss=0.7966505289077759\n",
            "epoch 60 iter 15 loss=0.49966490268707275\n",
            "epoch 60 iter 16 loss=0.4898405075073242\n",
            "epoch 60 iter 17 loss=0.4701143801212311\n",
            "epoch 60 iter 18 loss=0.5082874298095703\n",
            "epoch 60 iter 19 loss=0.47379612922668457\n",
            "epoch 60 iter 20 loss=0.5303154587745667\n",
            "epoch 60 iter 21 loss=0.5922048091888428\n",
            "epoch 60 iter 22 loss=0.4253929853439331\n",
            "epoch 60 iter 23 loss=0.5198813676834106\n",
            "epoch 60 iter 24 loss=0.35028812289237976\n",
            "epoch 60 iter 25 loss=0.4008610248565674\n",
            "epoch 60 iter 26 loss=0.6731981635093689\n",
            "epoch 60 iter 27 loss=0.5485203862190247\n",
            "epoch 60 iter 28 loss=0.6160176396369934\n",
            "epoch 60 iter 29 loss=0.617317795753479\n",
            "epoch 60 iter 30 loss=0.500503420829773\n",
            "epoch 60 iter 31 loss=0.662743330001831\n",
            "epoch 60 iter 32 loss=0.5698456168174744\n",
            "epoch 60 iter 33 loss=0.5330161452293396\n",
            "epoch 60 iter 34 loss=0.510083019733429\n",
            "epoch 60 iter 35 loss=0.553074836730957\n",
            "epoch 60 iter 36 loss=0.43794873356819153\n",
            "epoch 60 iter 37 loss=0.5237926244735718\n",
            "epoch 61 iter 0 loss=0.4861626625061035\n",
            "epoch 61 iter 1 loss=0.5108632445335388\n",
            "epoch 61 iter 2 loss=0.6898288130760193\n",
            "epoch 61 iter 3 loss=0.5030312538146973\n",
            "epoch 61 iter 4 loss=0.45840752124786377\n",
            "epoch 61 iter 5 loss=0.48630058765411377\n",
            "epoch 61 iter 6 loss=0.5411651730537415\n",
            "epoch 61 iter 7 loss=0.5533894896507263\n",
            "epoch 61 iter 8 loss=0.6518341302871704\n",
            "epoch 61 iter 9 loss=0.4188271760940552\n",
            "epoch 61 iter 10 loss=0.614956259727478\n",
            "epoch 61 iter 11 loss=0.47814318537712097\n",
            "epoch 61 iter 12 loss=0.5143207311630249\n",
            "epoch 61 iter 13 loss=0.46867525577545166\n",
            "epoch 61 iter 14 loss=0.46228092908859253\n",
            "epoch 61 iter 15 loss=0.521562933921814\n",
            "epoch 61 iter 16 loss=0.444863498210907\n",
            "epoch 61 iter 17 loss=0.4462321996688843\n",
            "epoch 61 iter 18 loss=0.3982260823249817\n",
            "epoch 61 iter 19 loss=0.36772939562797546\n",
            "epoch 61 iter 20 loss=0.6675469279289246\n",
            "epoch 61 iter 21 loss=0.41570377349853516\n",
            "epoch 61 iter 22 loss=0.49140164256095886\n",
            "epoch 61 iter 23 loss=0.4951377809047699\n",
            "epoch 61 iter 24 loss=0.5301388502120972\n",
            "epoch 61 iter 25 loss=0.416555255651474\n",
            "epoch 61 iter 26 loss=0.5464758276939392\n",
            "epoch 61 iter 27 loss=0.3455275297164917\n",
            "epoch 61 iter 28 loss=0.4525153338909149\n",
            "epoch 61 iter 29 loss=0.43799951672554016\n",
            "epoch 61 iter 30 loss=0.38867366313934326\n",
            "epoch 61 iter 31 loss=0.597939133644104\n",
            "epoch 61 iter 32 loss=0.520622730255127\n",
            "epoch 61 iter 33 loss=0.47697070240974426\n",
            "epoch 61 iter 34 loss=0.4663538336753845\n",
            "epoch 61 iter 35 loss=0.4533067047595978\n",
            "epoch 61 iter 36 loss=0.47338250279426575\n",
            "epoch 61 iter 37 loss=0.5428359508514404\n",
            "epoch 62 iter 0 loss=0.5233429670333862\n",
            "epoch 62 iter 1 loss=0.5682594180107117\n",
            "epoch 62 iter 2 loss=0.4714919626712799\n",
            "epoch 62 iter 3 loss=0.4741581082344055\n",
            "epoch 62 iter 4 loss=0.6890896558761597\n",
            "epoch 62 iter 5 loss=0.43990039825439453\n",
            "epoch 62 iter 6 loss=0.4705539345741272\n",
            "epoch 62 iter 7 loss=0.4470444619655609\n",
            "epoch 62 iter 8 loss=0.45534446835517883\n",
            "epoch 62 iter 9 loss=0.5698124170303345\n",
            "epoch 62 iter 10 loss=0.41929805278778076\n",
            "epoch 62 iter 11 loss=0.4481598436832428\n",
            "epoch 62 iter 12 loss=0.4429052174091339\n",
            "epoch 62 iter 13 loss=0.3399248719215393\n",
            "epoch 62 iter 14 loss=0.3651373088359833\n",
            "epoch 62 iter 15 loss=0.5860152840614319\n",
            "epoch 62 iter 16 loss=0.4000145196914673\n",
            "epoch 62 iter 17 loss=0.43628019094467163\n",
            "epoch 62 iter 18 loss=0.4589369595050812\n",
            "epoch 62 iter 19 loss=0.46314144134521484\n",
            "epoch 62 iter 20 loss=0.4793967008590698\n",
            "epoch 62 iter 21 loss=0.39166563749313354\n",
            "epoch 62 iter 22 loss=0.4111608862876892\n",
            "epoch 62 iter 23 loss=0.5516287088394165\n",
            "epoch 62 iter 24 loss=0.469390332698822\n",
            "epoch 62 iter 25 loss=0.44411009550094604\n",
            "epoch 62 iter 26 loss=0.45063316822052\n",
            "epoch 62 iter 27 loss=0.4331721067428589\n",
            "epoch 62 iter 28 loss=0.35732293128967285\n",
            "epoch 62 iter 29 loss=0.6199586987495422\n",
            "epoch 62 iter 30 loss=0.5024232268333435\n",
            "epoch 62 iter 31 loss=0.4170079827308655\n",
            "epoch 62 iter 32 loss=0.5683192014694214\n",
            "epoch 62 iter 33 loss=0.44698768854141235\n",
            "epoch 62 iter 34 loss=0.4217401146888733\n",
            "epoch 62 iter 35 loss=0.6503695249557495\n",
            "epoch 62 iter 36 loss=0.5414185523986816\n",
            "epoch 62 iter 37 loss=0.48136255145072937\n",
            "epoch 63 iter 0 loss=0.5353268980979919\n",
            "epoch 63 iter 1 loss=0.44091740250587463\n",
            "epoch 63 iter 2 loss=0.7423744201660156\n",
            "epoch 63 iter 3 loss=0.4521259069442749\n",
            "epoch 63 iter 4 loss=0.5866907238960266\n",
            "epoch 63 iter 5 loss=0.3822106420993805\n",
            "epoch 63 iter 6 loss=0.5018370747566223\n",
            "epoch 63 iter 7 loss=0.41349294781684875\n",
            "epoch 63 iter 8 loss=0.4364530146121979\n",
            "epoch 63 iter 9 loss=0.3096577525138855\n",
            "epoch 63 iter 10 loss=0.38206395506858826\n",
            "epoch 63 iter 11 loss=0.46232250332832336\n",
            "epoch 63 iter 12 loss=0.46712687611579895\n",
            "epoch 63 iter 13 loss=0.3727097511291504\n",
            "epoch 63 iter 14 loss=0.4650321304798126\n",
            "epoch 63 iter 15 loss=0.5363859534263611\n",
            "epoch 63 iter 16 loss=0.47380539774894714\n",
            "epoch 63 iter 17 loss=0.5661280155181885\n",
            "epoch 63 iter 18 loss=0.4135265648365021\n",
            "epoch 63 iter 19 loss=0.519119918346405\n",
            "epoch 63 iter 20 loss=0.4452708065509796\n",
            "epoch 63 iter 21 loss=0.43047037720680237\n",
            "epoch 63 iter 22 loss=0.34526845812797546\n",
            "epoch 63 iter 23 loss=0.6931055188179016\n",
            "epoch 63 iter 24 loss=0.44715753197669983\n",
            "epoch 63 iter 25 loss=0.5619553327560425\n",
            "epoch 63 iter 26 loss=0.6774957776069641\n",
            "epoch 63 iter 27 loss=0.3872784674167633\n",
            "epoch 63 iter 28 loss=0.7424860596656799\n",
            "epoch 63 iter 29 loss=0.5041662454605103\n",
            "epoch 63 iter 30 loss=0.43143555521965027\n",
            "epoch 63 iter 31 loss=0.46272143721580505\n",
            "epoch 63 iter 32 loss=0.5224741697311401\n",
            "epoch 63 iter 33 loss=0.7062380313873291\n",
            "epoch 63 iter 34 loss=0.6930993795394897\n",
            "epoch 63 iter 35 loss=0.49323683977127075\n",
            "epoch 63 iter 36 loss=0.4553862512111664\n",
            "epoch 63 iter 37 loss=0.7085715532302856\n",
            "epoch 64 iter 0 loss=0.5411010384559631\n",
            "epoch 64 iter 1 loss=0.4375365376472473\n",
            "epoch 64 iter 2 loss=0.4407796263694763\n",
            "epoch 64 iter 3 loss=0.5266367793083191\n",
            "epoch 64 iter 4 loss=0.3889392614364624\n",
            "epoch 64 iter 5 loss=0.31020450592041016\n",
            "epoch 64 iter 6 loss=0.38929709792137146\n",
            "epoch 64 iter 7 loss=0.46985092759132385\n",
            "epoch 64 iter 8 loss=0.4083292782306671\n",
            "epoch 64 iter 9 loss=0.5483626127243042\n",
            "epoch 64 iter 10 loss=0.45652449131011963\n",
            "epoch 64 iter 11 loss=0.6060739159584045\n",
            "epoch 64 iter 12 loss=0.5007970929145813\n",
            "epoch 64 iter 13 loss=0.3443494439125061\n",
            "epoch 64 iter 14 loss=0.550222635269165\n",
            "epoch 64 iter 15 loss=0.3730274438858032\n",
            "epoch 64 iter 16 loss=0.7284950017929077\n",
            "epoch 64 iter 17 loss=0.7349148988723755\n",
            "epoch 64 iter 18 loss=0.4595182240009308\n",
            "epoch 64 iter 19 loss=0.4704902172088623\n",
            "epoch 64 iter 20 loss=0.4687805771827698\n",
            "epoch 64 iter 21 loss=0.43304821848869324\n",
            "epoch 64 iter 22 loss=0.4136395752429962\n",
            "epoch 64 iter 23 loss=0.5404948592185974\n",
            "epoch 64 iter 24 loss=0.37085196375846863\n",
            "epoch 64 iter 25 loss=0.40264272689819336\n",
            "epoch 64 iter 26 loss=0.6742234230041504\n",
            "epoch 64 iter 27 loss=0.4394691586494446\n",
            "epoch 64 iter 28 loss=0.4520598351955414\n",
            "epoch 64 iter 29 loss=0.5417386889457703\n",
            "epoch 64 iter 30 loss=0.4822423458099365\n",
            "epoch 64 iter 31 loss=0.38285428285598755\n",
            "epoch 64 iter 32 loss=0.6950234174728394\n",
            "epoch 64 iter 33 loss=0.4435000419616699\n",
            "epoch 64 iter 34 loss=0.48084497451782227\n",
            "epoch 64 iter 35 loss=0.5857469439506531\n",
            "epoch 64 iter 36 loss=0.5346283316612244\n",
            "epoch 64 iter 37 loss=0.6702742576599121\n",
            "epoch 65 iter 0 loss=0.6567142605781555\n",
            "epoch 65 iter 1 loss=0.4078156352043152\n",
            "epoch 65 iter 2 loss=0.5324804186820984\n",
            "epoch 65 iter 3 loss=0.5008010864257812\n",
            "epoch 65 iter 4 loss=0.4408552646636963\n",
            "epoch 65 iter 5 loss=0.3386278748512268\n",
            "epoch 65 iter 6 loss=0.5278486013412476\n",
            "epoch 65 iter 7 loss=0.3691830337047577\n",
            "epoch 65 iter 8 loss=0.4341278076171875\n",
            "epoch 65 iter 9 loss=0.44082847237586975\n",
            "epoch 65 iter 10 loss=0.5469028353691101\n",
            "epoch 65 iter 11 loss=0.4273003935813904\n",
            "epoch 65 iter 12 loss=0.4062347114086151\n",
            "epoch 65 iter 13 loss=0.4928794205188751\n",
            "epoch 65 iter 14 loss=0.5473995804786682\n",
            "epoch 65 iter 15 loss=0.5988695621490479\n",
            "epoch 65 iter 16 loss=0.36665213108062744\n",
            "epoch 65 iter 17 loss=0.45258915424346924\n",
            "epoch 65 iter 18 loss=0.38913673162460327\n",
            "epoch 65 iter 19 loss=0.5245182514190674\n",
            "epoch 65 iter 20 loss=0.49217379093170166\n",
            "epoch 65 iter 21 loss=0.3822822868824005\n",
            "epoch 65 iter 22 loss=0.5336045026779175\n",
            "epoch 65 iter 23 loss=0.5246985554695129\n",
            "epoch 65 iter 24 loss=0.5349768400192261\n",
            "epoch 65 iter 25 loss=0.45921796560287476\n",
            "epoch 65 iter 26 loss=0.3474143445491791\n",
            "epoch 65 iter 27 loss=0.5160490870475769\n",
            "epoch 65 iter 28 loss=0.41236162185668945\n",
            "epoch 65 iter 29 loss=0.39246314764022827\n",
            "epoch 65 iter 30 loss=0.5562735199928284\n",
            "epoch 65 iter 31 loss=0.43406012654304504\n",
            "epoch 65 iter 32 loss=0.46827033162117004\n",
            "epoch 65 iter 33 loss=0.49949321150779724\n",
            "epoch 65 iter 34 loss=0.5370602011680603\n",
            "epoch 65 iter 35 loss=0.4948800206184387\n",
            "epoch 65 iter 36 loss=0.4515177309513092\n",
            "epoch 65 iter 37 loss=0.47314926981925964\n",
            "epoch 66 iter 0 loss=0.3546922206878662\n",
            "epoch 66 iter 1 loss=0.47067710757255554\n",
            "epoch 66 iter 2 loss=0.34693288803100586\n",
            "epoch 66 iter 3 loss=0.5252731442451477\n",
            "epoch 66 iter 4 loss=0.42952144145965576\n",
            "epoch 66 iter 5 loss=0.5534067749977112\n",
            "epoch 66 iter 6 loss=0.36156368255615234\n",
            "epoch 66 iter 7 loss=0.514937698841095\n",
            "epoch 66 iter 8 loss=0.45041584968566895\n",
            "epoch 66 iter 9 loss=0.46295422315597534\n",
            "epoch 66 iter 10 loss=0.42029306292533875\n",
            "epoch 66 iter 11 loss=0.49568918347358704\n",
            "epoch 66 iter 12 loss=0.5765683054924011\n",
            "epoch 66 iter 13 loss=0.4553891122341156\n",
            "epoch 66 iter 14 loss=0.37443727254867554\n",
            "epoch 66 iter 15 loss=0.3372698426246643\n",
            "epoch 66 iter 16 loss=0.5362429618835449\n",
            "epoch 66 iter 17 loss=0.38772687315940857\n",
            "epoch 66 iter 18 loss=0.44042113423347473\n",
            "epoch 66 iter 19 loss=0.4673541784286499\n",
            "epoch 66 iter 20 loss=0.45871803164482117\n",
            "epoch 66 iter 21 loss=0.4118589162826538\n",
            "epoch 66 iter 22 loss=0.35487136244773865\n",
            "epoch 66 iter 23 loss=0.5154811143875122\n",
            "epoch 66 iter 24 loss=0.46716147661209106\n",
            "epoch 66 iter 25 loss=0.4449826776981354\n",
            "epoch 66 iter 26 loss=0.48674213886260986\n",
            "epoch 66 iter 27 loss=0.35444211959838867\n",
            "epoch 66 iter 28 loss=0.4913474917411804\n",
            "epoch 66 iter 29 loss=0.428906112909317\n",
            "epoch 66 iter 30 loss=0.6082226634025574\n",
            "epoch 66 iter 31 loss=0.3708130419254303\n",
            "epoch 66 iter 32 loss=0.45045730471611023\n",
            "epoch 66 iter 33 loss=0.43040698766708374\n",
            "epoch 66 iter 34 loss=0.5256222486495972\n",
            "epoch 66 iter 35 loss=0.4581112563610077\n",
            "epoch 66 iter 36 loss=0.4932626485824585\n",
            "epoch 66 iter 37 loss=0.2729431986808777\n",
            "epoch 67 iter 0 loss=0.47473829984664917\n",
            "epoch 67 iter 1 loss=0.5462650060653687\n",
            "epoch 67 iter 2 loss=0.49008557200431824\n",
            "epoch 67 iter 3 loss=0.5675326585769653\n",
            "epoch 67 iter 4 loss=0.3621557056903839\n",
            "epoch 67 iter 5 loss=0.5444265604019165\n",
            "epoch 67 iter 6 loss=0.3744356334209442\n",
            "epoch 67 iter 7 loss=0.4906982183456421\n",
            "epoch 67 iter 8 loss=0.40203970670700073\n",
            "epoch 67 iter 9 loss=0.33439967036247253\n",
            "epoch 67 iter 10 loss=0.36256569623947144\n",
            "epoch 67 iter 11 loss=0.3196600377559662\n",
            "epoch 67 iter 12 loss=0.4709925353527069\n",
            "epoch 67 iter 13 loss=0.506490170955658\n",
            "epoch 67 iter 14 loss=0.5509954690933228\n",
            "epoch 67 iter 15 loss=0.4036635458469391\n",
            "epoch 67 iter 16 loss=0.4686475396156311\n",
            "epoch 67 iter 17 loss=0.5095011591911316\n",
            "epoch 67 iter 18 loss=0.5730733275413513\n",
            "epoch 67 iter 19 loss=0.4255106747150421\n",
            "epoch 67 iter 20 loss=0.5138332843780518\n",
            "epoch 67 iter 21 loss=0.538468599319458\n",
            "epoch 67 iter 22 loss=0.3352811932563782\n",
            "epoch 67 iter 23 loss=0.38694581389427185\n",
            "epoch 67 iter 24 loss=0.39434775710105896\n",
            "epoch 67 iter 25 loss=0.5779541730880737\n",
            "epoch 67 iter 26 loss=0.43344631791114807\n",
            "epoch 67 iter 27 loss=0.5321650505065918\n",
            "epoch 67 iter 28 loss=0.44515538215637207\n",
            "epoch 67 iter 29 loss=0.35489052534103394\n",
            "epoch 67 iter 30 loss=0.30265694856643677\n",
            "epoch 67 iter 31 loss=0.3673368990421295\n",
            "epoch 67 iter 32 loss=0.4408988952636719\n",
            "epoch 67 iter 33 loss=0.48290327191352844\n",
            "epoch 67 iter 34 loss=0.4890078902244568\n",
            "epoch 67 iter 35 loss=0.4299957752227783\n",
            "epoch 67 iter 36 loss=0.45753341913223267\n",
            "epoch 67 iter 37 loss=0.5585007667541504\n",
            "epoch 68 iter 0 loss=0.46682295203208923\n",
            "epoch 68 iter 1 loss=0.3322923183441162\n",
            "epoch 68 iter 2 loss=0.5323825478553772\n",
            "epoch 68 iter 3 loss=0.46381261944770813\n",
            "epoch 68 iter 4 loss=0.5430648326873779\n",
            "epoch 68 iter 5 loss=0.4759010672569275\n",
            "epoch 68 iter 6 loss=0.46469682455062866\n",
            "epoch 68 iter 7 loss=0.40858274698257446\n",
            "epoch 68 iter 8 loss=0.3842524588108063\n",
            "epoch 68 iter 9 loss=0.48361721634864807\n",
            "epoch 68 iter 10 loss=0.4842459261417389\n",
            "epoch 68 iter 11 loss=0.4075881838798523\n",
            "epoch 68 iter 12 loss=0.46893855929374695\n",
            "epoch 68 iter 13 loss=0.49409469962120056\n",
            "epoch 68 iter 14 loss=0.4130825996398926\n",
            "epoch 68 iter 15 loss=0.4341684579849243\n",
            "epoch 68 iter 16 loss=0.47027787566185\n",
            "epoch 68 iter 17 loss=0.3954591453075409\n",
            "epoch 68 iter 18 loss=0.41155657172203064\n",
            "epoch 68 iter 19 loss=0.3831513524055481\n",
            "epoch 68 iter 20 loss=0.44815289974212646\n",
            "epoch 68 iter 21 loss=0.3698945939540863\n",
            "epoch 68 iter 22 loss=0.375527948141098\n",
            "epoch 68 iter 23 loss=0.5939369797706604\n",
            "epoch 68 iter 24 loss=0.4044828414916992\n",
            "epoch 68 iter 25 loss=0.4365675449371338\n",
            "epoch 68 iter 26 loss=0.4868741035461426\n",
            "epoch 68 iter 27 loss=0.4589014947414398\n",
            "epoch 68 iter 28 loss=0.5165026187896729\n",
            "epoch 68 iter 29 loss=0.4319614768028259\n",
            "epoch 68 iter 30 loss=0.37943369150161743\n",
            "epoch 68 iter 31 loss=0.41958293318748474\n",
            "epoch 68 iter 32 loss=0.33854109048843384\n",
            "epoch 68 iter 33 loss=0.4523963928222656\n",
            "epoch 68 iter 34 loss=0.5398154854774475\n",
            "epoch 68 iter 35 loss=0.402457058429718\n",
            "epoch 68 iter 36 loss=0.4167267382144928\n",
            "epoch 68 iter 37 loss=0.9927732944488525\n",
            "epoch 69 iter 0 loss=0.7574451565742493\n",
            "epoch 69 iter 1 loss=1.2704211473464966\n",
            "epoch 69 iter 2 loss=0.8050410747528076\n",
            "epoch 69 iter 3 loss=0.7568932771682739\n",
            "epoch 69 iter 4 loss=1.0580329895019531\n",
            "epoch 69 iter 5 loss=0.9274682402610779\n",
            "epoch 69 iter 6 loss=1.4281837940216064\n",
            "epoch 69 iter 7 loss=0.7762835025787354\n",
            "epoch 69 iter 8 loss=0.8616051077842712\n",
            "epoch 69 iter 9 loss=0.893442690372467\n",
            "epoch 69 iter 10 loss=0.980223536491394\n",
            "epoch 69 iter 11 loss=0.8059112429618835\n",
            "epoch 69 iter 12 loss=0.8798460364341736\n",
            "epoch 69 iter 13 loss=0.911690890789032\n",
            "epoch 69 iter 14 loss=0.9190122485160828\n",
            "epoch 69 iter 15 loss=0.893530011177063\n",
            "epoch 69 iter 16 loss=0.7454082369804382\n",
            "epoch 69 iter 17 loss=0.6434930562973022\n",
            "epoch 69 iter 18 loss=0.6755436062812805\n",
            "epoch 69 iter 19 loss=0.6072660088539124\n",
            "epoch 69 iter 20 loss=0.5176761746406555\n",
            "epoch 69 iter 21 loss=0.9106284976005554\n",
            "epoch 69 iter 22 loss=0.5385580062866211\n",
            "epoch 69 iter 23 loss=0.6182792782783508\n",
            "epoch 69 iter 24 loss=0.683803379535675\n",
            "epoch 69 iter 25 loss=0.7146469354629517\n",
            "epoch 69 iter 26 loss=0.8602884411811829\n",
            "epoch 69 iter 27 loss=0.5268984436988831\n",
            "epoch 69 iter 28 loss=1.1315587759017944\n",
            "epoch 69 iter 29 loss=0.5353193879127502\n",
            "epoch 69 iter 30 loss=0.4617847204208374\n",
            "epoch 69 iter 31 loss=0.5118299126625061\n",
            "epoch 69 iter 32 loss=0.5483876466751099\n",
            "epoch 69 iter 33 loss=0.6565768122673035\n",
            "epoch 69 iter 34 loss=0.6194932460784912\n",
            "epoch 69 iter 35 loss=0.8506776094436646\n",
            "epoch 69 iter 36 loss=0.6531602144241333\n",
            "epoch 69 iter 37 loss=0.7450153827667236\n",
            "epoch 70 iter 0 loss=0.8061264753341675\n",
            "epoch 70 iter 1 loss=0.5213485956192017\n",
            "epoch 70 iter 2 loss=0.6167415976524353\n",
            "epoch 70 iter 3 loss=0.5915824174880981\n",
            "epoch 70 iter 4 loss=0.9278342127799988\n",
            "epoch 70 iter 5 loss=0.5465927720069885\n",
            "epoch 70 iter 6 loss=0.5168733596801758\n",
            "epoch 70 iter 7 loss=0.6108999252319336\n",
            "epoch 70 iter 8 loss=0.5774474740028381\n",
            "epoch 70 iter 9 loss=0.6318476796150208\n",
            "epoch 70 iter 10 loss=0.562360405921936\n",
            "epoch 70 iter 11 loss=0.46654579043388367\n",
            "epoch 70 iter 12 loss=0.557940661907196\n",
            "epoch 70 iter 13 loss=0.6476712226867676\n",
            "epoch 70 iter 14 loss=0.615179181098938\n",
            "epoch 70 iter 15 loss=0.6758344769477844\n",
            "epoch 70 iter 16 loss=0.5531150102615356\n",
            "epoch 70 iter 17 loss=0.5309591889381409\n",
            "epoch 70 iter 18 loss=0.5447946190834045\n",
            "epoch 70 iter 19 loss=0.45149531960487366\n",
            "epoch 70 iter 20 loss=0.4086949825286865\n",
            "epoch 70 iter 21 loss=0.4469493627548218\n",
            "epoch 70 iter 22 loss=0.5065340995788574\n",
            "epoch 70 iter 23 loss=0.608198881149292\n",
            "epoch 70 iter 24 loss=0.5859909057617188\n",
            "epoch 70 iter 25 loss=0.5064146518707275\n",
            "epoch 70 iter 26 loss=0.4175328314304352\n",
            "epoch 70 iter 27 loss=0.4956763982772827\n",
            "epoch 70 iter 28 loss=0.4703724682331085\n",
            "epoch 70 iter 29 loss=0.34336432814598083\n",
            "epoch 70 iter 30 loss=0.45601996779441833\n",
            "epoch 70 iter 31 loss=0.547204852104187\n",
            "epoch 70 iter 32 loss=0.5562156438827515\n",
            "epoch 70 iter 33 loss=0.6164655089378357\n",
            "epoch 70 iter 34 loss=0.3851885497570038\n",
            "epoch 70 iter 35 loss=0.5702293515205383\n",
            "epoch 70 iter 36 loss=0.6344384551048279\n",
            "epoch 70 iter 37 loss=0.4501701593399048\n",
            "epoch 71 iter 0 loss=0.4080483019351959\n",
            "epoch 71 iter 1 loss=0.5713418126106262\n",
            "epoch 71 iter 2 loss=0.5547665953636169\n",
            "epoch 71 iter 3 loss=0.42126932740211487\n",
            "epoch 71 iter 4 loss=0.557645320892334\n",
            "epoch 71 iter 5 loss=0.43955111503601074\n",
            "epoch 71 iter 6 loss=0.41448846459388733\n",
            "epoch 71 iter 7 loss=0.4148012697696686\n",
            "epoch 71 iter 8 loss=0.3899330794811249\n",
            "epoch 71 iter 9 loss=0.5837423205375671\n",
            "epoch 71 iter 10 loss=0.5203389525413513\n",
            "epoch 71 iter 11 loss=0.4451819360256195\n",
            "epoch 71 iter 12 loss=0.49162757396698\n",
            "epoch 71 iter 13 loss=0.447707861661911\n",
            "epoch 71 iter 14 loss=0.652842104434967\n",
            "epoch 71 iter 15 loss=0.5450380444526672\n",
            "epoch 71 iter 16 loss=0.5089098215103149\n",
            "epoch 71 iter 17 loss=0.4668401777744293\n",
            "epoch 71 iter 18 loss=0.46399062871932983\n",
            "epoch 71 iter 19 loss=0.829447329044342\n",
            "epoch 71 iter 20 loss=0.4357302486896515\n",
            "epoch 71 iter 21 loss=0.5547940731048584\n",
            "epoch 71 iter 22 loss=0.39035090804100037\n",
            "epoch 71 iter 23 loss=0.5258647203445435\n",
            "epoch 71 iter 24 loss=0.6393669247627258\n",
            "epoch 71 iter 25 loss=0.47551342844963074\n",
            "epoch 71 iter 26 loss=0.5110028982162476\n",
            "epoch 71 iter 27 loss=0.4731690585613251\n",
            "epoch 71 iter 28 loss=0.43484893441200256\n",
            "epoch 71 iter 29 loss=0.4719241261482239\n",
            "epoch 71 iter 30 loss=0.464987576007843\n",
            "epoch 71 iter 31 loss=0.5959325432777405\n",
            "epoch 71 iter 32 loss=0.3426194489002228\n",
            "epoch 71 iter 33 loss=0.45850077271461487\n",
            "epoch 71 iter 34 loss=0.4179585576057434\n",
            "epoch 71 iter 35 loss=0.487304151058197\n",
            "epoch 71 iter 36 loss=0.3733907639980316\n",
            "epoch 71 iter 37 loss=0.5996968150138855\n",
            "epoch 72 iter 0 loss=0.39643964171409607\n",
            "epoch 72 iter 1 loss=0.534678041934967\n",
            "epoch 72 iter 2 loss=0.3551221489906311\n",
            "epoch 72 iter 3 loss=0.4012295603752136\n",
            "epoch 72 iter 4 loss=0.6398797631263733\n",
            "epoch 72 iter 5 loss=0.49347466230392456\n",
            "epoch 72 iter 6 loss=0.4088142514228821\n",
            "epoch 72 iter 7 loss=0.43360796570777893\n",
            "epoch 72 iter 8 loss=0.38394659757614136\n",
            "epoch 72 iter 9 loss=0.5306179523468018\n",
            "epoch 72 iter 10 loss=0.5019383430480957\n",
            "epoch 72 iter 11 loss=0.5057221055030823\n",
            "epoch 72 iter 12 loss=0.5275055170059204\n",
            "epoch 72 iter 13 loss=0.484542578458786\n",
            "epoch 72 iter 14 loss=0.42178794741630554\n",
            "epoch 72 iter 15 loss=0.45591962337493896\n",
            "epoch 72 iter 16 loss=0.5479975938796997\n",
            "epoch 72 iter 17 loss=0.7534403204917908\n",
            "epoch 72 iter 18 loss=0.3798080086708069\n",
            "epoch 72 iter 19 loss=0.3790350556373596\n",
            "epoch 72 iter 20 loss=0.3759656846523285\n",
            "epoch 72 iter 21 loss=0.6974344253540039\n",
            "epoch 72 iter 22 loss=0.4278332591056824\n",
            "epoch 72 iter 23 loss=0.46644312143325806\n",
            "epoch 72 iter 24 loss=0.5107358694076538\n",
            "epoch 72 iter 25 loss=0.44558092951774597\n",
            "epoch 72 iter 26 loss=0.4255999028682709\n",
            "epoch 72 iter 27 loss=0.6165379881858826\n",
            "epoch 72 iter 28 loss=0.4365620017051697\n",
            "epoch 72 iter 29 loss=0.3634941875934601\n",
            "epoch 72 iter 30 loss=0.4046655297279358\n",
            "epoch 72 iter 31 loss=0.41217106580734253\n",
            "epoch 72 iter 32 loss=0.2888794243335724\n",
            "epoch 72 iter 33 loss=0.4782317280769348\n",
            "epoch 72 iter 34 loss=0.464827299118042\n",
            "epoch 72 iter 35 loss=0.3923657238483429\n",
            "epoch 72 iter 36 loss=0.4455276429653168\n",
            "epoch 72 iter 37 loss=0.5888726115226746\n",
            "epoch 73 iter 0 loss=0.47447264194488525\n",
            "epoch 73 iter 1 loss=0.45192548632621765\n",
            "epoch 73 iter 2 loss=0.4009324908256531\n",
            "epoch 73 iter 3 loss=0.48901429772377014\n",
            "epoch 73 iter 4 loss=0.4260137975215912\n",
            "epoch 73 iter 5 loss=0.44399353861808777\n",
            "epoch 73 iter 6 loss=0.695418655872345\n",
            "epoch 73 iter 7 loss=0.4053831696510315\n",
            "epoch 73 iter 8 loss=0.5197716951370239\n",
            "epoch 73 iter 9 loss=0.38661181926727295\n",
            "epoch 73 iter 10 loss=0.4070643484592438\n",
            "epoch 73 iter 11 loss=0.4848921597003937\n",
            "epoch 73 iter 12 loss=0.5399718284606934\n",
            "epoch 73 iter 13 loss=0.4631364345550537\n",
            "epoch 73 iter 14 loss=0.46980801224708557\n",
            "epoch 73 iter 15 loss=0.4071609079837799\n",
            "epoch 73 iter 16 loss=0.3692775368690491\n",
            "epoch 73 iter 17 loss=0.5186914205551147\n",
            "epoch 73 iter 18 loss=0.5002192258834839\n",
            "epoch 73 iter 19 loss=0.4529320299625397\n",
            "epoch 73 iter 20 loss=0.5916721820831299\n",
            "epoch 73 iter 21 loss=0.6415519118309021\n",
            "epoch 73 iter 22 loss=0.4466668367385864\n",
            "epoch 73 iter 23 loss=0.5007206201553345\n",
            "epoch 73 iter 24 loss=0.5088624954223633\n",
            "epoch 73 iter 25 loss=0.4460859000682831\n",
            "epoch 73 iter 26 loss=0.38420647382736206\n",
            "epoch 73 iter 27 loss=0.5006008744239807\n",
            "epoch 73 iter 28 loss=0.4003581702709198\n",
            "epoch 73 iter 29 loss=0.3622059226036072\n",
            "epoch 73 iter 30 loss=0.34776872396469116\n",
            "epoch 73 iter 31 loss=0.5181114673614502\n",
            "epoch 73 iter 32 loss=0.43392413854599\n",
            "epoch 73 iter 33 loss=0.39546844363212585\n",
            "epoch 73 iter 34 loss=0.3286186456680298\n",
            "epoch 73 iter 35 loss=0.5109997391700745\n",
            "epoch 73 iter 36 loss=0.4558618664741516\n",
            "epoch 73 iter 37 loss=0.368908166885376\n",
            "epoch 74 iter 0 loss=0.3667384088039398\n",
            "epoch 74 iter 1 loss=0.3645179867744446\n",
            "epoch 74 iter 2 loss=0.42910829186439514\n",
            "epoch 74 iter 3 loss=0.4520030617713928\n",
            "epoch 74 iter 4 loss=0.28589898347854614\n",
            "epoch 74 iter 5 loss=0.40329909324645996\n",
            "epoch 74 iter 6 loss=0.36338627338409424\n",
            "epoch 74 iter 7 loss=0.4990502595901489\n",
            "epoch 74 iter 8 loss=0.4760356545448303\n",
            "epoch 74 iter 9 loss=0.3230580687522888\n",
            "epoch 74 iter 10 loss=0.5044662952423096\n",
            "epoch 74 iter 11 loss=0.4367970824241638\n",
            "epoch 74 iter 12 loss=0.7650803327560425\n",
            "epoch 74 iter 13 loss=0.40724730491638184\n",
            "epoch 74 iter 14 loss=0.5306967496871948\n",
            "epoch 74 iter 15 loss=0.5543375611305237\n",
            "epoch 74 iter 16 loss=0.47111302614212036\n",
            "epoch 74 iter 17 loss=0.46236109733581543\n",
            "epoch 74 iter 18 loss=0.7618710994720459\n",
            "epoch 74 iter 19 loss=0.4591868221759796\n",
            "epoch 74 iter 20 loss=0.5461089015007019\n",
            "epoch 74 iter 21 loss=0.5471712946891785\n",
            "epoch 74 iter 22 loss=0.41206300258636475\n",
            "epoch 74 iter 23 loss=0.4412499666213989\n",
            "epoch 74 iter 24 loss=0.4338640570640564\n",
            "epoch 74 iter 25 loss=0.46162450313568115\n",
            "epoch 74 iter 26 loss=0.32925328612327576\n",
            "epoch 74 iter 27 loss=0.3495349884033203\n",
            "epoch 74 iter 28 loss=0.4801892936229706\n",
            "epoch 74 iter 29 loss=0.5205926895141602\n",
            "epoch 74 iter 30 loss=0.46439290046691895\n",
            "epoch 74 iter 31 loss=0.48321768641471863\n",
            "epoch 74 iter 32 loss=0.34804075956344604\n",
            "epoch 74 iter 33 loss=0.5180106163024902\n",
            "epoch 74 iter 34 loss=0.40569671988487244\n",
            "epoch 74 iter 35 loss=0.45558324456214905\n",
            "epoch 74 iter 36 loss=0.37554991245269775\n",
            "epoch 74 iter 37 loss=0.5167886018753052\n",
            "epoch 75 iter 0 loss=0.3450867831707001\n",
            "epoch 75 iter 1 loss=0.5085152983665466\n",
            "epoch 75 iter 2 loss=0.3423115909099579\n",
            "epoch 75 iter 3 loss=0.5136308073997498\n",
            "epoch 75 iter 4 loss=0.4434831142425537\n",
            "epoch 75 iter 5 loss=0.30287447571754456\n",
            "epoch 75 iter 6 loss=0.37604033946990967\n",
            "epoch 75 iter 7 loss=0.38067319989204407\n",
            "epoch 75 iter 8 loss=0.4932255446910858\n",
            "epoch 75 iter 9 loss=0.3522090017795563\n",
            "epoch 75 iter 10 loss=0.5052391290664673\n",
            "epoch 75 iter 11 loss=0.4159005284309387\n",
            "epoch 75 iter 12 loss=0.4873773753643036\n",
            "epoch 75 iter 13 loss=0.5355703234672546\n",
            "epoch 75 iter 14 loss=0.4762526750564575\n",
            "epoch 75 iter 15 loss=0.4626418650150299\n",
            "epoch 75 iter 16 loss=0.41779088973999023\n",
            "epoch 75 iter 17 loss=0.4558762013912201\n",
            "epoch 75 iter 18 loss=0.4298737049102783\n",
            "epoch 75 iter 19 loss=0.3911837041378021\n",
            "epoch 75 iter 20 loss=0.49433737993240356\n",
            "epoch 75 iter 21 loss=0.44780614972114563\n",
            "epoch 75 iter 22 loss=0.47077476978302\n",
            "epoch 75 iter 23 loss=0.35392454266548157\n",
            "epoch 75 iter 24 loss=0.3529762923717499\n",
            "epoch 75 iter 25 loss=0.5920060276985168\n",
            "epoch 75 iter 26 loss=0.4481344521045685\n",
            "epoch 75 iter 27 loss=0.4489600956439972\n",
            "epoch 75 iter 28 loss=0.4012331962585449\n",
            "epoch 75 iter 29 loss=0.3591661751270294\n",
            "epoch 75 iter 30 loss=0.48872852325439453\n",
            "epoch 75 iter 31 loss=0.309264212846756\n",
            "epoch 75 iter 32 loss=0.37917739152908325\n",
            "epoch 75 iter 33 loss=0.40643155574798584\n",
            "epoch 75 iter 34 loss=0.4041118621826172\n",
            "epoch 75 iter 35 loss=0.3694517910480499\n",
            "epoch 75 iter 36 loss=0.4824731647968292\n",
            "epoch 75 iter 37 loss=0.4480478763580322\n",
            "epoch 76 iter 0 loss=0.4797881543636322\n",
            "epoch 76 iter 1 loss=0.4977085292339325\n",
            "epoch 76 iter 2 loss=0.4719049036502838\n",
            "epoch 76 iter 3 loss=0.3756333589553833\n",
            "epoch 76 iter 4 loss=0.3258517384529114\n",
            "epoch 76 iter 5 loss=0.39352065324783325\n",
            "epoch 76 iter 6 loss=0.3781122863292694\n",
            "epoch 76 iter 7 loss=0.45427000522613525\n",
            "epoch 76 iter 8 loss=0.4837614893913269\n",
            "epoch 76 iter 9 loss=0.47770601511001587\n",
            "epoch 76 iter 10 loss=0.33624696731567383\n",
            "epoch 76 iter 11 loss=0.47232508659362793\n",
            "epoch 76 iter 12 loss=0.3552839457988739\n",
            "epoch 76 iter 13 loss=0.4356856942176819\n",
            "epoch 76 iter 14 loss=0.3834357261657715\n",
            "epoch 76 iter 15 loss=0.5039948225021362\n",
            "epoch 76 iter 16 loss=0.4466385245323181\n",
            "epoch 76 iter 17 loss=0.32616370916366577\n",
            "epoch 76 iter 18 loss=0.3585801422595978\n",
            "epoch 76 iter 19 loss=0.5063860416412354\n",
            "epoch 76 iter 20 loss=0.3901001513004303\n",
            "epoch 76 iter 21 loss=0.43774181604385376\n",
            "epoch 76 iter 22 loss=0.3598087430000305\n",
            "epoch 76 iter 23 loss=0.25834205746650696\n",
            "epoch 76 iter 24 loss=0.41653430461883545\n",
            "epoch 76 iter 25 loss=0.3498370945453644\n",
            "epoch 76 iter 26 loss=0.38496625423431396\n",
            "epoch 76 iter 27 loss=0.49422889947891235\n",
            "epoch 76 iter 28 loss=0.4217449724674225\n",
            "epoch 76 iter 29 loss=0.3819960057735443\n",
            "epoch 76 iter 30 loss=0.47009941935539246\n",
            "epoch 76 iter 31 loss=0.3646506369113922\n",
            "epoch 76 iter 32 loss=0.4469285011291504\n",
            "epoch 76 iter 33 loss=0.5141387581825256\n",
            "epoch 76 iter 34 loss=0.45298469066619873\n",
            "epoch 76 iter 35 loss=0.318694144487381\n",
            "epoch 76 iter 36 loss=0.3604814410209656\n",
            "epoch 76 iter 37 loss=0.4967081546783447\n",
            "epoch 77 iter 0 loss=0.36457788944244385\n",
            "epoch 77 iter 1 loss=0.6584669947624207\n",
            "epoch 77 iter 2 loss=0.4333198070526123\n",
            "epoch 77 iter 3 loss=0.2983465790748596\n",
            "epoch 77 iter 4 loss=0.301159143447876\n",
            "epoch 77 iter 5 loss=0.41462334990501404\n",
            "epoch 77 iter 6 loss=0.48484712839126587\n",
            "epoch 77 iter 7 loss=0.4207625687122345\n",
            "epoch 77 iter 8 loss=0.5717344284057617\n",
            "epoch 77 iter 9 loss=0.4440871775150299\n",
            "epoch 77 iter 10 loss=0.3812558054924011\n",
            "epoch 77 iter 11 loss=0.38992300629615784\n",
            "epoch 77 iter 12 loss=0.3523823916912079\n",
            "epoch 77 iter 13 loss=0.4057425260543823\n",
            "epoch 77 iter 14 loss=0.40489476919174194\n",
            "epoch 77 iter 15 loss=0.4388585090637207\n",
            "epoch 77 iter 16 loss=0.39174410700798035\n",
            "epoch 77 iter 17 loss=0.41601020097732544\n",
            "epoch 77 iter 18 loss=0.4456348419189453\n",
            "epoch 77 iter 19 loss=0.4249132573604584\n",
            "epoch 77 iter 20 loss=0.4341856837272644\n",
            "epoch 77 iter 21 loss=0.4359492361545563\n",
            "epoch 77 iter 22 loss=0.42122435569763184\n",
            "epoch 77 iter 23 loss=0.2736467123031616\n",
            "epoch 77 iter 24 loss=0.353458434343338\n",
            "epoch 77 iter 25 loss=0.5561323761940002\n",
            "epoch 77 iter 26 loss=0.2883726954460144\n",
            "epoch 77 iter 27 loss=0.4984171390533447\n",
            "epoch 77 iter 28 loss=0.40638843178749084\n",
            "epoch 77 iter 29 loss=0.520549476146698\n",
            "epoch 77 iter 30 loss=0.4460081458091736\n",
            "epoch 77 iter 31 loss=0.3131836950778961\n",
            "epoch 77 iter 32 loss=0.35334429144859314\n",
            "epoch 77 iter 33 loss=0.32390305399894714\n",
            "epoch 77 iter 34 loss=0.334665983915329\n",
            "epoch 77 iter 35 loss=0.4698331654071808\n",
            "epoch 77 iter 36 loss=0.37041884660720825\n",
            "epoch 77 iter 37 loss=0.3525363802909851\n",
            "epoch 78 iter 0 loss=0.3527753949165344\n",
            "epoch 78 iter 1 loss=0.512912392616272\n",
            "epoch 78 iter 2 loss=0.4574054479598999\n",
            "epoch 78 iter 3 loss=0.42337948083877563\n",
            "epoch 78 iter 4 loss=0.2677473723888397\n",
            "epoch 78 iter 5 loss=0.36008092761039734\n",
            "epoch 78 iter 6 loss=0.4226281940937042\n",
            "epoch 78 iter 7 loss=0.33577075600624084\n",
            "epoch 78 iter 8 loss=0.41673552989959717\n",
            "epoch 78 iter 9 loss=0.44375380873680115\n",
            "epoch 78 iter 10 loss=0.3457730710506439\n",
            "epoch 78 iter 11 loss=0.3306591212749481\n",
            "epoch 78 iter 12 loss=0.5595039129257202\n",
            "epoch 78 iter 13 loss=0.4123561680316925\n",
            "epoch 78 iter 14 loss=0.5043193697929382\n",
            "epoch 78 iter 15 loss=0.3074077367782593\n",
            "epoch 78 iter 16 loss=0.39836275577545166\n",
            "epoch 78 iter 17 loss=0.3167777955532074\n",
            "epoch 78 iter 18 loss=0.4459458887577057\n",
            "epoch 78 iter 19 loss=0.4389348030090332\n",
            "epoch 78 iter 20 loss=0.4009416699409485\n",
            "epoch 78 iter 21 loss=0.30484119057655334\n",
            "epoch 78 iter 22 loss=0.4660613238811493\n",
            "epoch 78 iter 23 loss=0.4156453609466553\n",
            "epoch 78 iter 24 loss=0.4128379821777344\n",
            "epoch 78 iter 25 loss=0.5097492337226868\n",
            "epoch 78 iter 26 loss=0.34807097911834717\n",
            "epoch 78 iter 27 loss=0.42787715792655945\n",
            "epoch 78 iter 28 loss=0.3723263144493103\n",
            "epoch 78 iter 29 loss=0.380329430103302\n",
            "epoch 78 iter 30 loss=0.31262847781181335\n",
            "epoch 78 iter 31 loss=0.5573185086250305\n",
            "epoch 78 iter 32 loss=0.4027714133262634\n",
            "epoch 78 iter 33 loss=0.3634170889854431\n",
            "epoch 78 iter 34 loss=0.4483751654624939\n",
            "epoch 78 iter 35 loss=0.350963830947876\n",
            "epoch 78 iter 36 loss=0.447653591632843\n",
            "epoch 78 iter 37 loss=0.47727271914482117\n",
            "epoch 79 iter 0 loss=0.37982478737831116\n",
            "epoch 79 iter 1 loss=0.4075758457183838\n",
            "epoch 79 iter 2 loss=0.349702388048172\n",
            "epoch 79 iter 3 loss=0.306877464056015\n",
            "epoch 79 iter 4 loss=0.4148015081882477\n",
            "epoch 79 iter 5 loss=0.3595089316368103\n",
            "epoch 79 iter 6 loss=0.5295335650444031\n",
            "epoch 79 iter 7 loss=0.3551611304283142\n",
            "epoch 79 iter 8 loss=0.5213373899459839\n",
            "epoch 79 iter 9 loss=0.29296472668647766\n",
            "epoch 79 iter 10 loss=0.33820852637290955\n",
            "epoch 79 iter 11 loss=0.4458325207233429\n",
            "epoch 79 iter 12 loss=0.34341442584991455\n",
            "epoch 79 iter 13 loss=0.4418913424015045\n",
            "epoch 79 iter 14 loss=0.3180318772792816\n",
            "epoch 79 iter 15 loss=0.43462935090065\n",
            "epoch 79 iter 16 loss=0.4643590450286865\n",
            "epoch 79 iter 17 loss=0.34360823035240173\n",
            "epoch 79 iter 18 loss=0.3882395327091217\n",
            "epoch 79 iter 19 loss=0.5088233947753906\n",
            "epoch 79 iter 20 loss=0.5373862385749817\n",
            "epoch 79 iter 21 loss=0.36274757981300354\n",
            "epoch 79 iter 22 loss=0.2668660879135132\n",
            "epoch 79 iter 23 loss=0.32811519503593445\n",
            "epoch 79 iter 24 loss=0.4924947917461395\n",
            "epoch 79 iter 25 loss=0.40044355392456055\n",
            "epoch 79 iter 26 loss=0.3922286331653595\n",
            "epoch 79 iter 27 loss=0.5464871525764465\n",
            "epoch 79 iter 28 loss=0.41122904419898987\n",
            "epoch 79 iter 29 loss=0.39810678362846375\n",
            "epoch 79 iter 30 loss=0.30776363611221313\n",
            "epoch 79 iter 31 loss=0.36711403727531433\n",
            "epoch 79 iter 32 loss=0.5531986355781555\n",
            "epoch 79 iter 33 loss=0.337604820728302\n",
            "epoch 79 iter 34 loss=0.4667966365814209\n",
            "epoch 79 iter 35 loss=0.3683018088340759\n",
            "epoch 79 iter 36 loss=0.4599270522594452\n",
            "epoch 79 iter 37 loss=0.4500201940536499\n",
            "epoch 80 iter 0 loss=0.5039877891540527\n",
            "epoch 80 iter 1 loss=0.39699476957321167\n",
            "epoch 80 iter 2 loss=0.5411425232887268\n",
            "epoch 80 iter 3 loss=0.3494463860988617\n",
            "epoch 80 iter 4 loss=0.40093961358070374\n",
            "epoch 80 iter 5 loss=0.2787727415561676\n",
            "epoch 80 iter 6 loss=0.5319554805755615\n",
            "epoch 80 iter 7 loss=0.5210775136947632\n",
            "epoch 80 iter 8 loss=0.3076745569705963\n",
            "epoch 80 iter 9 loss=0.5888400673866272\n",
            "epoch 80 iter 10 loss=0.36996081471443176\n",
            "epoch 80 iter 11 loss=0.3302818238735199\n",
            "epoch 80 iter 12 loss=0.5604270100593567\n",
            "epoch 80 iter 13 loss=0.3699895143508911\n",
            "epoch 80 iter 14 loss=0.3856875002384186\n",
            "epoch 80 iter 15 loss=0.5310668349266052\n",
            "epoch 80 iter 16 loss=0.5805760025978088\n",
            "epoch 80 iter 17 loss=0.4153688848018646\n",
            "epoch 80 iter 18 loss=0.31371036171913147\n",
            "epoch 80 iter 19 loss=0.4417102336883545\n",
            "epoch 80 iter 20 loss=0.3597955107688904\n",
            "epoch 80 iter 21 loss=0.40555545687675476\n",
            "epoch 80 iter 22 loss=0.3713679015636444\n",
            "epoch 80 iter 23 loss=0.3462524712085724\n",
            "epoch 80 iter 24 loss=0.260897159576416\n",
            "epoch 80 iter 25 loss=0.3835776448249817\n",
            "epoch 80 iter 26 loss=0.543084442615509\n",
            "epoch 80 iter 27 loss=0.43377262353897095\n",
            "epoch 80 iter 28 loss=0.5548665523529053\n",
            "epoch 80 iter 29 loss=0.35086268186569214\n",
            "epoch 80 iter 30 loss=0.4847562611103058\n",
            "epoch 80 iter 31 loss=0.47166118025779724\n",
            "epoch 80 iter 32 loss=0.3042023777961731\n",
            "epoch 80 iter 33 loss=0.3868827819824219\n",
            "epoch 80 iter 34 loss=0.44795238971710205\n",
            "epoch 80 iter 35 loss=0.3787984848022461\n",
            "epoch 80 iter 36 loss=0.3657912015914917\n",
            "epoch 80 iter 37 loss=0.5495489835739136\n",
            "epoch 81 iter 0 loss=0.36064422130584717\n",
            "epoch 81 iter 1 loss=0.4916715621948242\n",
            "epoch 81 iter 2 loss=0.3536837697029114\n",
            "epoch 81 iter 3 loss=0.3119868040084839\n",
            "epoch 81 iter 4 loss=0.5078228116035461\n",
            "epoch 81 iter 5 loss=0.32956913113594055\n",
            "epoch 81 iter 6 loss=0.47923722863197327\n",
            "epoch 81 iter 7 loss=0.34113991260528564\n",
            "epoch 81 iter 8 loss=0.41440442204475403\n",
            "epoch 81 iter 9 loss=0.3512289226055145\n",
            "epoch 81 iter 10 loss=0.3196518123149872\n",
            "epoch 81 iter 11 loss=0.47787773609161377\n",
            "epoch 81 iter 12 loss=0.30323028564453125\n",
            "epoch 81 iter 13 loss=0.4407225251197815\n",
            "epoch 81 iter 14 loss=0.5513865947723389\n",
            "epoch 81 iter 15 loss=0.40486931800842285\n",
            "epoch 81 iter 16 loss=0.4462112784385681\n",
            "epoch 81 iter 17 loss=0.43025848269462585\n",
            "epoch 81 iter 18 loss=0.38040998578071594\n",
            "epoch 81 iter 19 loss=0.3846686780452728\n",
            "epoch 81 iter 20 loss=0.5172744393348694\n",
            "epoch 81 iter 21 loss=0.42761552333831787\n",
            "epoch 81 iter 22 loss=0.2978628873825073\n",
            "epoch 81 iter 23 loss=0.5261056423187256\n",
            "epoch 81 iter 24 loss=0.27768439054489136\n",
            "epoch 81 iter 25 loss=0.3896735608577728\n",
            "epoch 81 iter 26 loss=0.376002699136734\n",
            "epoch 81 iter 27 loss=0.42907267808914185\n",
            "epoch 81 iter 28 loss=0.34003427624702454\n",
            "epoch 81 iter 29 loss=0.38987112045288086\n",
            "epoch 81 iter 30 loss=0.38122642040252686\n",
            "epoch 81 iter 31 loss=0.34703996777534485\n",
            "epoch 81 iter 32 loss=0.28788089752197266\n",
            "epoch 81 iter 33 loss=0.3651207685470581\n",
            "epoch 81 iter 34 loss=0.3489132225513458\n",
            "epoch 81 iter 35 loss=0.3111943304538727\n",
            "epoch 81 iter 36 loss=0.4065033197402954\n",
            "epoch 81 iter 37 loss=0.34620335698127747\n",
            "epoch 82 iter 0 loss=0.4117128252983093\n",
            "epoch 82 iter 1 loss=0.3767912685871124\n",
            "epoch 82 iter 2 loss=0.39963391423225403\n",
            "epoch 82 iter 3 loss=0.3941824436187744\n",
            "epoch 82 iter 4 loss=0.41085585951805115\n",
            "epoch 82 iter 5 loss=0.3960273861885071\n",
            "epoch 82 iter 6 loss=0.3968890309333801\n",
            "epoch 82 iter 7 loss=0.4403507709503174\n",
            "epoch 82 iter 8 loss=0.3037177324295044\n",
            "epoch 82 iter 9 loss=0.42935651540756226\n",
            "epoch 82 iter 10 loss=0.3492567837238312\n",
            "epoch 82 iter 11 loss=0.31601521372795105\n",
            "epoch 82 iter 12 loss=0.4144555926322937\n",
            "epoch 82 iter 13 loss=0.41845396161079407\n",
            "epoch 82 iter 14 loss=0.40870723128318787\n",
            "epoch 82 iter 15 loss=0.4955463409423828\n",
            "epoch 82 iter 16 loss=0.45704180002212524\n",
            "epoch 82 iter 17 loss=0.2910279631614685\n",
            "epoch 82 iter 18 loss=0.4176236689090729\n",
            "epoch 82 iter 19 loss=0.38925445079803467\n",
            "epoch 82 iter 20 loss=0.38515740633010864\n",
            "epoch 82 iter 21 loss=0.33986276388168335\n",
            "epoch 82 iter 22 loss=0.3196287155151367\n",
            "epoch 82 iter 23 loss=0.3388107717037201\n",
            "epoch 82 iter 24 loss=0.5342863202095032\n",
            "epoch 82 iter 25 loss=0.3017451763153076\n",
            "epoch 82 iter 26 loss=0.3406580090522766\n",
            "epoch 82 iter 27 loss=0.3830346167087555\n",
            "epoch 82 iter 28 loss=0.36255353689193726\n",
            "epoch 82 iter 29 loss=0.3777710199356079\n",
            "epoch 82 iter 30 loss=0.3339727520942688\n",
            "epoch 82 iter 31 loss=0.29823988676071167\n",
            "epoch 82 iter 32 loss=0.3169253170490265\n",
            "epoch 82 iter 33 loss=0.40077129006385803\n",
            "epoch 82 iter 34 loss=0.5236732959747314\n",
            "epoch 82 iter 35 loss=0.517772376537323\n",
            "epoch 82 iter 36 loss=0.3801453709602356\n",
            "epoch 82 iter 37 loss=0.35665929317474365\n",
            "epoch 83 iter 0 loss=0.4813074767589569\n",
            "epoch 83 iter 1 loss=0.38174983859062195\n",
            "epoch 83 iter 2 loss=0.5191740989685059\n",
            "epoch 83 iter 3 loss=0.43569719791412354\n",
            "epoch 83 iter 4 loss=0.3218580484390259\n",
            "epoch 83 iter 5 loss=0.37378039956092834\n",
            "epoch 83 iter 6 loss=0.6513004899024963\n",
            "epoch 83 iter 7 loss=0.3057836592197418\n",
            "epoch 83 iter 8 loss=0.4847060739994049\n",
            "epoch 83 iter 9 loss=0.30031147599220276\n",
            "epoch 83 iter 10 loss=0.3435671329498291\n",
            "epoch 83 iter 11 loss=0.337828129529953\n",
            "epoch 83 iter 12 loss=0.48852506279945374\n",
            "epoch 83 iter 13 loss=0.503894031047821\n",
            "epoch 83 iter 14 loss=0.372186541557312\n",
            "epoch 83 iter 15 loss=0.3556137681007385\n",
            "epoch 83 iter 16 loss=0.3667726218700409\n",
            "epoch 83 iter 17 loss=0.49659788608551025\n",
            "epoch 83 iter 18 loss=0.3611767590045929\n",
            "epoch 83 iter 19 loss=0.5122307538986206\n",
            "epoch 83 iter 20 loss=0.5244200825691223\n",
            "epoch 83 iter 21 loss=0.3699386417865753\n",
            "epoch 83 iter 22 loss=0.35513192415237427\n",
            "epoch 83 iter 23 loss=0.3908485770225525\n",
            "epoch 83 iter 24 loss=0.30884554982185364\n",
            "epoch 83 iter 25 loss=0.41175875067710876\n",
            "epoch 83 iter 26 loss=0.4834134876728058\n",
            "epoch 83 iter 27 loss=0.4179888069629669\n",
            "epoch 83 iter 28 loss=0.4395730793476105\n",
            "epoch 83 iter 29 loss=0.49570029973983765\n",
            "epoch 83 iter 30 loss=0.3446502387523651\n",
            "epoch 83 iter 31 loss=0.49471163749694824\n",
            "epoch 83 iter 32 loss=0.2823270261287689\n",
            "epoch 83 iter 33 loss=0.34485459327697754\n",
            "epoch 83 iter 34 loss=0.4075842499732971\n",
            "epoch 83 iter 35 loss=0.3013788163661957\n",
            "epoch 83 iter 36 loss=0.33840247988700867\n",
            "epoch 83 iter 37 loss=0.5657471418380737\n",
            "epoch 84 iter 0 loss=0.701599657535553\n",
            "epoch 84 iter 1 loss=0.45814821124076843\n",
            "epoch 84 iter 2 loss=0.5860973000526428\n",
            "epoch 84 iter 3 loss=0.3788781762123108\n",
            "epoch 84 iter 4 loss=0.4774571359157562\n",
            "epoch 84 iter 5 loss=0.42047199606895447\n",
            "epoch 84 iter 6 loss=0.45367157459259033\n",
            "epoch 84 iter 7 loss=0.4657365679740906\n",
            "epoch 84 iter 8 loss=0.6810466647148132\n",
            "epoch 84 iter 9 loss=0.6446704268455505\n",
            "epoch 84 iter 10 loss=0.39725324511528015\n",
            "epoch 84 iter 11 loss=0.5847694277763367\n",
            "epoch 84 iter 12 loss=0.5037035346031189\n",
            "epoch 84 iter 13 loss=0.4706196188926697\n",
            "epoch 84 iter 14 loss=0.5080845355987549\n",
            "epoch 84 iter 15 loss=0.7688413858413696\n",
            "epoch 84 iter 16 loss=0.3212614059448242\n",
            "epoch 84 iter 17 loss=0.40233588218688965\n",
            "epoch 84 iter 18 loss=0.4228442311286926\n",
            "epoch 84 iter 19 loss=0.7363178730010986\n",
            "epoch 84 iter 20 loss=0.6197269558906555\n",
            "epoch 84 iter 21 loss=0.299226850271225\n",
            "epoch 84 iter 22 loss=0.66083824634552\n",
            "epoch 84 iter 23 loss=0.6198593378067017\n",
            "epoch 84 iter 24 loss=0.4635440707206726\n",
            "epoch 84 iter 25 loss=0.5298722386360168\n",
            "epoch 84 iter 26 loss=0.485062837600708\n",
            "epoch 84 iter 27 loss=0.589467465877533\n",
            "epoch 84 iter 28 loss=0.5791171193122864\n",
            "epoch 84 iter 29 loss=0.34257972240448\n",
            "epoch 84 iter 30 loss=0.5877950191497803\n",
            "epoch 84 iter 31 loss=0.37937405705451965\n",
            "epoch 84 iter 32 loss=0.6215968132019043\n",
            "epoch 84 iter 33 loss=0.3917672634124756\n",
            "epoch 84 iter 34 loss=0.4657464027404785\n",
            "epoch 84 iter 35 loss=0.5786587595939636\n",
            "epoch 84 iter 36 loss=0.4254467487335205\n",
            "epoch 84 iter 37 loss=0.28801363706588745\n",
            "epoch 85 iter 0 loss=0.5630401968955994\n",
            "epoch 85 iter 1 loss=0.5320422053337097\n",
            "epoch 85 iter 2 loss=0.35579854249954224\n",
            "epoch 85 iter 3 loss=0.38230377435684204\n",
            "epoch 85 iter 4 loss=0.3839612305164337\n",
            "epoch 85 iter 5 loss=0.4347500801086426\n",
            "epoch 85 iter 6 loss=0.39170968532562256\n",
            "epoch 85 iter 7 loss=0.3616516590118408\n",
            "epoch 85 iter 8 loss=0.3932599127292633\n",
            "epoch 85 iter 9 loss=0.477163702249527\n",
            "epoch 85 iter 10 loss=0.4106764495372772\n",
            "epoch 85 iter 11 loss=0.5245366096496582\n",
            "epoch 85 iter 12 loss=0.6998233199119568\n",
            "epoch 85 iter 13 loss=0.45195767283439636\n",
            "epoch 85 iter 14 loss=0.2775622606277466\n",
            "epoch 85 iter 15 loss=0.37124648690223694\n",
            "epoch 85 iter 16 loss=0.3626496493816376\n",
            "epoch 85 iter 17 loss=0.37892118096351624\n",
            "epoch 85 iter 18 loss=0.43121808767318726\n",
            "epoch 85 iter 19 loss=0.3323676288127899\n",
            "epoch 85 iter 20 loss=0.4414162039756775\n",
            "epoch 85 iter 21 loss=0.41946548223495483\n",
            "epoch 85 iter 22 loss=0.44491854310035706\n",
            "epoch 85 iter 23 loss=0.3771252930164337\n",
            "epoch 85 iter 24 loss=0.37963467836380005\n",
            "epoch 85 iter 25 loss=0.37736642360687256\n",
            "epoch 85 iter 26 loss=0.3760948181152344\n",
            "epoch 85 iter 27 loss=0.3373354375362396\n",
            "epoch 85 iter 28 loss=0.6446222066879272\n",
            "epoch 85 iter 29 loss=0.30406126379966736\n",
            "epoch 85 iter 30 loss=0.36010587215423584\n",
            "epoch 85 iter 31 loss=0.43031778931617737\n",
            "epoch 85 iter 32 loss=0.4966527819633484\n",
            "epoch 85 iter 33 loss=0.30162692070007324\n",
            "epoch 85 iter 34 loss=0.3789432942867279\n",
            "epoch 85 iter 35 loss=0.4575751721858978\n",
            "epoch 85 iter 36 loss=0.339706152677536\n",
            "epoch 85 iter 37 loss=0.2715228199958801\n",
            "epoch 86 iter 0 loss=0.5150352120399475\n",
            "epoch 86 iter 1 loss=0.38454821705818176\n",
            "epoch 86 iter 2 loss=0.39814871549606323\n",
            "epoch 86 iter 3 loss=0.3055930435657501\n",
            "epoch 86 iter 4 loss=0.3219825327396393\n",
            "epoch 86 iter 5 loss=0.3310658633708954\n",
            "epoch 86 iter 6 loss=0.47351858019828796\n",
            "epoch 86 iter 7 loss=0.34941259026527405\n",
            "epoch 86 iter 8 loss=0.42139771580696106\n",
            "epoch 86 iter 9 loss=0.36614006757736206\n",
            "epoch 86 iter 10 loss=0.3874516785144806\n",
            "epoch 86 iter 11 loss=0.42899438738822937\n",
            "epoch 86 iter 12 loss=0.33149224519729614\n",
            "epoch 86 iter 13 loss=0.3994912803173065\n",
            "epoch 86 iter 14 loss=0.3766999840736389\n",
            "epoch 86 iter 15 loss=0.35358574986457825\n",
            "epoch 86 iter 16 loss=0.5821724534034729\n",
            "epoch 86 iter 17 loss=0.3332042992115021\n",
            "epoch 86 iter 18 loss=0.34704118967056274\n",
            "epoch 86 iter 19 loss=0.32937338948249817\n",
            "epoch 86 iter 20 loss=0.3986179232597351\n",
            "epoch 86 iter 21 loss=0.35479339957237244\n",
            "epoch 86 iter 22 loss=0.3383757174015045\n",
            "epoch 86 iter 23 loss=0.32550254464149475\n",
            "epoch 86 iter 24 loss=0.4755910038948059\n",
            "epoch 86 iter 25 loss=0.3729053735733032\n",
            "epoch 86 iter 26 loss=0.31119248270988464\n",
            "epoch 86 iter 27 loss=0.43803173303604126\n",
            "epoch 86 iter 28 loss=0.29531946778297424\n",
            "epoch 86 iter 29 loss=0.38972005248069763\n",
            "epoch 86 iter 30 loss=0.4048561453819275\n",
            "epoch 86 iter 31 loss=0.25359153747558594\n",
            "epoch 86 iter 32 loss=0.47122353315353394\n",
            "epoch 86 iter 33 loss=0.36147430539131165\n",
            "epoch 86 iter 34 loss=0.38664090633392334\n",
            "epoch 86 iter 35 loss=0.41877180337905884\n",
            "epoch 86 iter 36 loss=0.4149306118488312\n",
            "epoch 86 iter 37 loss=0.4063095152378082\n",
            "epoch 87 iter 0 loss=0.2717946469783783\n",
            "epoch 87 iter 1 loss=0.30415597558021545\n",
            "epoch 87 iter 2 loss=0.33680641651153564\n",
            "epoch 87 iter 3 loss=0.43830975890159607\n",
            "epoch 87 iter 4 loss=0.29850149154663086\n",
            "epoch 87 iter 5 loss=0.3765050172805786\n",
            "epoch 87 iter 6 loss=0.31966525316238403\n",
            "epoch 87 iter 7 loss=0.3958452343940735\n",
            "epoch 87 iter 8 loss=0.29472243785858154\n",
            "epoch 87 iter 9 loss=0.4245510697364807\n",
            "epoch 87 iter 10 loss=0.2907017469406128\n",
            "epoch 87 iter 11 loss=0.3715951442718506\n",
            "epoch 87 iter 12 loss=0.3213259279727936\n",
            "epoch 87 iter 13 loss=0.300001859664917\n",
            "epoch 87 iter 14 loss=0.2882954776287079\n",
            "epoch 87 iter 15 loss=0.42556533217430115\n",
            "epoch 87 iter 16 loss=0.29861852526664734\n",
            "epoch 87 iter 17 loss=0.39623603224754333\n",
            "epoch 87 iter 18 loss=0.33345356583595276\n",
            "epoch 87 iter 19 loss=0.47004470229148865\n",
            "epoch 87 iter 20 loss=0.3039631247520447\n",
            "epoch 87 iter 21 loss=0.27481213212013245\n",
            "epoch 87 iter 22 loss=0.306206613779068\n",
            "epoch 87 iter 23 loss=0.5606187582015991\n",
            "epoch 87 iter 24 loss=0.4530694782733917\n",
            "epoch 87 iter 25 loss=0.4316197335720062\n",
            "epoch 87 iter 26 loss=0.34768348932266235\n",
            "epoch 87 iter 27 loss=0.3388741612434387\n",
            "epoch 87 iter 28 loss=0.4778052866458893\n",
            "epoch 87 iter 29 loss=0.5035304427146912\n",
            "epoch 87 iter 30 loss=0.34691548347473145\n",
            "epoch 87 iter 31 loss=0.4715134799480438\n",
            "epoch 87 iter 32 loss=0.2350517213344574\n",
            "epoch 87 iter 33 loss=0.3039650619029999\n",
            "epoch 87 iter 34 loss=0.4057704210281372\n",
            "epoch 87 iter 35 loss=0.31202027201652527\n",
            "epoch 87 iter 36 loss=0.359647661447525\n",
            "epoch 87 iter 37 loss=0.38576969504356384\n",
            "epoch 88 iter 0 loss=0.3770316541194916\n",
            "epoch 88 iter 1 loss=0.48458531498908997\n",
            "epoch 88 iter 2 loss=0.34492790699005127\n",
            "epoch 88 iter 3 loss=0.3778999447822571\n",
            "epoch 88 iter 4 loss=0.3306761682033539\n",
            "epoch 88 iter 5 loss=0.42812541127204895\n",
            "epoch 88 iter 6 loss=0.28347018361091614\n",
            "epoch 88 iter 7 loss=0.48142990469932556\n",
            "epoch 88 iter 8 loss=0.36434975266456604\n",
            "epoch 88 iter 9 loss=0.3309422731399536\n",
            "epoch 88 iter 10 loss=0.38043493032455444\n",
            "epoch 88 iter 11 loss=0.30076199769973755\n",
            "epoch 88 iter 12 loss=0.32495734095573425\n",
            "epoch 88 iter 13 loss=0.32982075214385986\n",
            "epoch 88 iter 14 loss=0.2742505371570587\n",
            "epoch 88 iter 15 loss=0.492142915725708\n",
            "epoch 88 iter 16 loss=0.4191177487373352\n",
            "epoch 88 iter 17 loss=0.36595991253852844\n",
            "epoch 88 iter 18 loss=0.3588159680366516\n",
            "epoch 88 iter 19 loss=0.27088162302970886\n",
            "epoch 88 iter 20 loss=0.3350116014480591\n",
            "epoch 88 iter 21 loss=0.30672088265419006\n",
            "epoch 88 iter 22 loss=0.4070183038711548\n",
            "epoch 88 iter 23 loss=0.4348715841770172\n",
            "epoch 88 iter 24 loss=0.3589460253715515\n",
            "epoch 88 iter 25 loss=0.3870164155960083\n",
            "epoch 88 iter 26 loss=0.2390611171722412\n",
            "epoch 88 iter 27 loss=0.31656384468078613\n",
            "epoch 88 iter 28 loss=0.4428674578666687\n",
            "epoch 88 iter 29 loss=0.30433136224746704\n",
            "epoch 88 iter 30 loss=0.2939213514328003\n",
            "epoch 88 iter 31 loss=0.4039172828197479\n",
            "epoch 88 iter 32 loss=0.2708025574684143\n",
            "epoch 88 iter 33 loss=0.47287264466285706\n",
            "epoch 88 iter 34 loss=0.3594192862510681\n",
            "epoch 88 iter 35 loss=0.3795948624610901\n",
            "epoch 88 iter 36 loss=0.30479696393013\n",
            "epoch 88 iter 37 loss=0.43238165974617004\n",
            "epoch 89 iter 0 loss=0.3975367546081543\n",
            "epoch 89 iter 1 loss=0.43799757957458496\n",
            "epoch 89 iter 2 loss=0.3045276701450348\n",
            "epoch 89 iter 3 loss=0.40906819701194763\n",
            "epoch 89 iter 4 loss=0.261804461479187\n",
            "epoch 89 iter 5 loss=0.34149035811424255\n",
            "epoch 89 iter 6 loss=0.3859248161315918\n",
            "epoch 89 iter 7 loss=0.3683653175830841\n",
            "epoch 89 iter 8 loss=0.4420660734176636\n",
            "epoch 89 iter 9 loss=0.35951757431030273\n",
            "epoch 89 iter 10 loss=0.37760627269744873\n",
            "epoch 89 iter 11 loss=0.35101521015167236\n",
            "epoch 89 iter 12 loss=0.3492090106010437\n",
            "epoch 89 iter 13 loss=0.35234129428863525\n",
            "epoch 89 iter 14 loss=0.3720662593841553\n",
            "epoch 89 iter 15 loss=0.2625029981136322\n",
            "epoch 89 iter 16 loss=0.35450780391693115\n",
            "epoch 89 iter 17 loss=0.38523414731025696\n",
            "epoch 89 iter 18 loss=0.43756645917892456\n",
            "epoch 89 iter 19 loss=0.3452560305595398\n",
            "epoch 89 iter 20 loss=0.3415301442146301\n",
            "epoch 89 iter 21 loss=0.29451075196266174\n",
            "epoch 89 iter 22 loss=0.394927054643631\n",
            "epoch 89 iter 23 loss=0.5241779685020447\n",
            "epoch 89 iter 24 loss=0.4062705636024475\n",
            "epoch 89 iter 25 loss=0.34386277198791504\n",
            "epoch 89 iter 26 loss=0.47864314913749695\n",
            "epoch 89 iter 27 loss=0.2932520806789398\n",
            "epoch 89 iter 28 loss=0.2744397819042206\n",
            "epoch 89 iter 29 loss=0.3179061710834503\n",
            "epoch 89 iter 30 loss=0.355253666639328\n",
            "epoch 89 iter 31 loss=0.30549031496047974\n",
            "epoch 89 iter 32 loss=0.3224618434906006\n",
            "epoch 89 iter 33 loss=0.36572694778442383\n",
            "epoch 89 iter 34 loss=0.3150201141834259\n",
            "epoch 89 iter 35 loss=0.3337976634502411\n",
            "epoch 89 iter 36 loss=0.37601882219314575\n",
            "epoch 89 iter 37 loss=0.5661971569061279\n",
            "epoch 90 iter 0 loss=0.2722698748111725\n",
            "epoch 90 iter 1 loss=0.27444735169410706\n",
            "epoch 90 iter 2 loss=0.33439692854881287\n",
            "epoch 90 iter 3 loss=0.28453007340431213\n",
            "epoch 90 iter 4 loss=0.29108065366744995\n",
            "epoch 90 iter 5 loss=0.3044690787792206\n",
            "epoch 90 iter 6 loss=0.3434095084667206\n",
            "epoch 90 iter 7 loss=0.37981224060058594\n",
            "epoch 90 iter 8 loss=0.3804567754268646\n",
            "epoch 90 iter 9 loss=0.310756117105484\n",
            "epoch 90 iter 10 loss=0.339521586894989\n",
            "epoch 90 iter 11 loss=0.32107654213905334\n",
            "epoch 90 iter 12 loss=0.4315163195133209\n",
            "epoch 90 iter 13 loss=0.26779884099960327\n",
            "epoch 90 iter 14 loss=0.3981775641441345\n",
            "epoch 90 iter 15 loss=0.33218738436698914\n",
            "epoch 90 iter 16 loss=0.2862859070301056\n",
            "epoch 90 iter 17 loss=0.3924488425254822\n",
            "epoch 90 iter 18 loss=0.37677234411239624\n",
            "epoch 90 iter 19 loss=0.35656124353408813\n",
            "epoch 90 iter 20 loss=0.45532599091529846\n",
            "epoch 90 iter 21 loss=0.4320262670516968\n",
            "epoch 90 iter 22 loss=0.3363695442676544\n",
            "epoch 90 iter 23 loss=0.3361513912677765\n",
            "epoch 90 iter 24 loss=0.41603535413742065\n",
            "epoch 90 iter 25 loss=0.2784658372402191\n",
            "epoch 90 iter 26 loss=0.3062293827533722\n",
            "epoch 90 iter 27 loss=0.3769318759441376\n",
            "epoch 90 iter 28 loss=0.27676400542259216\n",
            "epoch 90 iter 29 loss=0.29255038499832153\n",
            "epoch 90 iter 30 loss=0.3179692327976227\n",
            "epoch 90 iter 31 loss=0.3912866711616516\n",
            "epoch 90 iter 32 loss=0.38025134801864624\n",
            "epoch 90 iter 33 loss=0.28632259368896484\n",
            "epoch 90 iter 34 loss=0.4360281825065613\n",
            "epoch 90 iter 35 loss=0.3596952557563782\n",
            "epoch 90 iter 36 loss=0.4696972072124481\n",
            "epoch 90 iter 37 loss=0.447763055562973\n",
            "epoch 91 iter 0 loss=0.3334134519100189\n",
            "epoch 91 iter 1 loss=0.42342230677604675\n",
            "epoch 91 iter 2 loss=0.4858914911746979\n",
            "epoch 91 iter 3 loss=0.322990745306015\n",
            "epoch 91 iter 4 loss=0.3517765402793884\n",
            "epoch 91 iter 5 loss=0.399130642414093\n",
            "epoch 91 iter 6 loss=0.33701178431510925\n",
            "epoch 91 iter 7 loss=0.3850080966949463\n",
            "epoch 91 iter 8 loss=0.3150244951248169\n",
            "epoch 91 iter 9 loss=0.3725537955760956\n",
            "epoch 91 iter 10 loss=0.3777267336845398\n",
            "epoch 91 iter 11 loss=0.3164564073085785\n",
            "epoch 91 iter 12 loss=0.27647218108177185\n",
            "epoch 91 iter 13 loss=0.3134480118751526\n",
            "epoch 91 iter 14 loss=0.33211973309516907\n",
            "epoch 91 iter 15 loss=0.29688477516174316\n",
            "epoch 91 iter 16 loss=0.3358151316642761\n",
            "epoch 91 iter 17 loss=0.3495807349681854\n",
            "epoch 91 iter 18 loss=0.2832683324813843\n",
            "epoch 91 iter 19 loss=0.3338596820831299\n",
            "epoch 91 iter 20 loss=0.2977907955646515\n",
            "epoch 91 iter 21 loss=0.35798996686935425\n",
            "epoch 91 iter 22 loss=0.2713247537612915\n",
            "epoch 91 iter 23 loss=0.3809607923030853\n",
            "epoch 91 iter 24 loss=0.4044244885444641\n",
            "epoch 91 iter 25 loss=0.2509063482284546\n",
            "epoch 91 iter 26 loss=0.3613685071468353\n",
            "epoch 91 iter 27 loss=0.5218048691749573\n",
            "epoch 91 iter 28 loss=0.32617852091789246\n",
            "epoch 91 iter 29 loss=0.31349968910217285\n",
            "epoch 91 iter 30 loss=0.3498840928077698\n",
            "epoch 91 iter 31 loss=0.3543345332145691\n",
            "epoch 91 iter 32 loss=0.34390854835510254\n",
            "epoch 91 iter 33 loss=0.3032083213329315\n",
            "epoch 91 iter 34 loss=0.3647046685218811\n",
            "epoch 91 iter 35 loss=0.35329124331474304\n",
            "epoch 91 iter 36 loss=0.2630541920661926\n",
            "epoch 91 iter 37 loss=0.26704901456832886\n",
            "epoch 92 iter 0 loss=0.3540952503681183\n",
            "epoch 92 iter 1 loss=0.3500808775424957\n",
            "epoch 92 iter 2 loss=0.3081417977809906\n",
            "epoch 92 iter 3 loss=0.2953200340270996\n",
            "epoch 92 iter 4 loss=0.25197136402130127\n",
            "epoch 92 iter 5 loss=0.3561559021472931\n",
            "epoch 92 iter 6 loss=0.36655113101005554\n",
            "epoch 92 iter 7 loss=0.33192551136016846\n",
            "epoch 92 iter 8 loss=0.377496600151062\n",
            "epoch 92 iter 9 loss=0.2688533663749695\n",
            "epoch 92 iter 10 loss=0.42572250962257385\n",
            "epoch 92 iter 11 loss=0.3375057876110077\n",
            "epoch 92 iter 12 loss=0.41868045926094055\n",
            "epoch 92 iter 13 loss=0.3173569440841675\n",
            "epoch 92 iter 14 loss=0.3826632499694824\n",
            "epoch 92 iter 15 loss=0.4378502368927002\n",
            "epoch 92 iter 16 loss=0.37823057174682617\n",
            "epoch 92 iter 17 loss=0.33765149116516113\n",
            "epoch 92 iter 18 loss=0.2306084930896759\n",
            "epoch 92 iter 19 loss=0.2973247170448303\n",
            "epoch 92 iter 20 loss=0.44777053594589233\n",
            "epoch 92 iter 21 loss=0.4142882823944092\n",
            "epoch 92 iter 22 loss=0.2891719937324524\n",
            "epoch 92 iter 23 loss=0.3634265959262848\n",
            "epoch 92 iter 24 loss=0.27132686972618103\n",
            "epoch 92 iter 25 loss=0.40181952714920044\n",
            "epoch 92 iter 26 loss=0.36600446701049805\n",
            "epoch 92 iter 27 loss=0.34034717082977295\n",
            "epoch 92 iter 28 loss=0.30375340580940247\n",
            "epoch 92 iter 29 loss=0.38347408175468445\n",
            "epoch 92 iter 30 loss=0.3097154498100281\n",
            "epoch 92 iter 31 loss=0.3976708948612213\n",
            "epoch 92 iter 32 loss=0.44678375124931335\n",
            "epoch 92 iter 33 loss=0.3031700849533081\n",
            "epoch 92 iter 34 loss=0.27055463194847107\n",
            "epoch 92 iter 35 loss=0.3448072075843811\n",
            "epoch 92 iter 36 loss=0.3671354055404663\n",
            "epoch 92 iter 37 loss=0.2706816494464874\n",
            "epoch 93 iter 0 loss=0.32800257205963135\n",
            "epoch 93 iter 1 loss=0.23010562360286713\n",
            "epoch 93 iter 2 loss=0.3073205053806305\n",
            "epoch 93 iter 3 loss=0.32135120034217834\n",
            "epoch 93 iter 4 loss=0.30314400792121887\n",
            "epoch 93 iter 5 loss=0.3712657690048218\n",
            "epoch 93 iter 6 loss=0.2755875885486603\n",
            "epoch 93 iter 7 loss=0.3039194643497467\n",
            "epoch 93 iter 8 loss=0.3207084834575653\n",
            "epoch 93 iter 9 loss=0.3156576156616211\n",
            "epoch 93 iter 10 loss=0.28268560767173767\n",
            "epoch 93 iter 11 loss=0.303598016500473\n",
            "epoch 93 iter 12 loss=0.29672250151634216\n",
            "epoch 93 iter 13 loss=0.4114696979522705\n",
            "epoch 93 iter 14 loss=0.37978342175483704\n",
            "epoch 93 iter 15 loss=0.3653222322463989\n",
            "epoch 93 iter 16 loss=0.3840256929397583\n",
            "epoch 93 iter 17 loss=0.2913200855255127\n",
            "epoch 93 iter 18 loss=0.3266511559486389\n",
            "epoch 93 iter 19 loss=0.3557198941707611\n",
            "epoch 93 iter 20 loss=0.2980981767177582\n",
            "epoch 93 iter 21 loss=0.36035045981407166\n",
            "epoch 93 iter 22 loss=0.3139791786670685\n",
            "epoch 93 iter 23 loss=0.3929402828216553\n",
            "epoch 93 iter 24 loss=0.2888123393058777\n",
            "epoch 93 iter 25 loss=0.30104193091392517\n",
            "epoch 93 iter 26 loss=0.5180982947349548\n",
            "epoch 93 iter 27 loss=0.3352021276950836\n",
            "epoch 93 iter 28 loss=0.45910242199897766\n",
            "epoch 93 iter 29 loss=0.3051411211490631\n",
            "epoch 93 iter 30 loss=0.33464524149894714\n",
            "epoch 93 iter 31 loss=0.6398186683654785\n",
            "epoch 93 iter 32 loss=0.4068843722343445\n",
            "epoch 93 iter 33 loss=0.3613542914390564\n",
            "epoch 93 iter 34 loss=0.383794367313385\n",
            "epoch 93 iter 35 loss=0.33876773715019226\n",
            "epoch 93 iter 36 loss=0.42994165420532227\n",
            "epoch 93 iter 37 loss=0.3479052484035492\n",
            "epoch 94 iter 0 loss=0.4014282524585724\n",
            "epoch 94 iter 1 loss=0.2656429409980774\n",
            "epoch 94 iter 2 loss=0.3419433832168579\n",
            "epoch 94 iter 3 loss=0.44605737924575806\n",
            "epoch 94 iter 4 loss=0.3969583809375763\n",
            "epoch 94 iter 5 loss=0.44067317247390747\n",
            "epoch 94 iter 6 loss=0.40115511417388916\n",
            "epoch 94 iter 7 loss=0.3214431405067444\n",
            "epoch 94 iter 8 loss=0.4191114604473114\n",
            "epoch 94 iter 9 loss=0.390749454498291\n",
            "epoch 94 iter 10 loss=0.29631271958351135\n",
            "epoch 94 iter 11 loss=0.4727882146835327\n",
            "epoch 94 iter 12 loss=0.3699234127998352\n",
            "epoch 94 iter 13 loss=0.32277101278305054\n",
            "epoch 94 iter 14 loss=0.2751249372959137\n",
            "epoch 94 iter 15 loss=0.42130449414253235\n",
            "epoch 94 iter 16 loss=0.35049009323120117\n",
            "epoch 94 iter 17 loss=0.3693414628505707\n",
            "epoch 94 iter 18 loss=0.34224238991737366\n",
            "epoch 94 iter 19 loss=0.3352658748626709\n",
            "epoch 94 iter 20 loss=0.3387093245983124\n",
            "epoch 94 iter 21 loss=0.43945038318634033\n",
            "epoch 94 iter 22 loss=0.31174394488334656\n",
            "epoch 94 iter 23 loss=0.30032670497894287\n",
            "epoch 94 iter 24 loss=0.3252638578414917\n",
            "epoch 94 iter 25 loss=0.36327043175697327\n",
            "epoch 94 iter 26 loss=0.3065599799156189\n",
            "epoch 94 iter 27 loss=0.32027578353881836\n",
            "epoch 94 iter 28 loss=0.29987382888793945\n",
            "epoch 94 iter 29 loss=0.3155278265476227\n",
            "epoch 94 iter 30 loss=0.3367159962654114\n",
            "epoch 94 iter 31 loss=0.3961748480796814\n",
            "epoch 94 iter 32 loss=0.2780384421348572\n",
            "epoch 94 iter 33 loss=0.43238335847854614\n",
            "epoch 94 iter 34 loss=0.30915695428848267\n",
            "epoch 94 iter 35 loss=0.25703132152557373\n",
            "epoch 94 iter 36 loss=0.4596976637840271\n",
            "epoch 94 iter 37 loss=0.3494992256164551\n",
            "epoch 95 iter 0 loss=0.26544666290283203\n",
            "epoch 95 iter 1 loss=0.3265596628189087\n",
            "epoch 95 iter 2 loss=0.3273446559906006\n",
            "epoch 95 iter 3 loss=0.31845834851264954\n",
            "epoch 95 iter 4 loss=0.24091805517673492\n",
            "epoch 95 iter 5 loss=0.3898717164993286\n",
            "epoch 95 iter 6 loss=0.34803012013435364\n",
            "epoch 95 iter 7 loss=0.30023181438446045\n",
            "epoch 95 iter 8 loss=0.3693043291568756\n",
            "epoch 95 iter 9 loss=0.30368438363075256\n",
            "epoch 95 iter 10 loss=0.40457043051719666\n",
            "epoch 95 iter 11 loss=0.30769482254981995\n",
            "epoch 95 iter 12 loss=0.3771127164363861\n",
            "epoch 95 iter 13 loss=0.34977737069129944\n",
            "epoch 95 iter 14 loss=0.2811697721481323\n",
            "epoch 95 iter 15 loss=0.2906193137168884\n",
            "epoch 95 iter 16 loss=0.2799641788005829\n",
            "epoch 95 iter 17 loss=0.29870864748954773\n",
            "epoch 95 iter 18 loss=0.27875810861587524\n",
            "epoch 95 iter 19 loss=0.35023564100265503\n",
            "epoch 95 iter 20 loss=0.34999197721481323\n",
            "epoch 95 iter 21 loss=0.40174949169158936\n",
            "epoch 95 iter 22 loss=0.2909708023071289\n",
            "epoch 95 iter 23 loss=0.3301233947277069\n",
            "epoch 95 iter 24 loss=0.32228994369506836\n",
            "epoch 95 iter 25 loss=0.3520946204662323\n",
            "epoch 95 iter 26 loss=0.32599952816963196\n",
            "epoch 95 iter 27 loss=0.33143338561058044\n",
            "epoch 95 iter 28 loss=0.29099515080451965\n",
            "epoch 95 iter 29 loss=0.29944106936454773\n",
            "epoch 95 iter 30 loss=0.34756866097450256\n",
            "epoch 95 iter 31 loss=0.41327837109565735\n",
            "epoch 95 iter 32 loss=0.3678789734840393\n",
            "epoch 95 iter 33 loss=0.2914216220378876\n",
            "epoch 95 iter 34 loss=0.34065842628479004\n",
            "epoch 95 iter 35 loss=0.4118921756744385\n",
            "epoch 95 iter 36 loss=0.2720332741737366\n",
            "epoch 95 iter 37 loss=0.270320326089859\n",
            "epoch 96 iter 0 loss=0.3799600899219513\n",
            "epoch 96 iter 1 loss=0.3712170422077179\n",
            "epoch 96 iter 2 loss=0.3000428080558777\n",
            "epoch 96 iter 3 loss=0.3018029034137726\n",
            "epoch 96 iter 4 loss=0.3201906085014343\n",
            "epoch 96 iter 5 loss=0.29877904057502747\n",
            "epoch 96 iter 6 loss=0.3410073518753052\n",
            "epoch 96 iter 7 loss=0.31419023871421814\n",
            "epoch 96 iter 8 loss=0.31159141659736633\n",
            "epoch 96 iter 9 loss=0.3728242516517639\n",
            "epoch 96 iter 10 loss=0.22005409002304077\n",
            "epoch 96 iter 11 loss=0.2505825161933899\n",
            "epoch 96 iter 12 loss=0.2999117076396942\n",
            "epoch 96 iter 13 loss=0.44213512539863586\n",
            "epoch 96 iter 14 loss=0.22797763347625732\n",
            "epoch 96 iter 15 loss=0.27547603845596313\n",
            "epoch 96 iter 16 loss=0.37832918763160706\n",
            "epoch 96 iter 17 loss=0.3499079942703247\n",
            "epoch 96 iter 18 loss=0.2765360474586487\n",
            "epoch 96 iter 19 loss=0.27583613991737366\n",
            "epoch 96 iter 20 loss=0.3053106367588043\n",
            "epoch 96 iter 21 loss=0.36271700263023376\n",
            "epoch 96 iter 22 loss=0.3257129490375519\n",
            "epoch 96 iter 23 loss=0.29928988218307495\n",
            "epoch 96 iter 24 loss=0.304969847202301\n",
            "epoch 96 iter 25 loss=0.4417775273323059\n",
            "epoch 96 iter 26 loss=0.3152656853199005\n",
            "epoch 96 iter 27 loss=0.29167497158050537\n",
            "epoch 96 iter 28 loss=0.33104974031448364\n",
            "epoch 96 iter 29 loss=0.35501083731651306\n",
            "epoch 96 iter 30 loss=0.276439368724823\n",
            "epoch 96 iter 31 loss=0.31768810749053955\n",
            "epoch 96 iter 32 loss=0.4157367944717407\n",
            "epoch 96 iter 33 loss=0.23782402276992798\n",
            "epoch 96 iter 34 loss=0.3677994906902313\n",
            "epoch 96 iter 35 loss=0.3138303756713867\n",
            "epoch 96 iter 36 loss=0.3892498314380646\n",
            "epoch 96 iter 37 loss=0.38749372959136963\n",
            "epoch 97 iter 0 loss=0.33737024664878845\n",
            "epoch 97 iter 1 loss=0.30865025520324707\n",
            "epoch 97 iter 2 loss=0.3230000138282776\n",
            "epoch 97 iter 3 loss=0.2801165282726288\n",
            "epoch 97 iter 4 loss=0.25719696283340454\n",
            "epoch 97 iter 5 loss=0.33437636494636536\n",
            "epoch 97 iter 6 loss=0.3394915461540222\n",
            "epoch 97 iter 7 loss=0.24458563327789307\n",
            "epoch 97 iter 8 loss=0.24998252093791962\n",
            "epoch 97 iter 9 loss=0.3145187795162201\n",
            "epoch 97 iter 10 loss=0.31889286637306213\n",
            "epoch 97 iter 11 loss=0.2655360698699951\n",
            "epoch 97 iter 12 loss=0.364071249961853\n",
            "epoch 97 iter 13 loss=0.3913629651069641\n",
            "epoch 97 iter 14 loss=0.2794218063354492\n",
            "epoch 97 iter 15 loss=0.46159619092941284\n",
            "epoch 97 iter 16 loss=0.4521912634372711\n",
            "epoch 97 iter 17 loss=0.29803746938705444\n",
            "epoch 97 iter 18 loss=0.32865461707115173\n",
            "epoch 97 iter 19 loss=0.33501216769218445\n",
            "epoch 97 iter 20 loss=0.37776902318000793\n",
            "epoch 97 iter 21 loss=0.29377031326293945\n",
            "epoch 97 iter 22 loss=0.3894614279270172\n",
            "epoch 97 iter 23 loss=0.26995521783828735\n",
            "epoch 97 iter 24 loss=0.28854721784591675\n",
            "epoch 97 iter 25 loss=0.41774219274520874\n",
            "epoch 97 iter 26 loss=0.3470543622970581\n",
            "epoch 97 iter 27 loss=0.3152022957801819\n",
            "epoch 97 iter 28 loss=0.30568355321884155\n",
            "epoch 97 iter 29 loss=0.3029075860977173\n",
            "epoch 97 iter 30 loss=0.3725709319114685\n",
            "epoch 97 iter 31 loss=0.365909606218338\n",
            "epoch 97 iter 32 loss=0.3278811275959015\n",
            "epoch 97 iter 33 loss=0.26111045479774475\n",
            "epoch 97 iter 34 loss=0.31336432695388794\n",
            "epoch 97 iter 35 loss=0.36487877368927\n",
            "epoch 97 iter 36 loss=0.27595868706703186\n",
            "epoch 97 iter 37 loss=0.20958182215690613\n",
            "epoch 98 iter 0 loss=0.2932555079460144\n",
            "epoch 98 iter 1 loss=0.34085872769355774\n",
            "epoch 98 iter 2 loss=0.30118370056152344\n",
            "epoch 98 iter 3 loss=0.36664658784866333\n",
            "epoch 98 iter 4 loss=0.32777389883995056\n",
            "epoch 98 iter 5 loss=0.3023031949996948\n",
            "epoch 98 iter 6 loss=0.32524457573890686\n",
            "epoch 98 iter 7 loss=0.3213980495929718\n",
            "epoch 98 iter 8 loss=0.3677573502063751\n",
            "epoch 98 iter 9 loss=0.3312438428401947\n",
            "epoch 98 iter 10 loss=0.2315145581960678\n",
            "epoch 98 iter 11 loss=0.30636245012283325\n",
            "epoch 98 iter 12 loss=0.3613310158252716\n",
            "epoch 98 iter 13 loss=0.30036264657974243\n",
            "epoch 98 iter 14 loss=0.40981656312942505\n",
            "epoch 98 iter 15 loss=0.3905474841594696\n",
            "epoch 98 iter 16 loss=0.2897697687149048\n",
            "epoch 98 iter 17 loss=0.29122284054756165\n",
            "epoch 98 iter 18 loss=0.33092501759529114\n",
            "epoch 98 iter 19 loss=0.3489713966846466\n",
            "epoch 98 iter 20 loss=0.36616238951683044\n",
            "epoch 98 iter 21 loss=0.3381699025630951\n",
            "epoch 98 iter 22 loss=0.2881389856338501\n",
            "epoch 98 iter 23 loss=0.32175466418266296\n",
            "epoch 98 iter 24 loss=0.3623494505882263\n",
            "epoch 98 iter 25 loss=0.33657678961753845\n",
            "epoch 98 iter 26 loss=0.3369433879852295\n",
            "epoch 98 iter 27 loss=0.2917034327983856\n",
            "epoch 98 iter 28 loss=0.3643251061439514\n",
            "epoch 98 iter 29 loss=0.3891550600528717\n",
            "epoch 98 iter 30 loss=0.37805259227752686\n",
            "epoch 98 iter 31 loss=0.28031808137893677\n",
            "epoch 98 iter 32 loss=0.3266594111919403\n",
            "epoch 98 iter 33 loss=0.30531981587409973\n",
            "epoch 98 iter 34 loss=0.2920974791049957\n",
            "epoch 98 iter 35 loss=0.25744152069091797\n",
            "epoch 98 iter 36 loss=0.40828239917755127\n",
            "epoch 98 iter 37 loss=0.3203094005584717\n",
            "epoch 99 iter 0 loss=0.4049314260482788\n",
            "epoch 99 iter 1 loss=0.30698710680007935\n",
            "epoch 99 iter 2 loss=0.2509375810623169\n",
            "epoch 99 iter 3 loss=0.3240050971508026\n",
            "epoch 99 iter 4 loss=0.32339051365852356\n",
            "epoch 99 iter 5 loss=0.3389281630516052\n",
            "epoch 99 iter 6 loss=0.2264169603586197\n",
            "epoch 99 iter 7 loss=0.32898059487342834\n",
            "epoch 99 iter 8 loss=0.3170221149921417\n",
            "epoch 99 iter 9 loss=0.47167742252349854\n",
            "epoch 99 iter 10 loss=0.3614656329154968\n",
            "epoch 99 iter 11 loss=0.3338507115840912\n",
            "epoch 99 iter 12 loss=0.42140865325927734\n",
            "epoch 99 iter 13 loss=0.3809724748134613\n",
            "epoch 99 iter 14 loss=0.35510489344596863\n",
            "epoch 99 iter 15 loss=0.2924315631389618\n",
            "epoch 99 iter 16 loss=0.48022547364234924\n",
            "epoch 99 iter 17 loss=0.3222748339176178\n",
            "epoch 99 iter 18 loss=0.28157109022140503\n",
            "epoch 99 iter 19 loss=0.2947884500026703\n",
            "epoch 99 iter 20 loss=0.3261314928531647\n",
            "epoch 99 iter 21 loss=0.35616475343704224\n",
            "epoch 99 iter 22 loss=0.2861693501472473\n",
            "epoch 99 iter 23 loss=0.284925639629364\n",
            "epoch 99 iter 24 loss=0.30070745944976807\n",
            "epoch 99 iter 25 loss=0.36613622307777405\n",
            "epoch 99 iter 26 loss=0.35203492641448975\n",
            "epoch 99 iter 27 loss=0.2967302203178406\n",
            "epoch 99 iter 28 loss=0.2968182861804962\n",
            "epoch 99 iter 29 loss=0.29697471857070923\n",
            "epoch 99 iter 30 loss=0.3734726309776306\n",
            "epoch 99 iter 31 loss=0.33889153599739075\n",
            "epoch 99 iter 32 loss=0.2951149642467499\n",
            "epoch 99 iter 33 loss=0.4280726909637451\n",
            "epoch 99 iter 34 loss=0.3398389518260956\n",
            "epoch 99 iter 35 loss=0.3793397545814514\n",
            "epoch 99 iter 36 loss=0.36538270115852356\n",
            "epoch 99 iter 37 loss=0.39199143648147583\n",
            "epoch 100 iter 0 loss=0.3927534818649292\n",
            "epoch 100 iter 1 loss=0.3806573450565338\n",
            "epoch 100 iter 2 loss=0.2623079717159271\n",
            "epoch 100 iter 3 loss=0.35403719544410706\n",
            "epoch 100 iter 4 loss=0.2317839413881302\n",
            "epoch 100 iter 5 loss=0.34058111906051636\n",
            "epoch 100 iter 6 loss=0.3711739480495453\n",
            "epoch 100 iter 7 loss=0.42490965127944946\n",
            "epoch 100 iter 8 loss=0.2985542416572571\n",
            "epoch 100 iter 9 loss=0.318959504365921\n",
            "epoch 100 iter 10 loss=0.3039439916610718\n",
            "epoch 100 iter 11 loss=0.41126203536987305\n",
            "epoch 100 iter 12 loss=0.31579601764678955\n",
            "epoch 100 iter 13 loss=0.2879166007041931\n",
            "epoch 100 iter 14 loss=0.36733025312423706\n",
            "epoch 100 iter 15 loss=0.28744786977767944\n",
            "epoch 100 iter 16 loss=0.21257033944129944\n",
            "epoch 100 iter 17 loss=0.3530809283256531\n",
            "epoch 100 iter 18 loss=0.28228655457496643\n",
            "epoch 100 iter 19 loss=0.3426015377044678\n",
            "epoch 100 iter 20 loss=0.3027483820915222\n",
            "epoch 100 iter 21 loss=0.3322449028491974\n",
            "epoch 100 iter 22 loss=0.29058942198753357\n",
            "epoch 100 iter 23 loss=0.2705787718296051\n",
            "epoch 100 iter 24 loss=0.3538443148136139\n",
            "epoch 100 iter 25 loss=0.5248231291770935\n",
            "epoch 100 iter 26 loss=0.3673485219478607\n",
            "epoch 100 iter 27 loss=0.313367635011673\n",
            "epoch 100 iter 28 loss=0.31524303555488586\n",
            "epoch 100 iter 29 loss=0.3051210939884186\n",
            "epoch 100 iter 30 loss=0.3322896659374237\n",
            "epoch 100 iter 31 loss=0.28097039461135864\n",
            "epoch 100 iter 32 loss=0.2642403841018677\n",
            "epoch 100 iter 33 loss=0.4129962623119354\n",
            "epoch 100 iter 34 loss=0.3951328694820404\n",
            "epoch 100 iter 35 loss=0.2949448823928833\n",
            "epoch 100 iter 36 loss=0.3037244975566864\n",
            "epoch 100 iter 37 loss=0.26824766397476196\n",
            "epoch 101 iter 0 loss=0.28850996494293213\n",
            "epoch 101 iter 1 loss=0.30885395407676697\n",
            "epoch 101 iter 2 loss=0.3869245946407318\n",
            "epoch 101 iter 3 loss=0.3439277708530426\n",
            "epoch 101 iter 4 loss=0.33690980076789856\n",
            "epoch 101 iter 5 loss=0.28793635964393616\n",
            "epoch 101 iter 6 loss=0.44908031821250916\n",
            "epoch 101 iter 7 loss=0.27691665291786194\n",
            "epoch 101 iter 8 loss=0.31729453802108765\n",
            "epoch 101 iter 9 loss=0.30764874815940857\n",
            "epoch 101 iter 10 loss=0.320271372795105\n",
            "epoch 101 iter 11 loss=0.3177837133407593\n",
            "epoch 101 iter 12 loss=0.27595779299736023\n",
            "epoch 101 iter 13 loss=0.39442890882492065\n",
            "epoch 101 iter 14 loss=0.2542087733745575\n",
            "epoch 101 iter 15 loss=0.18860004842281342\n",
            "epoch 101 iter 16 loss=0.24051277339458466\n",
            "epoch 101 iter 17 loss=0.3402034044265747\n",
            "epoch 101 iter 18 loss=0.3249713182449341\n",
            "epoch 101 iter 19 loss=0.2746638059616089\n",
            "epoch 101 iter 20 loss=0.2601410448551178\n",
            "epoch 101 iter 21 loss=0.3747439682483673\n",
            "epoch 101 iter 22 loss=0.35642901062965393\n",
            "epoch 101 iter 23 loss=0.39894288778305054\n",
            "epoch 101 iter 24 loss=0.2521181106567383\n",
            "epoch 101 iter 25 loss=0.2879464030265808\n",
            "epoch 101 iter 26 loss=0.30482378602027893\n",
            "epoch 101 iter 27 loss=0.2905719578266144\n",
            "epoch 101 iter 28 loss=0.26423096656799316\n",
            "epoch 101 iter 29 loss=0.33443206548690796\n",
            "epoch 101 iter 30 loss=0.24477794766426086\n",
            "epoch 101 iter 31 loss=0.26655644178390503\n",
            "epoch 101 iter 32 loss=0.3030242919921875\n",
            "epoch 101 iter 33 loss=0.23874656856060028\n",
            "epoch 101 iter 34 loss=0.29770541191101074\n",
            "epoch 101 iter 35 loss=0.3112516701221466\n",
            "epoch 101 iter 36 loss=0.28113436698913574\n",
            "epoch 101 iter 37 loss=0.45083630084991455\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2704.\n",
            "epoch 102 iter 0 loss=0.269979864358902\n",
            "epoch 102 iter 1 loss=0.3415076434612274\n",
            "epoch 102 iter 2 loss=0.3463837504386902\n",
            "epoch 102 iter 3 loss=0.31389686465263367\n",
            "epoch 102 iter 4 loss=0.32258161902427673\n",
            "epoch 102 iter 5 loss=0.4115857183933258\n",
            "epoch 102 iter 6 loss=0.31088781356811523\n",
            "epoch 102 iter 7 loss=0.3437395989894867\n",
            "epoch 102 iter 8 loss=0.30740049481391907\n",
            "epoch 102 iter 9 loss=0.2838096618652344\n",
            "epoch 102 iter 10 loss=0.3281659781932831\n",
            "epoch 102 iter 11 loss=0.346908837556839\n",
            "epoch 102 iter 12 loss=0.2567824721336365\n",
            "epoch 102 iter 13 loss=0.2735182046890259\n",
            "epoch 102 iter 14 loss=0.3586648106575012\n",
            "epoch 102 iter 15 loss=0.33718591928482056\n",
            "epoch 102 iter 16 loss=0.2915852665901184\n",
            "epoch 102 iter 17 loss=0.2742416262626648\n",
            "epoch 102 iter 18 loss=0.32243263721466064\n",
            "epoch 102 iter 19 loss=0.3012588620185852\n",
            "epoch 102 iter 20 loss=0.24963781237602234\n",
            "epoch 102 iter 21 loss=0.3261740505695343\n",
            "epoch 102 iter 22 loss=0.2722475528717041\n",
            "epoch 102 iter 23 loss=0.2651381492614746\n",
            "epoch 102 iter 24 loss=0.2750224471092224\n",
            "epoch 102 iter 25 loss=0.26244357228279114\n",
            "epoch 102 iter 26 loss=0.32421234250068665\n",
            "epoch 102 iter 27 loss=0.24144276976585388\n",
            "epoch 102 iter 28 loss=0.25376027822494507\n",
            "epoch 102 iter 29 loss=0.38380613923072815\n",
            "epoch 102 iter 30 loss=0.302550345659256\n",
            "epoch 102 iter 31 loss=0.3935603201389313\n",
            "epoch 102 iter 32 loss=0.2800499200820923\n",
            "epoch 102 iter 33 loss=0.3450999855995178\n",
            "epoch 102 iter 34 loss=0.23102973401546478\n",
            "epoch 102 iter 35 loss=0.33677130937576294\n",
            "epoch 102 iter 36 loss=0.3212779462337494\n",
            "epoch 102 iter 37 loss=0.2816491723060608\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2737.\n",
            "epoch 103 iter 0 loss=0.26996925473213196\n",
            "epoch 103 iter 1 loss=0.35297393798828125\n",
            "epoch 103 iter 2 loss=0.24429967999458313\n",
            "epoch 103 iter 3 loss=0.28191184997558594\n",
            "epoch 103 iter 4 loss=0.2751186788082123\n",
            "epoch 103 iter 5 loss=0.27048730850219727\n",
            "epoch 103 iter 6 loss=0.26217442750930786\n",
            "epoch 103 iter 7 loss=0.27944666147232056\n",
            "epoch 103 iter 8 loss=0.3353753983974457\n",
            "epoch 103 iter 9 loss=0.18283355236053467\n",
            "epoch 103 iter 10 loss=0.3673410415649414\n",
            "epoch 103 iter 11 loss=0.30165567994117737\n",
            "epoch 103 iter 12 loss=0.3005180060863495\n",
            "epoch 103 iter 13 loss=0.2695160210132599\n",
            "epoch 103 iter 14 loss=0.27846628427505493\n",
            "epoch 103 iter 15 loss=0.29113438725471497\n",
            "epoch 103 iter 16 loss=0.30865564942359924\n",
            "epoch 103 iter 17 loss=0.38722822070121765\n",
            "epoch 103 iter 18 loss=0.3607090413570404\n",
            "epoch 103 iter 19 loss=0.2652409076690674\n",
            "epoch 103 iter 20 loss=0.20517568290233612\n",
            "epoch 103 iter 21 loss=0.2389300912618637\n",
            "epoch 103 iter 22 loss=0.2432098388671875\n",
            "epoch 103 iter 23 loss=0.3507450520992279\n",
            "epoch 103 iter 24 loss=0.3534983694553375\n",
            "epoch 103 iter 25 loss=0.30955982208251953\n",
            "epoch 103 iter 26 loss=0.3001478612422943\n",
            "epoch 103 iter 27 loss=0.34780213236808777\n",
            "epoch 103 iter 28 loss=0.22823616862297058\n",
            "epoch 103 iter 29 loss=0.2682587802410126\n",
            "epoch 103 iter 30 loss=0.3234339654445648\n",
            "epoch 103 iter 31 loss=0.23909658193588257\n",
            "epoch 103 iter 32 loss=0.28177133202552795\n",
            "epoch 103 iter 33 loss=0.3190538287162781\n",
            "epoch 103 iter 34 loss=0.4912884533405304\n",
            "epoch 103 iter 35 loss=0.3546850085258484\n",
            "epoch 103 iter 36 loss=0.23729044198989868\n",
            "epoch 103 iter 37 loss=0.3729318082332611\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2749.\n",
            "epoch 104 iter 0 loss=0.30047696828842163\n",
            "epoch 104 iter 1 loss=0.2736044228076935\n",
            "epoch 104 iter 2 loss=0.2826842963695526\n",
            "epoch 104 iter 3 loss=0.276919424533844\n",
            "epoch 104 iter 4 loss=0.2735362946987152\n",
            "epoch 104 iter 5 loss=0.3366641700267792\n",
            "epoch 104 iter 6 loss=0.2634294033050537\n",
            "epoch 104 iter 7 loss=0.29077279567718506\n",
            "epoch 104 iter 8 loss=0.27794843912124634\n",
            "epoch 104 iter 9 loss=0.30417194962501526\n",
            "epoch 104 iter 10 loss=0.29691627621650696\n",
            "epoch 104 iter 11 loss=0.30775052309036255\n",
            "epoch 104 iter 12 loss=0.21798451244831085\n",
            "epoch 104 iter 13 loss=0.25827521085739136\n",
            "epoch 104 iter 14 loss=0.3237553536891937\n",
            "epoch 104 iter 15 loss=0.3170512914657593\n",
            "epoch 104 iter 16 loss=0.2895742654800415\n",
            "epoch 104 iter 17 loss=0.22854261100292206\n",
            "epoch 104 iter 18 loss=0.35848385095596313\n",
            "epoch 104 iter 19 loss=0.378473162651062\n",
            "epoch 104 iter 20 loss=0.3570118546485901\n",
            "epoch 104 iter 21 loss=0.23840773105621338\n",
            "epoch 104 iter 22 loss=0.3593410551548004\n",
            "epoch 104 iter 23 loss=0.25955328345298767\n",
            "epoch 104 iter 24 loss=0.24339276552200317\n",
            "epoch 104 iter 25 loss=0.29794254899024963\n",
            "epoch 104 iter 26 loss=0.32892730832099915\n",
            "epoch 104 iter 27 loss=0.37729939818382263\n",
            "epoch 104 iter 28 loss=0.30343055725097656\n",
            "epoch 104 iter 29 loss=0.25306233763694763\n",
            "epoch 104 iter 30 loss=0.36355653405189514\n",
            "epoch 104 iter 31 loss=0.2785479426383972\n",
            "epoch 104 iter 32 loss=0.2716583013534546\n",
            "epoch 104 iter 33 loss=0.23179447650909424\n",
            "epoch 104 iter 34 loss=0.34654033184051514\n",
            "epoch 104 iter 35 loss=0.28583016991615295\n",
            "epoch 104 iter 36 loss=0.30029189586639404\n",
            "epoch 104 iter 37 loss=0.2743827700614929\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2658.\n",
            "epoch 105 iter 0 loss=0.25511813163757324\n",
            "epoch 105 iter 1 loss=0.3568246364593506\n",
            "epoch 105 iter 2 loss=0.2388034164905548\n",
            "epoch 105 iter 3 loss=0.21855218708515167\n",
            "epoch 105 iter 4 loss=0.33490246534347534\n",
            "epoch 105 iter 5 loss=0.25596511363983154\n",
            "epoch 105 iter 6 loss=0.24669532477855682\n",
            "epoch 105 iter 7 loss=0.37594082951545715\n",
            "epoch 105 iter 8 loss=0.3717929720878601\n",
            "epoch 105 iter 9 loss=0.3012702465057373\n",
            "epoch 105 iter 10 loss=0.264965683221817\n",
            "epoch 105 iter 11 loss=0.35771703720092773\n",
            "epoch 105 iter 12 loss=0.3213125765323639\n",
            "epoch 105 iter 13 loss=0.29085418581962585\n",
            "epoch 105 iter 14 loss=0.3443578779697418\n",
            "epoch 105 iter 15 loss=0.31981348991394043\n",
            "epoch 105 iter 16 loss=0.3292902410030365\n",
            "epoch 105 iter 17 loss=0.2799578905105591\n",
            "epoch 105 iter 18 loss=0.3066483736038208\n",
            "epoch 105 iter 19 loss=0.26789793372154236\n",
            "epoch 105 iter 20 loss=0.32441872358322144\n",
            "epoch 105 iter 21 loss=0.3452169597148895\n",
            "epoch 105 iter 22 loss=0.36825066804885864\n",
            "epoch 105 iter 23 loss=0.3290725648403168\n",
            "epoch 105 iter 24 loss=0.3059319257736206\n",
            "epoch 105 iter 25 loss=0.2794612646102905\n",
            "epoch 105 iter 26 loss=0.3425528109073639\n",
            "epoch 105 iter 27 loss=0.32120686769485474\n",
            "epoch 105 iter 28 loss=0.3228923976421356\n",
            "epoch 105 iter 29 loss=0.33588600158691406\n",
            "epoch 105 iter 30 loss=0.38810446858406067\n",
            "epoch 105 iter 31 loss=0.30714625120162964\n",
            "epoch 105 iter 32 loss=0.3235652446746826\n",
            "epoch 105 iter 33 loss=0.20691189169883728\n",
            "epoch 105 iter 34 loss=0.22786979377269745\n",
            "epoch 105 iter 35 loss=0.2761722207069397\n",
            "epoch 105 iter 36 loss=0.36055582761764526\n",
            "epoch 105 iter 37 loss=0.2431493103504181\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2736.\n",
            "epoch 106 iter 0 loss=0.2868143618106842\n",
            "epoch 106 iter 1 loss=0.26316961646080017\n",
            "epoch 106 iter 2 loss=0.27064239978790283\n",
            "epoch 106 iter 3 loss=0.2622344195842743\n",
            "epoch 106 iter 4 loss=0.3023553788661957\n",
            "epoch 106 iter 5 loss=0.34720584750175476\n",
            "epoch 106 iter 6 loss=0.31078284978866577\n",
            "epoch 106 iter 7 loss=0.2807437777519226\n",
            "epoch 106 iter 8 loss=0.25730979442596436\n",
            "epoch 106 iter 9 loss=0.2827351689338684\n",
            "epoch 106 iter 10 loss=0.3019182085990906\n",
            "epoch 106 iter 11 loss=0.29063403606414795\n",
            "epoch 106 iter 12 loss=0.27243828773498535\n",
            "epoch 106 iter 13 loss=0.28988879919052124\n",
            "epoch 106 iter 14 loss=0.2965869605541229\n",
            "epoch 106 iter 15 loss=0.29440292716026306\n",
            "epoch 106 iter 16 loss=0.2415105700492859\n",
            "epoch 106 iter 17 loss=0.3184848427772522\n",
            "epoch 106 iter 18 loss=0.26643580198287964\n",
            "epoch 106 iter 19 loss=0.3280812203884125\n",
            "epoch 106 iter 20 loss=0.3493642508983612\n",
            "epoch 106 iter 21 loss=0.31198325753211975\n",
            "epoch 106 iter 22 loss=0.28084367513656616\n",
            "epoch 106 iter 23 loss=0.3272864520549774\n",
            "epoch 106 iter 24 loss=0.33739057183265686\n",
            "epoch 106 iter 25 loss=0.30677375197410583\n",
            "epoch 106 iter 26 loss=0.27921682596206665\n",
            "epoch 106 iter 27 loss=0.30721327662467957\n",
            "epoch 106 iter 28 loss=0.3338839113712311\n",
            "epoch 106 iter 29 loss=0.24088072776794434\n",
            "epoch 106 iter 30 loss=0.20737029612064362\n",
            "epoch 106 iter 31 loss=0.22959370911121368\n",
            "epoch 106 iter 32 loss=0.2981127202510834\n",
            "epoch 106 iter 33 loss=0.29789698123931885\n",
            "epoch 106 iter 34 loss=0.2799642086029053\n",
            "epoch 106 iter 35 loss=0.37326720356941223\n",
            "epoch 106 iter 36 loss=0.3149590790271759\n",
            "epoch 106 iter 37 loss=0.32348906993865967\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2729.\n",
            "epoch 107 iter 0 loss=0.2710918188095093\n",
            "epoch 107 iter 1 loss=0.32613223791122437\n",
            "epoch 107 iter 2 loss=0.21891926229000092\n",
            "epoch 107 iter 3 loss=0.35997840762138367\n",
            "epoch 107 iter 4 loss=0.28053018450737\n",
            "epoch 107 iter 5 loss=0.3000265061855316\n",
            "epoch 107 iter 6 loss=0.2397233098745346\n",
            "epoch 107 iter 7 loss=0.2472536414861679\n",
            "epoch 107 iter 8 loss=0.33139967918395996\n",
            "epoch 107 iter 9 loss=0.3789622485637665\n",
            "epoch 107 iter 10 loss=0.2908780574798584\n",
            "epoch 107 iter 11 loss=0.28628742694854736\n",
            "epoch 107 iter 12 loss=0.3079584538936615\n",
            "epoch 107 iter 13 loss=0.25661352276802063\n",
            "epoch 107 iter 14 loss=0.2759830951690674\n",
            "epoch 107 iter 15 loss=0.2773610055446625\n",
            "epoch 107 iter 16 loss=0.29080930352211\n",
            "epoch 107 iter 17 loss=0.25185179710388184\n",
            "epoch 107 iter 18 loss=0.36958253383636475\n",
            "epoch 107 iter 19 loss=0.3369689881801605\n",
            "epoch 107 iter 20 loss=0.3146660327911377\n",
            "epoch 107 iter 21 loss=0.3020886182785034\n",
            "epoch 107 iter 22 loss=0.3325018584728241\n",
            "epoch 107 iter 23 loss=0.2849331796169281\n",
            "epoch 107 iter 24 loss=0.22684118151664734\n",
            "epoch 107 iter 25 loss=0.2871328592300415\n",
            "epoch 107 iter 26 loss=0.2666054666042328\n",
            "epoch 107 iter 27 loss=0.2722603380680084\n",
            "epoch 107 iter 28 loss=0.21694059669971466\n",
            "epoch 107 iter 29 loss=0.2967444956302643\n",
            "epoch 107 iter 30 loss=0.26997047662734985\n",
            "epoch 107 iter 31 loss=0.2538371980190277\n",
            "epoch 107 iter 32 loss=0.23625938594341278\n",
            "epoch 107 iter 33 loss=0.2526160776615143\n",
            "epoch 107 iter 34 loss=0.3514954745769501\n",
            "epoch 107 iter 35 loss=0.3086985945701599\n",
            "epoch 107 iter 36 loss=0.22706298530101776\n",
            "epoch 107 iter 37 loss=0.26957231760025024\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2680.\n",
            "epoch 108 iter 0 loss=0.33018186688423157\n",
            "epoch 108 iter 1 loss=0.3204137682914734\n",
            "epoch 108 iter 2 loss=0.2648111581802368\n",
            "epoch 108 iter 3 loss=0.2508857846260071\n",
            "epoch 108 iter 4 loss=0.25934967398643494\n",
            "epoch 108 iter 5 loss=0.33103781938552856\n",
            "epoch 108 iter 6 loss=0.34275779128074646\n",
            "epoch 108 iter 7 loss=0.238727867603302\n",
            "epoch 108 iter 8 loss=0.35595953464508057\n",
            "epoch 108 iter 9 loss=0.2114361822605133\n",
            "epoch 108 iter 10 loss=0.28410401940345764\n",
            "epoch 108 iter 11 loss=0.29531070590019226\n",
            "epoch 108 iter 12 loss=0.20196864008903503\n",
            "epoch 108 iter 13 loss=0.26233187317848206\n",
            "epoch 108 iter 14 loss=0.2817239463329315\n",
            "epoch 108 iter 15 loss=0.2101188749074936\n",
            "epoch 108 iter 16 loss=0.25479423999786377\n",
            "epoch 108 iter 17 loss=0.25226694345474243\n",
            "epoch 108 iter 18 loss=0.3217364549636841\n",
            "epoch 108 iter 19 loss=0.241165891289711\n",
            "epoch 108 iter 20 loss=0.3211914896965027\n",
            "epoch 108 iter 21 loss=0.2646104097366333\n",
            "epoch 108 iter 22 loss=0.3230302631855011\n",
            "epoch 108 iter 23 loss=0.26444512605667114\n",
            "epoch 108 iter 24 loss=0.3081723749637604\n",
            "epoch 108 iter 25 loss=0.3100633919239044\n",
            "epoch 108 iter 26 loss=0.29195496439933777\n",
            "epoch 108 iter 27 loss=0.28555259108543396\n",
            "epoch 108 iter 28 loss=0.22770409286022186\n",
            "epoch 108 iter 29 loss=0.2733239233493805\n",
            "epoch 108 iter 30 loss=0.30161142349243164\n",
            "epoch 108 iter 31 loss=0.23283137381076813\n",
            "epoch 108 iter 32 loss=0.27152755856513977\n",
            "epoch 108 iter 33 loss=0.29905083775520325\n",
            "epoch 108 iter 34 loss=0.3172505497932434\n",
            "epoch 108 iter 35 loss=0.2510998249053955\n",
            "epoch 108 iter 36 loss=0.37148523330688477\n",
            "epoch 108 iter 37 loss=0.2763666808605194\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2654.\n",
            "epoch 109 iter 0 loss=0.2766268849372864\n",
            "epoch 109 iter 1 loss=0.2313707172870636\n",
            "epoch 109 iter 2 loss=0.21661746501922607\n",
            "epoch 109 iter 3 loss=0.25482720136642456\n",
            "epoch 109 iter 4 loss=0.28039291501045227\n",
            "epoch 109 iter 5 loss=0.23246096074581146\n",
            "epoch 109 iter 6 loss=0.22529859840869904\n",
            "epoch 109 iter 7 loss=0.31307679414749146\n",
            "epoch 109 iter 8 loss=0.2920115888118744\n",
            "epoch 109 iter 9 loss=0.3041170537471771\n",
            "epoch 109 iter 10 loss=0.3070715069770813\n",
            "epoch 109 iter 11 loss=0.2927071154117584\n",
            "epoch 109 iter 12 loss=0.308082640171051\n",
            "epoch 109 iter 13 loss=0.2341136336326599\n",
            "epoch 109 iter 14 loss=0.29379183053970337\n",
            "epoch 109 iter 15 loss=0.23824134469032288\n",
            "epoch 109 iter 16 loss=0.27844133973121643\n",
            "epoch 109 iter 17 loss=0.24965932965278625\n",
            "epoch 109 iter 18 loss=0.2969326376914978\n",
            "epoch 109 iter 19 loss=0.32683122158050537\n",
            "epoch 109 iter 20 loss=0.31371644139289856\n",
            "epoch 109 iter 21 loss=0.2899821996688843\n",
            "epoch 109 iter 22 loss=0.33225223422050476\n",
            "epoch 109 iter 23 loss=0.3010806143283844\n",
            "epoch 109 iter 24 loss=0.2960933446884155\n",
            "epoch 109 iter 25 loss=0.307252436876297\n",
            "epoch 109 iter 26 loss=0.26265546679496765\n",
            "epoch 109 iter 27 loss=0.2619917392730713\n",
            "epoch 109 iter 28 loss=0.2784213423728943\n",
            "epoch 109 iter 29 loss=0.267394095659256\n",
            "epoch 109 iter 30 loss=0.30139315128326416\n",
            "epoch 109 iter 31 loss=0.3357483446598053\n",
            "epoch 109 iter 32 loss=0.3427908718585968\n",
            "epoch 109 iter 33 loss=0.22637513279914856\n",
            "epoch 109 iter 34 loss=0.2330152839422226\n",
            "epoch 109 iter 35 loss=0.23584674298763275\n",
            "epoch 109 iter 36 loss=0.32520848512649536\n",
            "epoch 109 iter 37 loss=0.3733326494693756\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2755.\n",
            "epoch 110 iter 0 loss=0.28551775217056274\n",
            "epoch 110 iter 1 loss=0.257182240486145\n",
            "epoch 110 iter 2 loss=0.3419383764266968\n",
            "epoch 110 iter 3 loss=0.3355908691883087\n",
            "epoch 110 iter 4 loss=0.28926071524620056\n",
            "epoch 110 iter 5 loss=0.31651461124420166\n",
            "epoch 110 iter 6 loss=0.27600353956222534\n",
            "epoch 110 iter 7 loss=0.2331390082836151\n",
            "epoch 110 iter 8 loss=0.2869300842285156\n",
            "epoch 110 iter 9 loss=0.3278714120388031\n",
            "epoch 110 iter 10 loss=0.2770906686782837\n",
            "epoch 110 iter 11 loss=0.23619712889194489\n",
            "epoch 110 iter 12 loss=0.24252186715602875\n",
            "epoch 110 iter 13 loss=0.2592785656452179\n",
            "epoch 110 iter 14 loss=0.26732781529426575\n",
            "epoch 110 iter 15 loss=0.25153306126594543\n",
            "epoch 110 iter 16 loss=0.22007949650287628\n",
            "epoch 110 iter 17 loss=0.3167547285556793\n",
            "epoch 110 iter 18 loss=0.2914358079433441\n",
            "epoch 110 iter 19 loss=0.2638934850692749\n",
            "epoch 110 iter 20 loss=0.28811147809028625\n",
            "epoch 110 iter 21 loss=0.27313509583473206\n",
            "epoch 110 iter 22 loss=0.3482697010040283\n",
            "epoch 110 iter 23 loss=0.2729221284389496\n",
            "epoch 110 iter 24 loss=0.32839736342430115\n",
            "epoch 110 iter 25 loss=0.2550775408744812\n",
            "epoch 110 iter 26 loss=0.29138877987861633\n",
            "epoch 110 iter 27 loss=0.2559088170528412\n",
            "epoch 110 iter 28 loss=0.29757386445999146\n",
            "epoch 110 iter 29 loss=0.29239627718925476\n",
            "epoch 110 iter 30 loss=0.27299147844314575\n",
            "epoch 110 iter 31 loss=0.30191540718078613\n",
            "epoch 110 iter 32 loss=0.34136661887168884\n",
            "epoch 110 iter 33 loss=0.254271537065506\n",
            "epoch 110 iter 34 loss=0.24271802604198456\n",
            "epoch 110 iter 35 loss=0.3102303445339203\n",
            "epoch 110 iter 36 loss=0.25171956419944763\n",
            "epoch 110 iter 37 loss=0.20690138638019562\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2725.\n",
            "epoch 111 iter 0 loss=0.32926762104034424\n",
            "epoch 111 iter 1 loss=0.2779906094074249\n",
            "epoch 111 iter 2 loss=0.27504265308380127\n",
            "epoch 111 iter 3 loss=0.2227625846862793\n",
            "epoch 111 iter 4 loss=0.25933483242988586\n",
            "epoch 111 iter 5 loss=0.3601357638835907\n",
            "epoch 111 iter 6 loss=0.270182728767395\n",
            "epoch 111 iter 7 loss=0.24436132609844208\n",
            "epoch 111 iter 8 loss=0.3092516362667084\n",
            "epoch 111 iter 9 loss=0.34094735980033875\n",
            "epoch 111 iter 10 loss=0.21590521931648254\n",
            "epoch 111 iter 11 loss=0.2594057023525238\n",
            "epoch 111 iter 12 loss=0.30486172437667847\n",
            "epoch 111 iter 13 loss=0.2652556598186493\n",
            "epoch 111 iter 14 loss=0.3602021038532257\n",
            "epoch 111 iter 15 loss=0.31591060757637024\n",
            "epoch 111 iter 16 loss=0.27202701568603516\n",
            "epoch 111 iter 17 loss=0.3176459074020386\n",
            "epoch 111 iter 18 loss=0.2647026479244232\n",
            "epoch 111 iter 19 loss=0.26436999440193176\n",
            "epoch 111 iter 20 loss=0.2856598198413849\n",
            "epoch 111 iter 21 loss=0.32930445671081543\n",
            "epoch 111 iter 22 loss=0.3174428641796112\n",
            "epoch 111 iter 23 loss=0.3038442134857178\n",
            "epoch 111 iter 24 loss=0.26520562171936035\n",
            "epoch 111 iter 25 loss=0.28142017126083374\n",
            "epoch 111 iter 26 loss=0.2586667537689209\n",
            "epoch 111 iter 27 loss=0.25489696860313416\n",
            "epoch 111 iter 28 loss=0.27907994389533997\n",
            "epoch 111 iter 29 loss=0.21877561509609222\n",
            "epoch 111 iter 30 loss=0.30515092611312866\n",
            "epoch 111 iter 31 loss=0.24885447323322296\n",
            "epoch 111 iter 32 loss=0.2752586007118225\n",
            "epoch 111 iter 33 loss=0.3176226019859314\n",
            "epoch 111 iter 34 loss=0.3016173243522644\n",
            "epoch 111 iter 35 loss=0.24790939688682556\n",
            "epoch 111 iter 36 loss=0.2832454442977905\n",
            "epoch 111 iter 37 loss=0.2336861938238144\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2678.\n",
            "epoch 112 iter 0 loss=0.29229259490966797\n",
            "epoch 112 iter 1 loss=0.28160446882247925\n",
            "epoch 112 iter 2 loss=0.33437514305114746\n",
            "epoch 112 iter 3 loss=0.3722417652606964\n",
            "epoch 112 iter 4 loss=0.2581229507923126\n",
            "epoch 112 iter 5 loss=0.2800881862640381\n",
            "epoch 112 iter 6 loss=0.27711382508277893\n",
            "epoch 112 iter 7 loss=0.23900435864925385\n",
            "epoch 112 iter 8 loss=0.2470272332429886\n",
            "epoch 112 iter 9 loss=0.2862645983695984\n",
            "epoch 112 iter 10 loss=0.2557511031627655\n",
            "epoch 112 iter 11 loss=0.29477110505104065\n",
            "epoch 112 iter 12 loss=0.26446717977523804\n",
            "epoch 112 iter 13 loss=0.2908441722393036\n",
            "epoch 112 iter 14 loss=0.3282243013381958\n",
            "epoch 112 iter 15 loss=0.3187445402145386\n",
            "epoch 112 iter 16 loss=0.26819926500320435\n",
            "epoch 112 iter 17 loss=0.20854562520980835\n",
            "epoch 112 iter 18 loss=0.2023928016424179\n",
            "epoch 112 iter 19 loss=0.2895345985889435\n",
            "epoch 112 iter 20 loss=0.23980127274990082\n",
            "epoch 112 iter 21 loss=0.27599772810935974\n",
            "epoch 112 iter 22 loss=0.3299976587295532\n",
            "epoch 112 iter 23 loss=0.23239345848560333\n",
            "epoch 112 iter 24 loss=0.24383670091629028\n",
            "epoch 112 iter 25 loss=0.2501905858516693\n",
            "epoch 112 iter 26 loss=0.293573260307312\n",
            "epoch 112 iter 27 loss=0.2575288712978363\n",
            "epoch 112 iter 28 loss=0.31418028473854065\n",
            "epoch 112 iter 29 loss=0.2803483307361603\n",
            "epoch 112 iter 30 loss=0.20813174545764923\n",
            "epoch 112 iter 31 loss=0.3948621153831482\n",
            "epoch 112 iter 32 loss=0.26166582107543945\n",
            "epoch 112 iter 33 loss=0.3141939342021942\n",
            "epoch 112 iter 34 loss=0.308844655752182\n",
            "epoch 112 iter 35 loss=0.2571590840816498\n",
            "epoch 112 iter 36 loss=0.26902732253074646\n",
            "epoch 112 iter 37 loss=0.39131155610084534\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2663.\n",
            "epoch 113 iter 0 loss=0.23534822463989258\n",
            "epoch 113 iter 1 loss=0.1992788314819336\n",
            "epoch 113 iter 2 loss=0.31276828050613403\n",
            "epoch 113 iter 3 loss=0.2601492702960968\n",
            "epoch 113 iter 4 loss=0.24673697352409363\n",
            "epoch 113 iter 5 loss=0.30757302045822144\n",
            "epoch 113 iter 6 loss=0.31999722123146057\n",
            "epoch 113 iter 7 loss=0.22349120676517487\n",
            "epoch 113 iter 8 loss=0.308302640914917\n",
            "epoch 113 iter 9 loss=0.19240836799144745\n",
            "epoch 113 iter 10 loss=0.2554365396499634\n",
            "epoch 113 iter 11 loss=0.3274262249469757\n",
            "epoch 113 iter 12 loss=0.2705468237400055\n",
            "epoch 113 iter 13 loss=0.3112710118293762\n",
            "epoch 113 iter 14 loss=0.25896814465522766\n",
            "epoch 113 iter 15 loss=0.2391907423734665\n",
            "epoch 113 iter 16 loss=0.23349499702453613\n",
            "epoch 113 iter 17 loss=0.3158615231513977\n",
            "epoch 113 iter 18 loss=0.26631075143814087\n",
            "epoch 113 iter 19 loss=0.22182558476924896\n",
            "epoch 113 iter 20 loss=0.3657616376876831\n",
            "epoch 113 iter 21 loss=0.2696984112262726\n",
            "epoch 113 iter 22 loss=0.2780299782752991\n",
            "epoch 113 iter 23 loss=0.241330087184906\n",
            "epoch 113 iter 24 loss=0.271363765001297\n",
            "epoch 113 iter 25 loss=0.32312917709350586\n",
            "epoch 113 iter 26 loss=0.34269195795059204\n",
            "epoch 113 iter 27 loss=0.3363964259624481\n",
            "epoch 113 iter 28 loss=0.29841020703315735\n",
            "epoch 113 iter 29 loss=0.2772887051105499\n",
            "epoch 113 iter 30 loss=0.2839905917644501\n",
            "epoch 113 iter 31 loss=0.26292353868484497\n",
            "epoch 113 iter 32 loss=0.2874968647956848\n",
            "epoch 113 iter 33 loss=0.3136105239391327\n",
            "epoch 113 iter 34 loss=0.26002237200737\n",
            "epoch 113 iter 35 loss=0.2486378699541092\n",
            "epoch 113 iter 36 loss=0.2903628647327423\n",
            "epoch 113 iter 37 loss=0.2951781153678894\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2755.\n",
            "epoch 114 iter 0 loss=0.2694999873638153\n",
            "epoch 114 iter 1 loss=0.30178481340408325\n",
            "epoch 114 iter 2 loss=0.34543633460998535\n",
            "epoch 114 iter 3 loss=0.29504433274269104\n",
            "epoch 114 iter 4 loss=0.2368469089269638\n",
            "epoch 114 iter 5 loss=0.22366581857204437\n",
            "epoch 114 iter 6 loss=0.33917176723480225\n",
            "epoch 114 iter 7 loss=0.17533963918685913\n",
            "epoch 114 iter 8 loss=0.25523075461387634\n",
            "epoch 114 iter 9 loss=0.3198871314525604\n",
            "epoch 114 iter 10 loss=0.27447745203971863\n",
            "epoch 114 iter 11 loss=0.27951928973197937\n",
            "epoch 114 iter 12 loss=0.25327247381210327\n",
            "epoch 114 iter 13 loss=0.21081280708312988\n",
            "epoch 114 iter 14 loss=0.22383704781532288\n",
            "epoch 114 iter 15 loss=0.3288302421569824\n",
            "epoch 114 iter 16 loss=0.23982290923595428\n",
            "epoch 114 iter 17 loss=0.2760363221168518\n",
            "epoch 114 iter 18 loss=0.2758558690547943\n",
            "epoch 114 iter 19 loss=0.3149748742580414\n",
            "epoch 114 iter 20 loss=0.22145399451255798\n",
            "epoch 114 iter 21 loss=0.25287777185440063\n",
            "epoch 114 iter 22 loss=0.2729269862174988\n",
            "epoch 114 iter 23 loss=0.29253631830215454\n",
            "epoch 114 iter 24 loss=0.2614833116531372\n",
            "epoch 114 iter 25 loss=0.296389102935791\n",
            "epoch 114 iter 26 loss=0.21534298360347748\n",
            "epoch 114 iter 27 loss=0.30388978123664856\n",
            "epoch 114 iter 28 loss=0.24251149594783783\n",
            "epoch 114 iter 29 loss=0.18379497528076172\n",
            "epoch 114 iter 30 loss=0.2768296003341675\n",
            "epoch 114 iter 31 loss=0.3458236753940582\n",
            "epoch 114 iter 32 loss=0.2721126675605774\n",
            "epoch 114 iter 33 loss=0.2368207573890686\n",
            "epoch 114 iter 34 loss=0.2820791006088257\n",
            "epoch 114 iter 35 loss=0.3163321018218994\n",
            "epoch 114 iter 36 loss=0.2701888978481293\n",
            "epoch 114 iter 37 loss=0.2621665298938751\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2719.\n",
            "epoch 115 iter 0 loss=0.23006758093833923\n",
            "epoch 115 iter 1 loss=0.21667324006557465\n",
            "epoch 115 iter 2 loss=0.23373274505138397\n",
            "epoch 115 iter 3 loss=0.22316530346870422\n",
            "epoch 115 iter 4 loss=0.29040536284446716\n",
            "epoch 115 iter 5 loss=0.27287739515304565\n",
            "epoch 115 iter 6 loss=0.25604143738746643\n",
            "epoch 115 iter 7 loss=0.34269917011260986\n",
            "epoch 115 iter 8 loss=0.26777079701423645\n",
            "epoch 115 iter 9 loss=0.2704561650753021\n",
            "epoch 115 iter 10 loss=0.24431952834129333\n",
            "epoch 115 iter 11 loss=0.3157215416431427\n",
            "epoch 115 iter 12 loss=0.3121514916419983\n",
            "epoch 115 iter 13 loss=0.26348626613616943\n",
            "epoch 115 iter 14 loss=0.2439272254705429\n",
            "epoch 115 iter 15 loss=0.2650798261165619\n",
            "epoch 115 iter 16 loss=0.22172047197818756\n",
            "epoch 115 iter 17 loss=0.2702142298221588\n",
            "epoch 115 iter 18 loss=0.3195223808288574\n",
            "epoch 115 iter 19 loss=0.28911855816841125\n",
            "epoch 115 iter 20 loss=0.31923866271972656\n",
            "epoch 115 iter 21 loss=0.4627583622932434\n",
            "epoch 115 iter 22 loss=0.21063335239887238\n",
            "epoch 115 iter 23 loss=0.4950697422027588\n",
            "epoch 115 iter 24 loss=0.32060492038726807\n",
            "epoch 115 iter 25 loss=0.4632013142108917\n",
            "epoch 115 iter 26 loss=0.3422079086303711\n",
            "epoch 115 iter 27 loss=0.36538881063461304\n",
            "epoch 115 iter 28 loss=0.35599222779273987\n",
            "epoch 115 iter 29 loss=0.3914589285850525\n",
            "epoch 115 iter 30 loss=0.42397281527519226\n",
            "epoch 115 iter 31 loss=0.3100832402706146\n",
            "epoch 115 iter 32 loss=0.3966059684753418\n",
            "epoch 115 iter 33 loss=0.3277992904186249\n",
            "epoch 115 iter 34 loss=0.32736581563949585\n",
            "epoch 115 iter 35 loss=0.27311238646507263\n",
            "epoch 115 iter 36 loss=0.3066118061542511\n",
            "epoch 115 iter 37 loss=0.5084012150764465\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2613.\n",
            "epoch 116 iter 0 loss=0.41151076555252075\n",
            "epoch 116 iter 1 loss=0.2789745032787323\n",
            "epoch 116 iter 2 loss=0.2630409002304077\n",
            "epoch 116 iter 3 loss=0.256523072719574\n",
            "epoch 116 iter 4 loss=0.3138806223869324\n",
            "epoch 116 iter 5 loss=0.3714706003665924\n",
            "epoch 116 iter 6 loss=0.3396722078323364\n",
            "epoch 116 iter 7 loss=0.3334404230117798\n",
            "epoch 116 iter 8 loss=0.3190632164478302\n",
            "epoch 116 iter 9 loss=0.3430432379245758\n",
            "epoch 116 iter 10 loss=0.46635809540748596\n",
            "epoch 116 iter 11 loss=0.34876549243927\n",
            "epoch 116 iter 12 loss=0.5259274244308472\n",
            "epoch 116 iter 13 loss=0.3371938169002533\n",
            "epoch 116 iter 14 loss=0.34344300627708435\n",
            "epoch 116 iter 15 loss=0.43322646617889404\n",
            "epoch 116 iter 16 loss=0.38819220662117004\n",
            "epoch 116 iter 17 loss=0.290495365858078\n",
            "epoch 116 iter 18 loss=0.3485843241214752\n",
            "epoch 116 iter 19 loss=0.34482502937316895\n",
            "epoch 116 iter 20 loss=0.3858427107334137\n",
            "epoch 116 iter 21 loss=0.34412887692451477\n",
            "epoch 116 iter 22 loss=0.3482949435710907\n",
            "epoch 116 iter 23 loss=0.32547321915626526\n",
            "epoch 116 iter 24 loss=0.3295952379703522\n",
            "epoch 116 iter 25 loss=0.38431087136268616\n",
            "epoch 116 iter 26 loss=0.24507641792297363\n",
            "epoch 116 iter 27 loss=0.34777751564979553\n",
            "epoch 116 iter 28 loss=0.30068841576576233\n",
            "epoch 116 iter 29 loss=0.3628460168838501\n",
            "epoch 116 iter 30 loss=0.3110417425632477\n",
            "epoch 116 iter 31 loss=0.345294326543808\n",
            "epoch 116 iter 32 loss=0.2941843271255493\n",
            "epoch 116 iter 33 loss=0.28197208046913147\n",
            "epoch 116 iter 34 loss=0.33450236916542053\n",
            "epoch 116 iter 35 loss=0.24956102669239044\n",
            "epoch 116 iter 36 loss=0.30732956528663635\n",
            "epoch 116 iter 37 loss=0.2641514837741852\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2734.\n",
            "epoch 117 iter 0 loss=0.36029526591300964\n",
            "epoch 117 iter 1 loss=0.2604207992553711\n",
            "epoch 117 iter 2 loss=0.288945734500885\n",
            "epoch 117 iter 3 loss=0.2827957272529602\n",
            "epoch 117 iter 4 loss=0.2604321539402008\n",
            "epoch 117 iter 5 loss=0.2920131981372833\n",
            "epoch 117 iter 6 loss=0.2824113070964813\n",
            "epoch 117 iter 7 loss=0.2801775336265564\n",
            "epoch 117 iter 8 loss=0.25090405344963074\n",
            "epoch 117 iter 9 loss=0.3089647591114044\n",
            "epoch 117 iter 10 loss=0.26894310116767883\n",
            "epoch 117 iter 11 loss=0.26714903116226196\n",
            "epoch 117 iter 12 loss=0.26959559321403503\n",
            "epoch 117 iter 13 loss=0.2475794404745102\n",
            "epoch 117 iter 14 loss=0.24635225534439087\n",
            "epoch 117 iter 15 loss=0.34558749198913574\n",
            "epoch 117 iter 16 loss=0.32913193106651306\n",
            "epoch 117 iter 17 loss=0.2686826288700104\n",
            "epoch 117 iter 18 loss=0.2525941729545593\n",
            "epoch 117 iter 19 loss=0.25782814621925354\n",
            "epoch 117 iter 20 loss=0.2829676866531372\n",
            "epoch 117 iter 21 loss=0.2616337835788727\n",
            "epoch 117 iter 22 loss=0.3349972367286682\n",
            "epoch 117 iter 23 loss=0.30088135600090027\n",
            "epoch 117 iter 24 loss=0.3172586262226105\n",
            "epoch 117 iter 25 loss=0.23888815939426422\n",
            "epoch 117 iter 26 loss=0.2805076539516449\n",
            "epoch 117 iter 27 loss=0.2912527918815613\n",
            "epoch 117 iter 28 loss=0.3234916031360626\n",
            "epoch 117 iter 29 loss=0.33783888816833496\n",
            "epoch 117 iter 30 loss=0.2844696640968323\n",
            "epoch 117 iter 31 loss=0.3287234306335449\n",
            "epoch 117 iter 32 loss=0.21500985324382782\n",
            "epoch 117 iter 33 loss=0.3593023717403412\n",
            "epoch 117 iter 34 loss=0.23946332931518555\n",
            "epoch 117 iter 35 loss=0.28133150935173035\n",
            "epoch 117 iter 36 loss=0.22170378267765045\n",
            "epoch 117 iter 37 loss=0.25726890563964844\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2688.\n",
            "epoch 118 iter 0 loss=0.20518656075000763\n",
            "epoch 118 iter 1 loss=0.4613686203956604\n",
            "epoch 118 iter 2 loss=0.33893877267837524\n",
            "epoch 118 iter 3 loss=0.21641896665096283\n",
            "epoch 118 iter 4 loss=0.2952880859375\n",
            "epoch 118 iter 5 loss=0.44083335995674133\n",
            "epoch 118 iter 6 loss=0.2776450514793396\n",
            "epoch 118 iter 7 loss=0.2745710015296936\n",
            "epoch 118 iter 8 loss=0.3256742060184479\n",
            "epoch 118 iter 9 loss=0.23484571278095245\n",
            "epoch 118 iter 10 loss=0.2114090770483017\n",
            "epoch 118 iter 11 loss=0.25977373123168945\n",
            "epoch 118 iter 12 loss=0.22177131474018097\n",
            "epoch 118 iter 13 loss=0.22491498291492462\n",
            "epoch 118 iter 14 loss=0.31933921575546265\n",
            "epoch 118 iter 15 loss=0.26879212260246277\n",
            "epoch 118 iter 16 loss=0.20795366168022156\n",
            "epoch 118 iter 17 loss=0.31910285353660583\n",
            "epoch 118 iter 18 loss=0.23101112246513367\n",
            "epoch 118 iter 19 loss=0.32507002353668213\n",
            "epoch 118 iter 20 loss=0.2652775049209595\n",
            "epoch 118 iter 21 loss=0.23682069778442383\n",
            "epoch 118 iter 22 loss=0.3195774257183075\n",
            "epoch 118 iter 23 loss=0.20643001794815063\n",
            "epoch 118 iter 24 loss=0.2724419832229614\n",
            "epoch 118 iter 25 loss=0.2552429735660553\n",
            "epoch 118 iter 26 loss=0.2748745381832123\n",
            "epoch 118 iter 27 loss=0.28606879711151123\n",
            "epoch 118 iter 28 loss=0.2293301373720169\n",
            "epoch 118 iter 29 loss=0.3195361793041229\n",
            "epoch 118 iter 30 loss=0.3018641173839569\n",
            "epoch 118 iter 31 loss=0.26119139790534973\n",
            "epoch 118 iter 32 loss=0.34097719192504883\n",
            "epoch 118 iter 33 loss=0.22547444701194763\n",
            "epoch 118 iter 34 loss=0.30079248547554016\n",
            "epoch 118 iter 35 loss=0.26005905866622925\n",
            "epoch 118 iter 36 loss=0.3135800361633301\n",
            "epoch 118 iter 37 loss=0.26485365629196167\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2741.\n",
            "epoch 119 iter 0 loss=0.23708032071590424\n",
            "epoch 119 iter 1 loss=0.38155850768089294\n",
            "epoch 119 iter 2 loss=0.31836357712745667\n",
            "epoch 119 iter 3 loss=0.19114775955677032\n",
            "epoch 119 iter 4 loss=0.22214818000793457\n",
            "epoch 119 iter 5 loss=0.2809193730354309\n",
            "epoch 119 iter 6 loss=0.2755407392978668\n",
            "epoch 119 iter 7 loss=0.30376091599464417\n",
            "epoch 119 iter 8 loss=0.2105015516281128\n",
            "epoch 119 iter 9 loss=0.2034422904253006\n",
            "epoch 119 iter 10 loss=0.32658007740974426\n",
            "epoch 119 iter 11 loss=0.27352696657180786\n",
            "epoch 119 iter 12 loss=0.31943079829216003\n",
            "epoch 119 iter 13 loss=0.2966861128807068\n",
            "epoch 119 iter 14 loss=0.24084968864917755\n",
            "epoch 119 iter 15 loss=0.2883744537830353\n",
            "epoch 119 iter 16 loss=0.3118450343608856\n",
            "epoch 119 iter 17 loss=0.27645739912986755\n",
            "epoch 119 iter 18 loss=0.25066062808036804\n",
            "epoch 119 iter 19 loss=0.2789400517940521\n",
            "epoch 119 iter 20 loss=0.2786990702152252\n",
            "epoch 119 iter 21 loss=0.29222068190574646\n",
            "epoch 119 iter 22 loss=0.2535552382469177\n",
            "epoch 119 iter 23 loss=0.25159865617752075\n",
            "epoch 119 iter 24 loss=0.32869985699653625\n",
            "epoch 119 iter 25 loss=0.20980192720890045\n",
            "epoch 119 iter 26 loss=0.24871832132339478\n",
            "epoch 119 iter 27 loss=0.22921475768089294\n",
            "epoch 119 iter 28 loss=0.24911415576934814\n",
            "epoch 119 iter 29 loss=0.30453765392303467\n",
            "epoch 119 iter 30 loss=0.28226524591445923\n",
            "epoch 119 iter 31 loss=0.315544992685318\n",
            "epoch 119 iter 32 loss=0.2717936336994171\n",
            "epoch 119 iter 33 loss=0.26611486077308655\n",
            "epoch 119 iter 34 loss=0.19195513427257538\n",
            "epoch 119 iter 35 loss=0.21968229115009308\n",
            "epoch 119 iter 36 loss=0.2007792741060257\n",
            "epoch 119 iter 37 loss=0.19519750773906708\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2725.\n",
            "epoch 120 iter 0 loss=0.28252169489860535\n",
            "epoch 120 iter 1 loss=0.31283897161483765\n",
            "epoch 120 iter 2 loss=0.259808748960495\n",
            "epoch 120 iter 3 loss=0.3083757758140564\n",
            "epoch 120 iter 4 loss=0.3232867121696472\n",
            "epoch 120 iter 5 loss=0.3152286112308502\n",
            "epoch 120 iter 6 loss=0.2580046057701111\n",
            "epoch 120 iter 7 loss=0.300567626953125\n",
            "epoch 120 iter 8 loss=0.3151630163192749\n",
            "epoch 120 iter 9 loss=0.27567094564437866\n",
            "epoch 120 iter 10 loss=0.3364034593105316\n",
            "epoch 120 iter 11 loss=0.3536089360713959\n",
            "epoch 120 iter 12 loss=0.3095802664756775\n",
            "epoch 120 iter 13 loss=0.32354822754859924\n",
            "epoch 120 iter 14 loss=0.33046409487724304\n",
            "epoch 120 iter 15 loss=0.24088384211063385\n",
            "epoch 120 iter 16 loss=0.3068515956401825\n",
            "epoch 120 iter 17 loss=0.30760517716407776\n",
            "epoch 120 iter 18 loss=0.28804317116737366\n",
            "epoch 120 iter 19 loss=0.3356991410255432\n",
            "epoch 120 iter 20 loss=0.2692307233810425\n",
            "epoch 120 iter 21 loss=0.2768004834651947\n",
            "epoch 120 iter 22 loss=0.2515557110309601\n",
            "epoch 120 iter 23 loss=0.2323150932788849\n",
            "epoch 120 iter 24 loss=0.3627542555332184\n",
            "epoch 120 iter 25 loss=0.3219442665576935\n",
            "epoch 120 iter 26 loss=0.2366764098405838\n",
            "epoch 120 iter 27 loss=0.33493006229400635\n",
            "epoch 120 iter 28 loss=0.24211080372333527\n",
            "epoch 120 iter 29 loss=0.2664704918861389\n",
            "epoch 120 iter 30 loss=0.2508556544780731\n",
            "epoch 120 iter 31 loss=0.30353111028671265\n",
            "epoch 120 iter 32 loss=0.2340511530637741\n",
            "epoch 120 iter 33 loss=0.24339105188846588\n",
            "epoch 120 iter 34 loss=0.22155360877513885\n",
            "epoch 120 iter 35 loss=0.2819543778896332\n",
            "epoch 120 iter 36 loss=0.363620787858963\n",
            "epoch 120 iter 37 loss=0.22653645277023315\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2749.\n",
            "epoch 121 iter 0 loss=0.23459942638874054\n",
            "epoch 121 iter 1 loss=0.3214205205440521\n",
            "epoch 121 iter 2 loss=0.24030721187591553\n",
            "epoch 121 iter 3 loss=0.370814710855484\n",
            "epoch 121 iter 4 loss=0.45133671164512634\n",
            "epoch 121 iter 5 loss=0.28931477665901184\n",
            "epoch 121 iter 6 loss=0.40540722012519836\n",
            "epoch 121 iter 7 loss=0.3961035907268524\n",
            "epoch 121 iter 8 loss=0.32640498876571655\n",
            "epoch 121 iter 9 loss=0.37830567359924316\n",
            "epoch 121 iter 10 loss=0.3865625858306885\n",
            "epoch 121 iter 11 loss=0.2810954451560974\n",
            "epoch 121 iter 12 loss=0.29902347922325134\n",
            "epoch 121 iter 13 loss=0.30888041853904724\n",
            "epoch 121 iter 14 loss=0.3867972493171692\n",
            "epoch 121 iter 15 loss=0.4385935664176941\n",
            "epoch 121 iter 16 loss=0.35989058017730713\n",
            "epoch 121 iter 17 loss=0.35653406381607056\n",
            "epoch 121 iter 18 loss=0.3611431419849396\n",
            "epoch 121 iter 19 loss=0.37193062901496887\n",
            "epoch 121 iter 20 loss=0.313773512840271\n",
            "epoch 121 iter 21 loss=0.3002127408981323\n",
            "epoch 121 iter 22 loss=0.3045414984226227\n",
            "epoch 121 iter 23 loss=0.33618536591529846\n",
            "epoch 121 iter 24 loss=0.2950457036495209\n",
            "epoch 121 iter 25 loss=0.5462093353271484\n",
            "epoch 121 iter 26 loss=0.25971198081970215\n",
            "epoch 121 iter 27 loss=0.47239166498184204\n",
            "epoch 121 iter 28 loss=0.289222776889801\n",
            "epoch 121 iter 29 loss=0.3514310419559479\n",
            "epoch 121 iter 30 loss=0.2473558932542801\n",
            "epoch 121 iter 31 loss=0.3212813138961792\n",
            "epoch 121 iter 32 loss=0.352301687002182\n",
            "epoch 121 iter 33 loss=0.2584308981895447\n",
            "epoch 121 iter 34 loss=0.27370935678482056\n",
            "epoch 121 iter 35 loss=0.3938412070274353\n",
            "epoch 121 iter 36 loss=0.2921367883682251\n",
            "epoch 121 iter 37 loss=0.33446747064590454\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2612.\n",
            "epoch 122 iter 0 loss=0.3240174651145935\n",
            "epoch 122 iter 1 loss=0.30243077874183655\n",
            "epoch 122 iter 2 loss=0.3436238169670105\n",
            "epoch 122 iter 3 loss=0.30120378732681274\n",
            "epoch 122 iter 4 loss=0.34793615341186523\n",
            "epoch 122 iter 5 loss=0.25589829683303833\n",
            "epoch 122 iter 6 loss=0.3574199676513672\n",
            "epoch 122 iter 7 loss=0.3979073166847229\n",
            "epoch 122 iter 8 loss=0.2725348174571991\n",
            "epoch 122 iter 9 loss=0.3989383578300476\n",
            "epoch 122 iter 10 loss=0.30914783477783203\n",
            "epoch 122 iter 11 loss=0.2849920392036438\n",
            "epoch 122 iter 12 loss=0.231577530503273\n",
            "epoch 122 iter 13 loss=0.234821155667305\n",
            "epoch 122 iter 14 loss=0.3298374116420746\n",
            "epoch 122 iter 15 loss=0.2760160267353058\n",
            "epoch 122 iter 16 loss=0.29985207319259644\n",
            "epoch 122 iter 17 loss=0.2819027304649353\n",
            "epoch 122 iter 18 loss=0.21001972258090973\n",
            "epoch 122 iter 19 loss=0.2970021665096283\n",
            "epoch 122 iter 20 loss=0.3115071952342987\n",
            "epoch 122 iter 21 loss=0.2536623775959015\n",
            "epoch 122 iter 22 loss=0.3342479169368744\n",
            "epoch 122 iter 23 loss=0.3202747404575348\n",
            "epoch 122 iter 24 loss=0.24571947753429413\n",
            "epoch 122 iter 25 loss=0.2674206793308258\n",
            "epoch 122 iter 26 loss=0.3848182260990143\n",
            "epoch 122 iter 27 loss=0.3005251884460449\n",
            "epoch 122 iter 28 loss=0.3270855247974396\n",
            "epoch 122 iter 29 loss=0.26925623416900635\n",
            "epoch 122 iter 30 loss=0.34799790382385254\n",
            "epoch 122 iter 31 loss=0.33297741413116455\n",
            "epoch 122 iter 32 loss=0.2502298951148987\n",
            "epoch 122 iter 33 loss=0.2916509807109833\n",
            "epoch 122 iter 34 loss=0.28948450088500977\n",
            "epoch 122 iter 35 loss=0.3350054621696472\n",
            "epoch 122 iter 36 loss=0.2961139678955078\n",
            "epoch 122 iter 37 loss=0.25103962421417236\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2672.\n",
            "epoch 123 iter 0 loss=0.2404610812664032\n",
            "epoch 123 iter 1 loss=0.35879021883010864\n",
            "epoch 123 iter 2 loss=0.2900371551513672\n",
            "epoch 123 iter 3 loss=0.26547932624816895\n",
            "epoch 123 iter 4 loss=0.2462872713804245\n",
            "epoch 123 iter 5 loss=0.2006097435951233\n",
            "epoch 123 iter 6 loss=0.3119419813156128\n",
            "epoch 123 iter 7 loss=0.31531256437301636\n",
            "epoch 123 iter 8 loss=0.2591719627380371\n",
            "epoch 123 iter 9 loss=0.3095192313194275\n",
            "epoch 123 iter 10 loss=0.2717197835445404\n",
            "epoch 123 iter 11 loss=0.3134773373603821\n",
            "epoch 123 iter 12 loss=0.19148753583431244\n",
            "epoch 123 iter 13 loss=0.21195408701896667\n",
            "epoch 123 iter 14 loss=0.28941860795021057\n",
            "epoch 123 iter 15 loss=0.233712837100029\n",
            "epoch 123 iter 16 loss=0.24593734741210938\n",
            "epoch 123 iter 17 loss=0.310276061296463\n",
            "epoch 123 iter 18 loss=0.26515302062034607\n",
            "epoch 123 iter 19 loss=0.25900861620903015\n",
            "epoch 123 iter 20 loss=0.24126076698303223\n",
            "epoch 123 iter 21 loss=0.2745554745197296\n",
            "epoch 123 iter 22 loss=0.23798029124736786\n",
            "epoch 123 iter 23 loss=0.2616831958293915\n",
            "epoch 123 iter 24 loss=0.2482278198003769\n",
            "epoch 123 iter 25 loss=0.2872220575809479\n",
            "epoch 123 iter 26 loss=0.23985350131988525\n",
            "epoch 123 iter 27 loss=0.32796624302864075\n",
            "epoch 123 iter 28 loss=0.2638222575187683\n",
            "epoch 123 iter 29 loss=0.2820979058742523\n",
            "epoch 123 iter 30 loss=0.28435394167900085\n",
            "epoch 123 iter 31 loss=0.30349200963974\n",
            "epoch 123 iter 32 loss=0.2985607385635376\n",
            "epoch 123 iter 33 loss=0.28313860297203064\n",
            "epoch 123 iter 34 loss=0.2525804042816162\n",
            "epoch 123 iter 35 loss=0.20086278021335602\n",
            "epoch 123 iter 36 loss=0.2283274382352829\n",
            "epoch 123 iter 37 loss=0.2506517767906189\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2782.\n",
            "epoch 124 iter 0 loss=0.25971871614456177\n",
            "epoch 124 iter 1 loss=0.25974562764167786\n",
            "epoch 124 iter 2 loss=0.23153181374073029\n",
            "epoch 124 iter 3 loss=0.23092886805534363\n",
            "epoch 124 iter 4 loss=0.22992829978466034\n",
            "epoch 124 iter 5 loss=0.23775653541088104\n",
            "epoch 124 iter 6 loss=0.23541991412639618\n",
            "epoch 124 iter 7 loss=0.22793184220790863\n",
            "epoch 124 iter 8 loss=0.2977399528026581\n",
            "epoch 124 iter 9 loss=0.2509972155094147\n",
            "epoch 124 iter 10 loss=0.22909794747829437\n",
            "epoch 124 iter 11 loss=0.2332940399646759\n",
            "epoch 124 iter 12 loss=0.20537225902080536\n",
            "epoch 124 iter 13 loss=0.2856997847557068\n",
            "epoch 124 iter 14 loss=0.27845361828804016\n",
            "epoch 124 iter 15 loss=0.28622788190841675\n",
            "epoch 124 iter 16 loss=0.23958797752857208\n",
            "epoch 124 iter 17 loss=0.3204156756401062\n",
            "epoch 124 iter 18 loss=0.27904585003852844\n",
            "epoch 124 iter 19 loss=0.25974398851394653\n",
            "epoch 124 iter 20 loss=0.2163746953010559\n",
            "epoch 124 iter 21 loss=0.23054341971874237\n",
            "epoch 124 iter 22 loss=0.26972973346710205\n",
            "epoch 124 iter 23 loss=0.25044748187065125\n",
            "epoch 124 iter 24 loss=0.23318952322006226\n",
            "epoch 124 iter 25 loss=0.4353868067264557\n",
            "epoch 124 iter 26 loss=0.23161868751049042\n",
            "epoch 124 iter 27 loss=0.18987666070461273\n",
            "epoch 124 iter 28 loss=0.2238716036081314\n",
            "epoch 124 iter 29 loss=0.2886964678764343\n",
            "epoch 124 iter 30 loss=0.2482628971338272\n",
            "epoch 124 iter 31 loss=0.29934197664260864\n",
            "epoch 124 iter 32 loss=0.21884728968143463\n",
            "epoch 124 iter 33 loss=0.26998892426490784\n",
            "epoch 124 iter 34 loss=0.26704707741737366\n",
            "epoch 124 iter 35 loss=0.27242326736450195\n",
            "epoch 124 iter 36 loss=0.24338479340076447\n",
            "epoch 124 iter 37 loss=0.23880082368850708\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2742.\n",
            "epoch 125 iter 0 loss=0.23514880239963531\n",
            "epoch 125 iter 1 loss=0.25915440917015076\n",
            "epoch 125 iter 2 loss=0.24080289900302887\n",
            "epoch 125 iter 3 loss=0.282626211643219\n",
            "epoch 125 iter 4 loss=0.24057818949222565\n",
            "epoch 125 iter 5 loss=0.22403433918952942\n",
            "epoch 125 iter 6 loss=0.28917285799980164\n",
            "epoch 125 iter 7 loss=0.23471850156784058\n",
            "epoch 125 iter 8 loss=0.19767242670059204\n",
            "epoch 125 iter 9 loss=0.2230842411518097\n",
            "epoch 125 iter 10 loss=0.2797352969646454\n",
            "epoch 125 iter 11 loss=0.30856162309646606\n",
            "epoch 125 iter 12 loss=0.24488186836242676\n",
            "epoch 125 iter 13 loss=0.2242957502603531\n",
            "epoch 125 iter 14 loss=0.24547933042049408\n",
            "epoch 125 iter 15 loss=0.2344539314508438\n",
            "epoch 125 iter 16 loss=0.25743454694747925\n",
            "epoch 125 iter 17 loss=0.2556792199611664\n",
            "epoch 125 iter 18 loss=0.17667792737483978\n",
            "epoch 125 iter 19 loss=0.20760394632816315\n",
            "epoch 125 iter 20 loss=0.19360236823558807\n",
            "epoch 125 iter 21 loss=0.36461764574050903\n",
            "epoch 125 iter 22 loss=0.23610496520996094\n",
            "epoch 125 iter 23 loss=0.24107696115970612\n",
            "epoch 125 iter 24 loss=0.2455645352602005\n",
            "epoch 125 iter 25 loss=0.1996626853942871\n",
            "epoch 125 iter 26 loss=0.2611502408981323\n",
            "epoch 125 iter 27 loss=0.2663953900337219\n",
            "epoch 125 iter 28 loss=0.31070467829704285\n",
            "epoch 125 iter 29 loss=0.3241038918495178\n",
            "epoch 125 iter 30 loss=0.2536788284778595\n",
            "epoch 125 iter 31 loss=0.24246284365653992\n",
            "epoch 125 iter 32 loss=0.34671762585639954\n",
            "epoch 125 iter 33 loss=0.255908727645874\n",
            "epoch 125 iter 34 loss=0.2935262620449066\n",
            "epoch 125 iter 35 loss=0.2621420919895172\n",
            "epoch 125 iter 36 loss=0.20340044796466827\n",
            "epoch 125 iter 37 loss=0.2784709632396698\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2741.\n",
            "epoch 126 iter 0 loss=0.25885361433029175\n",
            "epoch 126 iter 1 loss=0.28521808981895447\n",
            "epoch 126 iter 2 loss=0.24124382436275482\n",
            "epoch 126 iter 3 loss=0.26322317123413086\n",
            "epoch 126 iter 4 loss=0.2877800762653351\n",
            "epoch 126 iter 5 loss=0.20111894607543945\n",
            "epoch 126 iter 6 loss=0.20114144682884216\n",
            "epoch 126 iter 7 loss=0.21786053478717804\n",
            "epoch 126 iter 8 loss=0.3133821487426758\n",
            "epoch 126 iter 9 loss=0.22392261028289795\n",
            "epoch 126 iter 10 loss=0.2520862817764282\n",
            "epoch 126 iter 11 loss=0.2584908902645111\n",
            "epoch 126 iter 12 loss=0.271137535572052\n",
            "epoch 126 iter 13 loss=0.22516067326068878\n",
            "epoch 126 iter 14 loss=0.23629355430603027\n",
            "epoch 126 iter 15 loss=0.18682415783405304\n",
            "epoch 126 iter 16 loss=0.31488361954689026\n",
            "epoch 126 iter 17 loss=0.21263903379440308\n",
            "epoch 126 iter 18 loss=0.29154160618782043\n",
            "epoch 126 iter 19 loss=0.2616950273513794\n",
            "epoch 126 iter 20 loss=0.20464131236076355\n",
            "epoch 126 iter 21 loss=0.24724628031253815\n",
            "epoch 126 iter 22 loss=0.23733064532279968\n",
            "epoch 126 iter 23 loss=0.21969373524188995\n",
            "epoch 126 iter 24 loss=0.24857108294963837\n",
            "epoch 126 iter 25 loss=0.21308091282844543\n",
            "epoch 126 iter 26 loss=0.24163098633289337\n",
            "epoch 126 iter 27 loss=0.2895481288433075\n",
            "epoch 126 iter 28 loss=0.2949233949184418\n",
            "epoch 126 iter 29 loss=0.2259286344051361\n",
            "epoch 126 iter 30 loss=0.24383558332920074\n",
            "epoch 126 iter 31 loss=0.2625966966152191\n",
            "epoch 126 iter 32 loss=0.2028447836637497\n",
            "epoch 126 iter 33 loss=0.2617224454879761\n",
            "epoch 126 iter 34 loss=0.34691905975341797\n",
            "epoch 126 iter 35 loss=0.20022837817668915\n",
            "epoch 126 iter 36 loss=0.23704908788204193\n",
            "epoch 126 iter 37 loss=0.3290594816207886\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2761.\n",
            "epoch 127 iter 0 loss=0.2658058702945709\n",
            "epoch 127 iter 1 loss=0.26807767152786255\n",
            "epoch 127 iter 2 loss=0.28215575218200684\n",
            "epoch 127 iter 3 loss=0.1852823793888092\n",
            "epoch 127 iter 4 loss=0.2596786320209503\n",
            "epoch 127 iter 5 loss=0.21254438161849976\n",
            "epoch 127 iter 6 loss=0.2919490337371826\n",
            "epoch 127 iter 7 loss=0.21370317041873932\n",
            "epoch 127 iter 8 loss=0.27697497606277466\n",
            "epoch 127 iter 9 loss=0.2835729122161865\n",
            "epoch 127 iter 10 loss=0.23357196152210236\n",
            "epoch 127 iter 11 loss=0.21729369461536407\n",
            "epoch 127 iter 12 loss=0.25402605533599854\n",
            "epoch 127 iter 13 loss=0.2287883311510086\n",
            "epoch 127 iter 14 loss=0.23773305118083954\n",
            "epoch 127 iter 15 loss=0.29466384649276733\n",
            "epoch 127 iter 16 loss=0.19469021260738373\n",
            "epoch 127 iter 17 loss=0.23790866136550903\n",
            "epoch 127 iter 18 loss=0.2830536961555481\n",
            "epoch 127 iter 19 loss=0.26266345381736755\n",
            "epoch 127 iter 20 loss=0.23870611190795898\n",
            "epoch 127 iter 21 loss=0.2657061815261841\n",
            "epoch 127 iter 22 loss=0.21046039462089539\n",
            "epoch 127 iter 23 loss=0.29019787907600403\n",
            "epoch 127 iter 24 loss=0.20993663370609283\n",
            "epoch 127 iter 25 loss=0.25297996401786804\n",
            "epoch 127 iter 26 loss=0.2233850359916687\n",
            "epoch 127 iter 27 loss=0.2383415251970291\n",
            "epoch 127 iter 28 loss=0.18386027216911316\n",
            "epoch 127 iter 29 loss=0.25245365500450134\n",
            "epoch 127 iter 30 loss=0.259277880191803\n",
            "epoch 127 iter 31 loss=0.288776159286499\n",
            "epoch 127 iter 32 loss=0.21282373368740082\n",
            "epoch 127 iter 33 loss=0.26338478922843933\n",
            "epoch 127 iter 34 loss=0.17120154201984406\n",
            "epoch 127 iter 35 loss=0.24590793251991272\n",
            "epoch 127 iter 36 loss=0.19420917332172394\n",
            "epoch 127 iter 37 loss=0.3311157524585724\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2760.\n",
            "epoch 128 iter 0 loss=0.28850311040878296\n",
            "epoch 128 iter 1 loss=0.22463829815387726\n",
            "epoch 128 iter 2 loss=0.29708102345466614\n",
            "epoch 128 iter 3 loss=0.2250843197107315\n",
            "epoch 128 iter 4 loss=0.20036454498767853\n",
            "epoch 128 iter 5 loss=0.2804437577724457\n",
            "epoch 128 iter 6 loss=0.20822134613990784\n",
            "epoch 128 iter 7 loss=0.26983293890953064\n",
            "epoch 128 iter 8 loss=0.24569441378116608\n",
            "epoch 128 iter 9 loss=0.30865949392318726\n",
            "epoch 128 iter 10 loss=0.29075437784194946\n",
            "epoch 128 iter 11 loss=0.20849522948265076\n",
            "epoch 128 iter 12 loss=0.23752664029598236\n",
            "epoch 128 iter 13 loss=0.19136305153369904\n",
            "epoch 128 iter 14 loss=0.2858032286167145\n",
            "epoch 128 iter 15 loss=0.2692627012729645\n",
            "epoch 128 iter 16 loss=0.2870488166809082\n",
            "epoch 128 iter 17 loss=0.21435332298278809\n",
            "epoch 128 iter 18 loss=0.22628353536128998\n",
            "epoch 128 iter 19 loss=0.237806499004364\n",
            "epoch 128 iter 20 loss=0.24506181478500366\n",
            "epoch 128 iter 21 loss=0.26670175790786743\n",
            "epoch 128 iter 22 loss=0.24193885922431946\n",
            "epoch 128 iter 23 loss=0.2902241349220276\n",
            "epoch 128 iter 24 loss=0.20832163095474243\n",
            "epoch 128 iter 25 loss=0.2527649998664856\n",
            "epoch 128 iter 26 loss=0.21186210215091705\n",
            "epoch 128 iter 27 loss=0.2697146534919739\n",
            "epoch 128 iter 28 loss=0.2664836347103119\n",
            "epoch 128 iter 29 loss=0.28292492032051086\n",
            "epoch 128 iter 30 loss=0.1900528073310852\n",
            "epoch 128 iter 31 loss=0.2643166482448578\n",
            "epoch 128 iter 32 loss=0.2236527055501938\n",
            "epoch 128 iter 33 loss=0.1998516321182251\n",
            "epoch 128 iter 34 loss=0.2196892648935318\n",
            "epoch 128 iter 35 loss=0.2476472109556198\n",
            "epoch 128 iter 36 loss=0.2688496708869934\n",
            "epoch 128 iter 37 loss=0.17081879079341888\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2742.\n",
            "epoch 129 iter 0 loss=0.22864799201488495\n",
            "epoch 129 iter 1 loss=0.274981290102005\n",
            "epoch 129 iter 2 loss=0.2638244032859802\n",
            "epoch 129 iter 3 loss=0.2446134239435196\n",
            "epoch 129 iter 4 loss=0.2674403488636017\n",
            "epoch 129 iter 5 loss=0.28812021017074585\n",
            "epoch 129 iter 6 loss=0.22637750208377838\n",
            "epoch 129 iter 7 loss=0.2562253773212433\n",
            "epoch 129 iter 8 loss=0.20388048887252808\n",
            "epoch 129 iter 9 loss=0.1977958083152771\n",
            "epoch 129 iter 10 loss=0.21068261563777924\n",
            "epoch 129 iter 11 loss=0.2676733136177063\n",
            "epoch 129 iter 12 loss=0.2355496734380722\n",
            "epoch 129 iter 13 loss=0.24942469596862793\n",
            "epoch 129 iter 14 loss=0.19310279190540314\n",
            "epoch 129 iter 15 loss=0.21015962958335876\n",
            "epoch 129 iter 16 loss=0.21579718589782715\n",
            "epoch 129 iter 17 loss=0.22199948132038116\n",
            "epoch 129 iter 18 loss=0.22294171154499054\n",
            "epoch 129 iter 19 loss=0.23949967324733734\n",
            "epoch 129 iter 20 loss=0.27031052112579346\n",
            "epoch 129 iter 21 loss=0.23456120491027832\n",
            "epoch 129 iter 22 loss=0.26983606815338135\n",
            "epoch 129 iter 23 loss=0.2423074096441269\n",
            "epoch 129 iter 24 loss=0.21357376873493195\n",
            "epoch 129 iter 25 loss=0.27021679282188416\n",
            "epoch 129 iter 26 loss=0.2748991847038269\n",
            "epoch 129 iter 27 loss=0.26210352778434753\n",
            "epoch 129 iter 28 loss=0.25116753578186035\n",
            "epoch 129 iter 29 loss=0.21254706382751465\n",
            "epoch 129 iter 30 loss=0.2613396644592285\n",
            "epoch 129 iter 31 loss=0.24001389741897583\n",
            "epoch 129 iter 32 loss=0.2305486649274826\n",
            "epoch 129 iter 33 loss=0.28986576199531555\n",
            "epoch 129 iter 34 loss=0.2843339741230011\n",
            "epoch 129 iter 35 loss=0.22886791825294495\n",
            "epoch 129 iter 36 loss=0.20995278656482697\n",
            "epoch 129 iter 37 loss=0.36791080236434937\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2743.\n",
            "epoch 130 iter 0 loss=0.2613376975059509\n",
            "epoch 130 iter 1 loss=0.29833081364631653\n",
            "epoch 130 iter 2 loss=0.21015974879264832\n",
            "epoch 130 iter 3 loss=0.2270251214504242\n",
            "epoch 130 iter 4 loss=0.23114092648029327\n",
            "epoch 130 iter 5 loss=0.20711028575897217\n",
            "epoch 130 iter 6 loss=0.2728123366832733\n",
            "epoch 130 iter 7 loss=0.21326102316379547\n",
            "epoch 130 iter 8 loss=0.26096537709236145\n",
            "epoch 130 iter 9 loss=0.24267907440662384\n",
            "epoch 130 iter 10 loss=0.2519814074039459\n",
            "epoch 130 iter 11 loss=0.23585869371891022\n",
            "epoch 130 iter 12 loss=0.24339769780635834\n",
            "epoch 130 iter 13 loss=0.26857051253318787\n",
            "epoch 130 iter 14 loss=0.2419896423816681\n",
            "epoch 130 iter 15 loss=0.2413904070854187\n",
            "epoch 130 iter 16 loss=0.22761312127113342\n",
            "epoch 130 iter 17 loss=0.24894443154335022\n",
            "epoch 130 iter 18 loss=0.28284746408462524\n",
            "epoch 130 iter 19 loss=0.22395092248916626\n",
            "epoch 130 iter 20 loss=0.3244716227054596\n",
            "epoch 130 iter 21 loss=0.20196054875850677\n",
            "epoch 130 iter 22 loss=0.17820829153060913\n",
            "epoch 130 iter 23 loss=0.20194686949253082\n",
            "epoch 130 iter 24 loss=0.18094883859157562\n",
            "epoch 130 iter 25 loss=0.24219025671482086\n",
            "epoch 130 iter 26 loss=0.21429023146629333\n",
            "epoch 130 iter 27 loss=0.25027647614479065\n",
            "epoch 130 iter 28 loss=0.2813219726085663\n",
            "epoch 130 iter 29 loss=0.21657465398311615\n",
            "epoch 130 iter 30 loss=0.28289249539375305\n",
            "epoch 130 iter 31 loss=0.25978007912635803\n",
            "epoch 130 iter 32 loss=0.3093052804470062\n",
            "epoch 130 iter 33 loss=0.2826317846775055\n",
            "epoch 130 iter 34 loss=0.20005345344543457\n",
            "epoch 130 iter 35 loss=0.22569070756435394\n",
            "epoch 130 iter 36 loss=0.24930080771446228\n",
            "epoch 130 iter 37 loss=0.1618126779794693\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2797.\n",
            "epoch 131 iter 0 loss=0.261094868183136\n",
            "epoch 131 iter 1 loss=0.27818775177001953\n",
            "epoch 131 iter 2 loss=0.22964470088481903\n",
            "epoch 131 iter 3 loss=0.2657167315483093\n",
            "epoch 131 iter 4 loss=0.26656079292297363\n",
            "epoch 131 iter 5 loss=0.19117166101932526\n",
            "epoch 131 iter 6 loss=0.2414320856332779\n",
            "epoch 131 iter 7 loss=0.2729001045227051\n",
            "epoch 131 iter 8 loss=0.2131672352552414\n",
            "epoch 131 iter 9 loss=0.19404037296772003\n",
            "epoch 131 iter 10 loss=0.22421470284461975\n",
            "epoch 131 iter 11 loss=0.25101685523986816\n",
            "epoch 131 iter 12 loss=0.1713121235370636\n",
            "epoch 131 iter 13 loss=0.1989826112985611\n",
            "epoch 131 iter 14 loss=0.2725791335105896\n",
            "epoch 131 iter 15 loss=0.22491219639778137\n",
            "epoch 131 iter 16 loss=0.29358768463134766\n",
            "epoch 131 iter 17 loss=0.22163863480091095\n",
            "epoch 131 iter 18 loss=0.18084724247455597\n",
            "epoch 131 iter 19 loss=0.2521977722644806\n",
            "epoch 131 iter 20 loss=0.19828087091445923\n",
            "epoch 131 iter 21 loss=0.24883396923542023\n",
            "epoch 131 iter 22 loss=0.1792573183774948\n",
            "epoch 131 iter 23 loss=0.18465059995651245\n",
            "epoch 131 iter 24 loss=0.3040931224822998\n",
            "epoch 131 iter 25 loss=0.24064984917640686\n",
            "epoch 131 iter 26 loss=0.26879146695137024\n",
            "epoch 131 iter 27 loss=0.2890630066394806\n",
            "epoch 131 iter 28 loss=0.33375367522239685\n",
            "epoch 131 iter 29 loss=0.24555310606956482\n",
            "epoch 131 iter 30 loss=0.2725938558578491\n",
            "epoch 131 iter 31 loss=0.21586504578590393\n",
            "epoch 131 iter 32 loss=0.24554961919784546\n",
            "epoch 131 iter 33 loss=0.25674399733543396\n",
            "epoch 131 iter 34 loss=0.20673654973506927\n",
            "epoch 131 iter 35 loss=0.2600908577442169\n",
            "epoch 131 iter 36 loss=0.27709823846817017\n",
            "epoch 131 iter 37 loss=0.2300729602575302\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2801.\n",
            "epoch 132 iter 0 loss=0.3255404531955719\n",
            "epoch 132 iter 1 loss=0.2720281183719635\n",
            "epoch 132 iter 2 loss=0.21949978172779083\n",
            "epoch 132 iter 3 loss=0.24388137459754944\n",
            "epoch 132 iter 4 loss=0.22138391435146332\n",
            "epoch 132 iter 5 loss=0.30905643105506897\n",
            "epoch 132 iter 6 loss=0.22168341279029846\n",
            "epoch 132 iter 7 loss=0.2668677568435669\n",
            "epoch 132 iter 8 loss=0.2291601598262787\n",
            "epoch 132 iter 9 loss=0.21206720173358917\n",
            "epoch 132 iter 10 loss=0.2178618162870407\n",
            "epoch 132 iter 11 loss=0.32767876982688904\n",
            "epoch 132 iter 12 loss=0.20307205617427826\n",
            "epoch 132 iter 13 loss=0.17030656337738037\n",
            "epoch 132 iter 14 loss=0.2496984302997589\n",
            "epoch 132 iter 15 loss=0.23790587484836578\n",
            "epoch 132 iter 16 loss=0.2304730862379074\n",
            "epoch 132 iter 17 loss=0.2227250337600708\n",
            "epoch 132 iter 18 loss=0.2758152484893799\n",
            "epoch 132 iter 19 loss=0.22476492822170258\n",
            "epoch 132 iter 20 loss=0.19621548056602478\n",
            "epoch 132 iter 21 loss=0.2055722028017044\n",
            "epoch 132 iter 22 loss=0.24369068443775177\n",
            "epoch 132 iter 23 loss=0.201160728931427\n",
            "epoch 132 iter 24 loss=0.23480181396007538\n",
            "epoch 132 iter 25 loss=0.269235223531723\n",
            "epoch 132 iter 26 loss=0.24590958654880524\n",
            "epoch 132 iter 27 loss=0.22776232659816742\n",
            "epoch 132 iter 28 loss=0.25624436140060425\n",
            "epoch 132 iter 29 loss=0.26456138491630554\n",
            "epoch 132 iter 30 loss=0.22479073703289032\n",
            "epoch 132 iter 31 loss=0.2206423133611679\n",
            "epoch 132 iter 32 loss=0.25935739278793335\n",
            "epoch 132 iter 33 loss=0.20921793580055237\n",
            "epoch 132 iter 34 loss=0.22673803567886353\n",
            "epoch 132 iter 35 loss=0.21115495264530182\n",
            "epoch 132 iter 36 loss=0.22946102917194366\n",
            "epoch 132 iter 37 loss=0.21152129769325256\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2778.\n",
            "epoch 133 iter 0 loss=0.22890648245811462\n",
            "epoch 133 iter 1 loss=0.21153850853443146\n",
            "epoch 133 iter 2 loss=0.2017194926738739\n",
            "epoch 133 iter 3 loss=0.254643052816391\n",
            "epoch 133 iter 4 loss=0.24481076002120972\n",
            "epoch 133 iter 5 loss=0.27399808168411255\n",
            "epoch 133 iter 6 loss=0.27975648641586304\n",
            "epoch 133 iter 7 loss=0.2743636965751648\n",
            "epoch 133 iter 8 loss=0.19818982481956482\n",
            "epoch 133 iter 9 loss=0.24365633726119995\n",
            "epoch 133 iter 10 loss=0.2480883151292801\n",
            "epoch 133 iter 11 loss=0.2562532126903534\n",
            "epoch 133 iter 12 loss=0.3087340295314789\n",
            "epoch 133 iter 13 loss=0.2515608072280884\n",
            "epoch 133 iter 14 loss=0.198483407497406\n",
            "epoch 133 iter 15 loss=0.23591826856136322\n",
            "epoch 133 iter 16 loss=0.19281812012195587\n",
            "epoch 133 iter 17 loss=0.18864071369171143\n",
            "epoch 133 iter 18 loss=0.25349435210227966\n",
            "epoch 133 iter 19 loss=0.22747109830379486\n",
            "epoch 133 iter 20 loss=0.22841285169124603\n",
            "epoch 133 iter 21 loss=0.21392807364463806\n",
            "epoch 133 iter 22 loss=0.33508601784706116\n",
            "epoch 133 iter 23 loss=0.22545333206653595\n",
            "epoch 133 iter 24 loss=0.27353426814079285\n",
            "epoch 133 iter 25 loss=0.20786748826503754\n",
            "epoch 133 iter 26 loss=0.22906887531280518\n",
            "epoch 133 iter 27 loss=0.22686734795570374\n",
            "epoch 133 iter 28 loss=0.1988893300294876\n",
            "epoch 133 iter 29 loss=0.2176368534564972\n",
            "epoch 133 iter 30 loss=0.2461870163679123\n",
            "epoch 133 iter 31 loss=0.2293298989534378\n",
            "epoch 133 iter 32 loss=0.21077945828437805\n",
            "epoch 133 iter 33 loss=0.20279225707054138\n",
            "epoch 133 iter 34 loss=0.2637893557548523\n",
            "epoch 133 iter 35 loss=0.21977652609348297\n",
            "epoch 133 iter 36 loss=0.2567940950393677\n",
            "epoch 133 iter 37 loss=0.27288398146629333\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2766.\n",
            "epoch 134 iter 0 loss=0.217817485332489\n",
            "epoch 134 iter 1 loss=0.2529321014881134\n",
            "epoch 134 iter 2 loss=0.22837074100971222\n",
            "epoch 134 iter 3 loss=0.28453370928764343\n",
            "epoch 134 iter 4 loss=0.20077483355998993\n",
            "epoch 134 iter 5 loss=0.20238354802131653\n",
            "epoch 134 iter 6 loss=0.2269575446844101\n",
            "epoch 134 iter 7 loss=0.24601225554943085\n",
            "epoch 134 iter 8 loss=0.2486456334590912\n",
            "epoch 134 iter 9 loss=0.21552692353725433\n",
            "epoch 134 iter 10 loss=0.271330863237381\n",
            "epoch 134 iter 11 loss=0.1711493879556656\n",
            "epoch 134 iter 12 loss=0.3298373222351074\n",
            "epoch 134 iter 13 loss=0.24826617538928986\n",
            "epoch 134 iter 14 loss=0.24200110137462616\n",
            "epoch 134 iter 15 loss=0.21379180252552032\n",
            "epoch 134 iter 16 loss=0.25116589665412903\n",
            "epoch 134 iter 17 loss=0.2163611352443695\n",
            "epoch 134 iter 18 loss=0.20581665635108948\n",
            "epoch 134 iter 19 loss=0.22859497368335724\n",
            "epoch 134 iter 20 loss=0.25764524936676025\n",
            "epoch 134 iter 21 loss=0.22054138779640198\n",
            "epoch 134 iter 22 loss=0.24398104846477509\n",
            "epoch 134 iter 23 loss=0.20017392933368683\n",
            "epoch 134 iter 24 loss=0.26932793855667114\n",
            "epoch 134 iter 25 loss=0.23841582238674164\n",
            "epoch 134 iter 26 loss=0.27374473214149475\n",
            "epoch 134 iter 27 loss=0.24283471703529358\n",
            "epoch 134 iter 28 loss=0.24717402458190918\n",
            "epoch 134 iter 29 loss=0.25924164056777954\n",
            "epoch 134 iter 30 loss=0.26193591952323914\n",
            "epoch 134 iter 31 loss=0.25069350004196167\n",
            "epoch 134 iter 32 loss=0.22750890254974365\n",
            "epoch 134 iter 33 loss=0.3028000593185425\n",
            "epoch 134 iter 34 loss=0.1847626119852066\n",
            "epoch 134 iter 35 loss=0.2519017457962036\n",
            "epoch 134 iter 36 loss=0.2562050521373749\n",
            "epoch 134 iter 37 loss=0.19982363283634186\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2732.\n",
            "epoch 135 iter 0 loss=0.3060035705566406\n",
            "epoch 135 iter 1 loss=0.27030256390571594\n",
            "epoch 135 iter 2 loss=0.25331616401672363\n",
            "epoch 135 iter 3 loss=0.23004578053951263\n",
            "epoch 135 iter 4 loss=0.2711140215396881\n",
            "epoch 135 iter 5 loss=0.23480834066867828\n",
            "epoch 135 iter 6 loss=0.25243058800697327\n",
            "epoch 135 iter 7 loss=0.262326180934906\n",
            "epoch 135 iter 8 loss=0.24284009635448456\n",
            "epoch 135 iter 9 loss=0.22787293791770935\n",
            "epoch 135 iter 10 loss=0.2435094267129898\n",
            "epoch 135 iter 11 loss=0.2153950184583664\n",
            "epoch 135 iter 12 loss=0.22653187811374664\n",
            "epoch 135 iter 13 loss=0.22541570663452148\n",
            "epoch 135 iter 14 loss=0.20395447313785553\n",
            "epoch 135 iter 15 loss=0.25032535195350647\n",
            "epoch 135 iter 16 loss=0.21101802587509155\n",
            "epoch 135 iter 17 loss=0.1996099352836609\n",
            "epoch 135 iter 18 loss=0.20400233566761017\n",
            "epoch 135 iter 19 loss=0.2843549847602844\n",
            "epoch 135 iter 20 loss=0.17116951942443848\n",
            "epoch 135 iter 21 loss=0.23550985753536224\n",
            "epoch 135 iter 22 loss=0.24980174005031586\n",
            "epoch 135 iter 23 loss=0.33094263076782227\n",
            "epoch 135 iter 24 loss=0.24806110560894012\n",
            "epoch 135 iter 25 loss=0.26234006881713867\n",
            "epoch 135 iter 26 loss=0.1921289563179016\n",
            "epoch 135 iter 27 loss=0.17454716563224792\n",
            "epoch 135 iter 28 loss=0.2436097413301468\n",
            "epoch 135 iter 29 loss=0.2815569341182709\n",
            "epoch 135 iter 30 loss=0.2719309329986572\n",
            "epoch 135 iter 31 loss=0.2917642593383789\n",
            "epoch 135 iter 32 loss=0.21458734571933746\n",
            "epoch 135 iter 33 loss=0.18292869627475739\n",
            "epoch 135 iter 34 loss=0.2641143202781677\n",
            "epoch 135 iter 35 loss=0.22680708765983582\n",
            "epoch 135 iter 36 loss=0.22018256783485413\n",
            "epoch 135 iter 37 loss=0.20928245782852173\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2741.\n",
            "epoch 136 iter 0 loss=0.21912789344787598\n",
            "epoch 136 iter 1 loss=0.24479122459888458\n",
            "epoch 136 iter 2 loss=0.18684466183185577\n",
            "epoch 136 iter 3 loss=0.3233700096607208\n",
            "epoch 136 iter 4 loss=0.19705361127853394\n",
            "epoch 136 iter 5 loss=0.2571275234222412\n",
            "epoch 136 iter 6 loss=0.247674822807312\n",
            "epoch 136 iter 7 loss=0.23875181376934052\n",
            "epoch 136 iter 8 loss=0.21457551419734955\n",
            "epoch 136 iter 9 loss=0.2375047355890274\n",
            "epoch 136 iter 10 loss=0.14996062219142914\n",
            "epoch 136 iter 11 loss=0.25630566477775574\n",
            "epoch 136 iter 12 loss=0.28558221459388733\n",
            "epoch 136 iter 13 loss=0.2853716313838959\n",
            "epoch 136 iter 14 loss=0.20872843265533447\n",
            "epoch 136 iter 15 loss=0.2349403202533722\n",
            "epoch 136 iter 16 loss=0.2716313898563385\n",
            "epoch 136 iter 17 loss=0.24685341119766235\n",
            "epoch 136 iter 18 loss=0.17922785878181458\n",
            "epoch 136 iter 19 loss=0.2287236452102661\n",
            "epoch 136 iter 20 loss=0.2506033480167389\n",
            "epoch 136 iter 21 loss=0.2743205726146698\n",
            "epoch 136 iter 22 loss=0.2782945930957794\n",
            "epoch 136 iter 23 loss=0.24992652237415314\n",
            "epoch 136 iter 24 loss=0.2525695264339447\n",
            "epoch 136 iter 25 loss=0.22156129777431488\n",
            "epoch 136 iter 26 loss=0.18000780045986176\n",
            "epoch 136 iter 27 loss=0.21901820600032806\n",
            "epoch 136 iter 28 loss=0.30523914098739624\n",
            "epoch 136 iter 29 loss=0.18132860958576202\n",
            "epoch 136 iter 30 loss=0.25859948992729187\n",
            "epoch 136 iter 31 loss=0.19024018943309784\n",
            "epoch 136 iter 32 loss=0.24559852480888367\n",
            "epoch 136 iter 33 loss=0.2882773280143738\n",
            "epoch 136 iter 34 loss=0.17217564582824707\n",
            "epoch 136 iter 35 loss=0.22928962111473083\n",
            "epoch 136 iter 36 loss=0.2494359314441681\n",
            "epoch 136 iter 37 loss=0.20246948301792145\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2760.\n",
            "epoch 137 iter 0 loss=0.276903361082077\n",
            "epoch 137 iter 1 loss=0.1903304159641266\n",
            "epoch 137 iter 2 loss=0.27121296525001526\n",
            "epoch 137 iter 3 loss=0.18020965158939362\n",
            "epoch 137 iter 4 loss=0.26428917050361633\n",
            "epoch 137 iter 5 loss=0.21995320916175842\n",
            "epoch 137 iter 6 loss=0.3079455494880676\n",
            "epoch 137 iter 7 loss=0.2182442843914032\n",
            "epoch 137 iter 8 loss=0.2586476802825928\n",
            "epoch 137 iter 9 loss=0.21513453125953674\n",
            "epoch 137 iter 10 loss=0.22637096047401428\n",
            "epoch 137 iter 11 loss=0.17861254513263702\n",
            "epoch 137 iter 12 loss=0.29671937227249146\n",
            "epoch 137 iter 13 loss=0.22806929051876068\n",
            "epoch 137 iter 14 loss=0.25717753171920776\n",
            "epoch 137 iter 15 loss=0.1960580050945282\n",
            "epoch 137 iter 16 loss=0.24627713859081268\n",
            "epoch 137 iter 17 loss=0.2122192531824112\n",
            "epoch 137 iter 18 loss=0.18294984102249146\n",
            "epoch 137 iter 19 loss=0.30957287549972534\n",
            "epoch 137 iter 20 loss=0.2644142806529999\n",
            "epoch 137 iter 21 loss=0.30757811665534973\n",
            "epoch 137 iter 22 loss=0.2254360318183899\n",
            "epoch 137 iter 23 loss=0.19771435856819153\n",
            "epoch 137 iter 24 loss=0.24086545407772064\n",
            "epoch 137 iter 25 loss=0.24612222611904144\n",
            "epoch 137 iter 26 loss=0.21126917004585266\n",
            "epoch 137 iter 27 loss=0.21048514544963837\n",
            "epoch 137 iter 28 loss=0.3349582254886627\n",
            "epoch 137 iter 29 loss=0.19743750989437103\n",
            "epoch 137 iter 30 loss=0.2107073962688446\n",
            "epoch 137 iter 31 loss=0.18186841905117035\n",
            "epoch 137 iter 32 loss=0.2492588609457016\n",
            "epoch 137 iter 33 loss=0.2684653103351593\n",
            "epoch 137 iter 34 loss=0.23942236602306366\n",
            "epoch 137 iter 35 loss=0.22596298158168793\n",
            "epoch 137 iter 36 loss=0.21127799153327942\n",
            "epoch 137 iter 37 loss=0.17249560356140137\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2828.\n",
            "epoch 138 iter 0 loss=0.2676786482334137\n",
            "epoch 138 iter 1 loss=0.19840192794799805\n",
            "epoch 138 iter 2 loss=0.23987777531147003\n",
            "epoch 138 iter 3 loss=0.20514100790023804\n",
            "epoch 138 iter 4 loss=0.21322102844715118\n",
            "epoch 138 iter 5 loss=0.21091222763061523\n",
            "epoch 138 iter 6 loss=0.27114591002464294\n",
            "epoch 138 iter 7 loss=0.16726966202259064\n",
            "epoch 138 iter 8 loss=0.2237091064453125\n",
            "epoch 138 iter 9 loss=0.19939503073692322\n",
            "epoch 138 iter 10 loss=0.24133849143981934\n",
            "epoch 138 iter 11 loss=0.22700445353984833\n",
            "epoch 138 iter 12 loss=0.19742131233215332\n",
            "epoch 138 iter 13 loss=0.21702656149864197\n",
            "epoch 138 iter 14 loss=0.26577672362327576\n",
            "epoch 138 iter 15 loss=0.25767359137535095\n",
            "epoch 138 iter 16 loss=0.28911396861076355\n",
            "epoch 138 iter 17 loss=0.2514437437057495\n",
            "epoch 138 iter 18 loss=0.23974506556987762\n",
            "epoch 138 iter 19 loss=0.23437322676181793\n",
            "epoch 138 iter 20 loss=0.2463987022638321\n",
            "epoch 138 iter 21 loss=0.20259636640548706\n",
            "epoch 138 iter 22 loss=0.19819337129592896\n",
            "epoch 138 iter 23 loss=0.26559343934059143\n",
            "epoch 138 iter 24 loss=0.22796060144901276\n",
            "epoch 138 iter 25 loss=0.20731882750988007\n",
            "epoch 138 iter 26 loss=0.24407249689102173\n",
            "epoch 138 iter 27 loss=0.23932680487632751\n",
            "epoch 138 iter 28 loss=0.2530995309352875\n",
            "epoch 138 iter 29 loss=0.21417152881622314\n",
            "epoch 138 iter 30 loss=0.277690052986145\n",
            "epoch 138 iter 31 loss=0.22898051142692566\n",
            "epoch 138 iter 32 loss=0.20340175926685333\n",
            "epoch 138 iter 33 loss=0.25401511788368225\n",
            "epoch 138 iter 34 loss=0.27142706513404846\n",
            "epoch 138 iter 35 loss=0.24501915276050568\n",
            "epoch 138 iter 36 loss=0.2333209067583084\n",
            "epoch 138 iter 37 loss=0.1665004938840866\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2747.\n",
            "epoch 139 iter 0 loss=0.24657051265239716\n",
            "epoch 139 iter 1 loss=0.22743888199329376\n",
            "epoch 139 iter 2 loss=0.2157067507505417\n",
            "epoch 139 iter 3 loss=0.22761695086956024\n",
            "epoch 139 iter 4 loss=0.19536791741847992\n",
            "epoch 139 iter 5 loss=0.2291487455368042\n",
            "epoch 139 iter 6 loss=0.2408655285835266\n",
            "epoch 139 iter 7 loss=0.25370246171951294\n",
            "epoch 139 iter 8 loss=0.17031069099903107\n",
            "epoch 139 iter 9 loss=0.23206418752670288\n",
            "epoch 139 iter 10 loss=0.18326595425605774\n",
            "epoch 139 iter 11 loss=0.2591530680656433\n",
            "epoch 139 iter 12 loss=0.2159452885389328\n",
            "epoch 139 iter 13 loss=0.18679818511009216\n",
            "epoch 139 iter 14 loss=0.2550656795501709\n",
            "epoch 139 iter 15 loss=0.24422791600227356\n",
            "epoch 139 iter 16 loss=0.25995147228240967\n",
            "epoch 139 iter 17 loss=0.26822125911712646\n",
            "epoch 139 iter 18 loss=0.2725328505039215\n",
            "epoch 139 iter 19 loss=0.1981322318315506\n",
            "epoch 139 iter 20 loss=0.23554283380508423\n",
            "epoch 139 iter 21 loss=0.22911302745342255\n",
            "epoch 139 iter 22 loss=0.21140891313552856\n",
            "epoch 139 iter 23 loss=0.22301840782165527\n",
            "epoch 139 iter 24 loss=0.2571810185909271\n",
            "epoch 139 iter 25 loss=0.24490976333618164\n",
            "epoch 139 iter 26 loss=0.19143131375312805\n",
            "epoch 139 iter 27 loss=0.2752097547054291\n",
            "epoch 139 iter 28 loss=0.23299241065979004\n",
            "epoch 139 iter 29 loss=0.2599259316921234\n",
            "epoch 139 iter 30 loss=0.2794324457645416\n",
            "epoch 139 iter 31 loss=0.1998400092124939\n",
            "epoch 139 iter 32 loss=0.20443370938301086\n",
            "epoch 139 iter 33 loss=0.19748744368553162\n",
            "epoch 139 iter 34 loss=0.25736889243125916\n",
            "epoch 139 iter 35 loss=0.19877664744853973\n",
            "epoch 139 iter 36 loss=0.19271984696388245\n",
            "epoch 139 iter 37 loss=0.2223072499036789\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2759.\n",
            "epoch 140 iter 0 loss=0.2112024575471878\n",
            "epoch 140 iter 1 loss=0.2595922648906708\n",
            "epoch 140 iter 2 loss=0.2829599380493164\n",
            "epoch 140 iter 3 loss=0.20717884600162506\n",
            "epoch 140 iter 4 loss=0.199000284075737\n",
            "epoch 140 iter 5 loss=0.1998589187860489\n",
            "epoch 140 iter 6 loss=0.2051956057548523\n",
            "epoch 140 iter 7 loss=0.2350037693977356\n",
            "epoch 140 iter 8 loss=0.21261365711688995\n",
            "epoch 140 iter 9 loss=0.24448992311954498\n",
            "epoch 140 iter 10 loss=0.22306664288043976\n",
            "epoch 140 iter 11 loss=0.23158255219459534\n",
            "epoch 140 iter 12 loss=0.23683257400989532\n",
            "epoch 140 iter 13 loss=0.25031718611717224\n",
            "epoch 140 iter 14 loss=0.19276660680770874\n",
            "epoch 140 iter 15 loss=0.24593304097652435\n",
            "epoch 140 iter 16 loss=0.24318310618400574\n",
            "epoch 140 iter 17 loss=0.20828106999397278\n",
            "epoch 140 iter 18 loss=0.22968651354312897\n",
            "epoch 140 iter 19 loss=0.2604556977748871\n",
            "epoch 140 iter 20 loss=0.20175227522850037\n",
            "epoch 140 iter 21 loss=0.26825815439224243\n",
            "epoch 140 iter 22 loss=0.2522836923599243\n",
            "epoch 140 iter 23 loss=0.22006988525390625\n",
            "epoch 140 iter 24 loss=0.242041677236557\n",
            "epoch 140 iter 25 loss=0.17015205323696136\n",
            "epoch 140 iter 26 loss=0.23494954407215118\n",
            "epoch 140 iter 27 loss=0.2651604413986206\n",
            "epoch 140 iter 28 loss=0.22118715941905975\n",
            "epoch 140 iter 29 loss=0.22713445127010345\n",
            "epoch 140 iter 30 loss=0.23542191088199615\n",
            "epoch 140 iter 31 loss=0.1669243425130844\n",
            "epoch 140 iter 32 loss=0.1881367564201355\n",
            "epoch 140 iter 33 loss=0.23509445786476135\n",
            "epoch 140 iter 34 loss=0.21402347087860107\n",
            "epoch 140 iter 35 loss=0.1697571575641632\n",
            "epoch 140 iter 36 loss=0.2904253304004669\n",
            "epoch 140 iter 37 loss=0.32140815258026123\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2821.\n",
            "epoch 141 iter 0 loss=0.224778413772583\n",
            "epoch 141 iter 1 loss=0.21721628308296204\n",
            "epoch 141 iter 2 loss=0.19118353724479675\n",
            "epoch 141 iter 3 loss=0.20461967587471008\n",
            "epoch 141 iter 4 loss=0.24971766769886017\n",
            "epoch 141 iter 5 loss=0.21382559835910797\n",
            "epoch 141 iter 6 loss=0.2350454181432724\n",
            "epoch 141 iter 7 loss=0.22424064576625824\n",
            "epoch 141 iter 8 loss=0.21190999448299408\n",
            "epoch 141 iter 9 loss=0.29150500893592834\n",
            "epoch 141 iter 10 loss=0.15523049235343933\n",
            "epoch 141 iter 11 loss=0.24489577114582062\n",
            "epoch 141 iter 12 loss=0.2933202385902405\n",
            "epoch 141 iter 13 loss=0.20430243015289307\n",
            "epoch 141 iter 14 loss=0.2597287595272064\n",
            "epoch 141 iter 15 loss=0.21953760087490082\n",
            "epoch 141 iter 16 loss=0.2102009356021881\n",
            "epoch 141 iter 17 loss=0.3083256483078003\n",
            "epoch 141 iter 18 loss=0.2193724364042282\n",
            "epoch 141 iter 19 loss=0.22111119329929352\n",
            "epoch 141 iter 20 loss=0.22616954147815704\n",
            "epoch 141 iter 21 loss=0.23413525521755219\n",
            "epoch 141 iter 22 loss=0.22170163691043854\n",
            "epoch 141 iter 23 loss=0.23250353336334229\n",
            "epoch 141 iter 24 loss=0.20807255804538727\n",
            "epoch 141 iter 25 loss=0.17244921624660492\n",
            "epoch 141 iter 26 loss=0.26990053057670593\n",
            "epoch 141 iter 27 loss=0.23184439539909363\n",
            "epoch 141 iter 28 loss=0.2590731680393219\n",
            "epoch 141 iter 29 loss=0.18570512533187866\n",
            "epoch 141 iter 30 loss=0.2568318843841553\n",
            "epoch 141 iter 31 loss=0.3011765778064728\n",
            "epoch 141 iter 32 loss=0.23870374262332916\n",
            "epoch 141 iter 33 loss=0.21839626133441925\n",
            "epoch 141 iter 34 loss=0.2110433727502823\n",
            "epoch 141 iter 35 loss=0.2737945020198822\n",
            "epoch 141 iter 36 loss=0.23582248389720917\n",
            "epoch 141 iter 37 loss=0.22102871537208557\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2734.\n",
            "epoch 142 iter 0 loss=0.26378539204597473\n",
            "epoch 142 iter 1 loss=0.20574672520160675\n",
            "epoch 142 iter 2 loss=0.21855542063713074\n",
            "epoch 142 iter 3 loss=0.22437167167663574\n",
            "epoch 142 iter 4 loss=0.21290205419063568\n",
            "epoch 142 iter 5 loss=0.21657325327396393\n",
            "epoch 142 iter 6 loss=0.166243776679039\n",
            "epoch 142 iter 7 loss=0.2733551263809204\n",
            "epoch 142 iter 8 loss=0.2571187913417816\n",
            "epoch 142 iter 9 loss=0.23254939913749695\n",
            "epoch 142 iter 10 loss=0.27301353216171265\n",
            "epoch 142 iter 11 loss=0.2112717181444168\n",
            "epoch 142 iter 12 loss=0.22881047427654266\n",
            "epoch 142 iter 13 loss=0.1994108110666275\n",
            "epoch 142 iter 14 loss=0.21381087601184845\n",
            "epoch 142 iter 15 loss=0.24880941212177277\n",
            "epoch 142 iter 16 loss=0.28251588344573975\n",
            "epoch 142 iter 17 loss=0.2298002988100052\n",
            "epoch 142 iter 18 loss=0.279018759727478\n",
            "epoch 142 iter 19 loss=0.17706137895584106\n",
            "epoch 142 iter 20 loss=0.28690874576568604\n",
            "epoch 142 iter 21 loss=0.2856051027774811\n",
            "epoch 142 iter 22 loss=0.24578291177749634\n",
            "epoch 142 iter 23 loss=0.2335755079984665\n",
            "epoch 142 iter 24 loss=0.28481146693229675\n",
            "epoch 142 iter 25 loss=0.21647080779075623\n",
            "epoch 142 iter 26 loss=0.2073449194431305\n",
            "epoch 142 iter 27 loss=0.22658786177635193\n",
            "epoch 142 iter 28 loss=0.19183917343616486\n",
            "epoch 142 iter 29 loss=0.23481489717960358\n",
            "epoch 142 iter 30 loss=0.2278442531824112\n",
            "epoch 142 iter 31 loss=0.2254391610622406\n",
            "epoch 142 iter 32 loss=0.257781445980072\n",
            "epoch 142 iter 33 loss=0.2078530341386795\n",
            "epoch 142 iter 34 loss=0.24964404106140137\n",
            "epoch 142 iter 35 loss=0.19853781163692474\n",
            "epoch 142 iter 36 loss=0.22417858242988586\n",
            "epoch 142 iter 37 loss=0.138983353972435\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2705.\n",
            "epoch 143 iter 0 loss=0.208475261926651\n",
            "epoch 143 iter 1 loss=0.2154950350522995\n",
            "epoch 143 iter 2 loss=0.2125445157289505\n",
            "epoch 143 iter 3 loss=0.2268228679895401\n",
            "epoch 143 iter 4 loss=0.2550303637981415\n",
            "epoch 143 iter 5 loss=0.2611311376094818\n",
            "epoch 143 iter 6 loss=0.2721816599369049\n",
            "epoch 143 iter 7 loss=0.22500553727149963\n",
            "epoch 143 iter 8 loss=0.26451122760772705\n",
            "epoch 143 iter 9 loss=0.2749588191509247\n",
            "epoch 143 iter 10 loss=0.2577173709869385\n",
            "epoch 143 iter 11 loss=0.21128015220165253\n",
            "epoch 143 iter 12 loss=0.23451043665409088\n",
            "epoch 143 iter 13 loss=0.19682548940181732\n",
            "epoch 143 iter 14 loss=0.23323331773281097\n",
            "epoch 143 iter 15 loss=0.22362260520458221\n",
            "epoch 143 iter 16 loss=0.17373743653297424\n",
            "epoch 143 iter 17 loss=0.3127487897872925\n",
            "epoch 143 iter 18 loss=0.23654422163963318\n",
            "epoch 143 iter 19 loss=0.19550541043281555\n",
            "epoch 143 iter 20 loss=0.22673147916793823\n",
            "epoch 143 iter 21 loss=0.1917424201965332\n",
            "epoch 143 iter 22 loss=0.17156323790550232\n",
            "epoch 143 iter 23 loss=0.18862466514110565\n",
            "epoch 143 iter 24 loss=0.1601105034351349\n",
            "epoch 143 iter 25 loss=0.21083964407444\n",
            "epoch 143 iter 26 loss=0.26117366552352905\n",
            "epoch 143 iter 27 loss=0.2050173282623291\n",
            "epoch 143 iter 28 loss=0.22382530570030212\n",
            "epoch 143 iter 29 loss=0.24171628057956696\n",
            "epoch 143 iter 30 loss=0.2667381167411804\n",
            "epoch 143 iter 31 loss=0.28044265508651733\n",
            "epoch 143 iter 32 loss=0.23596476018428802\n",
            "epoch 143 iter 33 loss=0.2203412801027298\n",
            "epoch 143 iter 34 loss=0.20058490335941315\n",
            "epoch 143 iter 35 loss=0.26665258407592773\n",
            "epoch 143 iter 36 loss=0.20286139845848083\n",
            "epoch 143 iter 37 loss=0.24049706757068634\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2735.\n",
            "epoch 144 iter 0 loss=0.16665783524513245\n",
            "epoch 144 iter 1 loss=0.22237399220466614\n",
            "epoch 144 iter 2 loss=0.27184200286865234\n",
            "epoch 144 iter 3 loss=0.22293773293495178\n",
            "epoch 144 iter 4 loss=0.21031758189201355\n",
            "epoch 144 iter 5 loss=0.3263677954673767\n",
            "epoch 144 iter 6 loss=0.2083907276391983\n",
            "epoch 144 iter 7 loss=0.19857226312160492\n",
            "epoch 144 iter 8 loss=0.19055874645709991\n",
            "epoch 144 iter 9 loss=0.25355809926986694\n",
            "epoch 144 iter 10 loss=0.34440991282463074\n",
            "epoch 144 iter 11 loss=0.25495973229408264\n",
            "epoch 144 iter 12 loss=0.20125645399093628\n",
            "epoch 144 iter 13 loss=0.1970411092042923\n",
            "epoch 144 iter 14 loss=0.23221832513809204\n",
            "epoch 144 iter 15 loss=0.22712476551532745\n",
            "epoch 144 iter 16 loss=0.24328450858592987\n",
            "epoch 144 iter 17 loss=0.20643553137779236\n",
            "epoch 144 iter 18 loss=0.2728891968727112\n",
            "epoch 144 iter 19 loss=0.1486872434616089\n",
            "epoch 144 iter 20 loss=0.23646630346775055\n",
            "epoch 144 iter 21 loss=0.2752974331378937\n",
            "epoch 144 iter 22 loss=0.2686413526535034\n",
            "epoch 144 iter 23 loss=0.2346448302268982\n",
            "epoch 144 iter 24 loss=0.2577841877937317\n",
            "epoch 144 iter 25 loss=0.2376016527414322\n",
            "epoch 144 iter 26 loss=0.19408723711967468\n",
            "epoch 144 iter 27 loss=0.19966796040534973\n",
            "epoch 144 iter 28 loss=0.26183557510375977\n",
            "epoch 144 iter 29 loss=0.21905262768268585\n",
            "epoch 144 iter 30 loss=0.17619125545024872\n",
            "epoch 144 iter 31 loss=0.2528543770313263\n",
            "epoch 144 iter 32 loss=0.21729350090026855\n",
            "epoch 144 iter 33 loss=0.2165544033050537\n",
            "epoch 144 iter 34 loss=0.2544185221195221\n",
            "epoch 144 iter 35 loss=0.19803103804588318\n",
            "epoch 144 iter 36 loss=0.25401821732521057\n",
            "epoch 144 iter 37 loss=0.178566113114357\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2826.\n",
            "epoch 145 iter 0 loss=0.20703144371509552\n",
            "epoch 145 iter 1 loss=0.28706124424934387\n",
            "epoch 145 iter 2 loss=0.18613161146640778\n",
            "epoch 145 iter 3 loss=0.21804571151733398\n",
            "epoch 145 iter 4 loss=0.236628919839859\n",
            "epoch 145 iter 5 loss=0.20322081446647644\n",
            "epoch 145 iter 6 loss=0.24511343240737915\n",
            "epoch 145 iter 7 loss=0.18230058252811432\n",
            "epoch 145 iter 8 loss=0.1985853910446167\n",
            "epoch 145 iter 9 loss=0.28912875056266785\n",
            "epoch 145 iter 10 loss=0.2566380798816681\n",
            "epoch 145 iter 11 loss=0.2530107796192169\n",
            "epoch 145 iter 12 loss=0.16328950226306915\n",
            "epoch 145 iter 13 loss=0.19657734036445618\n",
            "epoch 145 iter 14 loss=0.26251843571662903\n",
            "epoch 145 iter 15 loss=0.19176188111305237\n",
            "epoch 145 iter 16 loss=0.18795883655548096\n",
            "epoch 145 iter 17 loss=0.2637818157672882\n",
            "epoch 145 iter 18 loss=0.18575601279735565\n",
            "epoch 145 iter 19 loss=0.22863589227199554\n",
            "epoch 145 iter 20 loss=0.2084668129682541\n",
            "epoch 145 iter 21 loss=0.21649453043937683\n",
            "epoch 145 iter 22 loss=0.2269984483718872\n",
            "epoch 145 iter 23 loss=0.2112867683172226\n",
            "epoch 145 iter 24 loss=0.2365235537290573\n",
            "epoch 145 iter 25 loss=0.19322802126407623\n",
            "epoch 145 iter 26 loss=0.17742952704429626\n",
            "epoch 145 iter 27 loss=0.26472386717796326\n",
            "epoch 145 iter 28 loss=0.22508496046066284\n",
            "epoch 145 iter 29 loss=0.2180110663175583\n",
            "epoch 145 iter 30 loss=0.19873160123825073\n",
            "epoch 145 iter 31 loss=0.26014941930770874\n",
            "epoch 145 iter 32 loss=0.23182988166809082\n",
            "epoch 145 iter 33 loss=0.18182359635829926\n",
            "epoch 145 iter 34 loss=0.24550089240074158\n",
            "epoch 145 iter 35 loss=0.22270230948925018\n",
            "epoch 145 iter 36 loss=0.20972155034542084\n",
            "epoch 145 iter 37 loss=0.23740807175636292\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2796.\n",
            "epoch 146 iter 0 loss=0.2366640418767929\n",
            "epoch 146 iter 1 loss=0.2557714581489563\n",
            "epoch 146 iter 2 loss=0.2465691715478897\n",
            "epoch 146 iter 3 loss=0.25297287106513977\n",
            "epoch 146 iter 4 loss=0.2250879853963852\n",
            "epoch 146 iter 5 loss=0.303763747215271\n",
            "epoch 146 iter 6 loss=0.23974905908107758\n",
            "epoch 146 iter 7 loss=0.22701643407344818\n",
            "epoch 146 iter 8 loss=0.2276856154203415\n",
            "epoch 146 iter 9 loss=0.2880147397518158\n",
            "epoch 146 iter 10 loss=0.19386473298072815\n",
            "epoch 146 iter 11 loss=0.19708161056041718\n",
            "epoch 146 iter 12 loss=0.19763000309467316\n",
            "epoch 146 iter 13 loss=0.21544396877288818\n",
            "epoch 146 iter 14 loss=0.24337545037269592\n",
            "epoch 146 iter 15 loss=0.22590266168117523\n",
            "epoch 146 iter 16 loss=0.22468797862529755\n",
            "epoch 146 iter 17 loss=0.2127307504415512\n",
            "epoch 146 iter 18 loss=0.19447776675224304\n",
            "epoch 146 iter 19 loss=0.2834354639053345\n",
            "epoch 146 iter 20 loss=0.17800645530223846\n",
            "epoch 146 iter 21 loss=0.2785350978374481\n",
            "epoch 146 iter 22 loss=0.18369127810001373\n",
            "epoch 146 iter 23 loss=0.212232306599617\n",
            "epoch 146 iter 24 loss=0.19342657923698425\n",
            "epoch 146 iter 25 loss=0.2141440361738205\n",
            "epoch 146 iter 26 loss=0.19860175251960754\n",
            "epoch 146 iter 27 loss=0.21510903537273407\n",
            "epoch 146 iter 28 loss=0.23214244842529297\n",
            "epoch 146 iter 29 loss=0.14811955392360687\n",
            "epoch 146 iter 30 loss=0.20746946334838867\n",
            "epoch 146 iter 31 loss=0.21021994948387146\n",
            "epoch 146 iter 32 loss=0.18942029774188995\n",
            "epoch 146 iter 33 loss=0.18042302131652832\n",
            "epoch 146 iter 34 loss=0.19848360121250153\n",
            "epoch 146 iter 35 loss=0.19032534956932068\n",
            "epoch 146 iter 36 loss=0.23933783173561096\n",
            "epoch 146 iter 37 loss=0.2906184196472168\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2808.\n",
            "epoch 147 iter 0 loss=0.2587759494781494\n",
            "epoch 147 iter 1 loss=0.19635426998138428\n",
            "epoch 147 iter 2 loss=0.26750415563583374\n",
            "epoch 147 iter 3 loss=0.20517677068710327\n",
            "epoch 147 iter 4 loss=0.227237269282341\n",
            "epoch 147 iter 5 loss=0.20176593959331512\n",
            "epoch 147 iter 6 loss=0.24968981742858887\n",
            "epoch 147 iter 7 loss=0.2199597954750061\n",
            "epoch 147 iter 8 loss=0.1685442328453064\n",
            "epoch 147 iter 9 loss=0.1990208923816681\n",
            "epoch 147 iter 10 loss=0.26002541184425354\n",
            "epoch 147 iter 11 loss=0.20452167093753815\n",
            "epoch 147 iter 12 loss=0.17536279559135437\n",
            "epoch 147 iter 13 loss=0.20897351205348969\n",
            "epoch 147 iter 14 loss=0.2588490843772888\n",
            "epoch 147 iter 15 loss=0.19477726519107819\n",
            "epoch 147 iter 16 loss=0.22919271886348724\n",
            "epoch 147 iter 17 loss=0.18691061437129974\n",
            "epoch 147 iter 18 loss=0.21123315393924713\n",
            "epoch 147 iter 19 loss=0.24649952352046967\n",
            "epoch 147 iter 20 loss=0.2914261519908905\n",
            "epoch 147 iter 21 loss=0.2523956894874573\n",
            "epoch 147 iter 22 loss=0.20232388377189636\n",
            "epoch 147 iter 23 loss=0.20168960094451904\n",
            "epoch 147 iter 24 loss=0.2227717787027359\n",
            "epoch 147 iter 25 loss=0.1983511596918106\n",
            "epoch 147 iter 26 loss=0.2125261425971985\n",
            "epoch 147 iter 27 loss=0.1898263692855835\n",
            "epoch 147 iter 28 loss=0.25093957781791687\n",
            "epoch 147 iter 29 loss=0.2199179232120514\n",
            "epoch 147 iter 30 loss=0.2365640103816986\n",
            "epoch 147 iter 31 loss=0.20233683288097382\n",
            "epoch 147 iter 32 loss=0.24888427555561066\n",
            "epoch 147 iter 33 loss=0.182203009724617\n",
            "epoch 147 iter 34 loss=0.2366715520620346\n",
            "epoch 147 iter 35 loss=0.2801832854747772\n",
            "epoch 147 iter 36 loss=0.19589872658252716\n",
            "epoch 147 iter 37 loss=0.19894148409366608\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2786.\n",
            "epoch 148 iter 0 loss=0.2219841182231903\n",
            "epoch 148 iter 1 loss=0.30842453241348267\n",
            "epoch 148 iter 2 loss=0.2539258599281311\n",
            "epoch 148 iter 3 loss=0.22463646531105042\n",
            "epoch 148 iter 4 loss=0.24824093282222748\n",
            "epoch 148 iter 5 loss=0.2344406545162201\n",
            "epoch 148 iter 6 loss=0.23740969598293304\n",
            "epoch 148 iter 7 loss=0.300545334815979\n",
            "epoch 148 iter 8 loss=0.2741822302341461\n",
            "epoch 148 iter 9 loss=0.1924857348203659\n",
            "epoch 148 iter 10 loss=0.2714250683784485\n",
            "epoch 148 iter 11 loss=0.18604397773742676\n",
            "epoch 148 iter 12 loss=0.25168657302856445\n",
            "epoch 148 iter 13 loss=0.21866807341575623\n",
            "epoch 148 iter 14 loss=0.2337372750043869\n",
            "epoch 148 iter 15 loss=0.19009487330913544\n",
            "epoch 148 iter 16 loss=0.198200985789299\n",
            "epoch 148 iter 17 loss=0.20621134340763092\n",
            "epoch 148 iter 18 loss=0.19603317975997925\n",
            "epoch 148 iter 19 loss=0.18645170331001282\n",
            "epoch 148 iter 20 loss=0.18430471420288086\n",
            "epoch 148 iter 21 loss=0.18823839724063873\n",
            "epoch 148 iter 22 loss=0.1967143714427948\n",
            "epoch 148 iter 23 loss=0.22407901287078857\n",
            "epoch 148 iter 24 loss=0.21939656138420105\n",
            "epoch 148 iter 25 loss=0.23792658746242523\n",
            "epoch 148 iter 26 loss=0.16323047876358032\n",
            "epoch 148 iter 27 loss=0.2049844115972519\n",
            "epoch 148 iter 28 loss=0.22127412259578705\n",
            "epoch 148 iter 29 loss=0.23642279207706451\n",
            "epoch 148 iter 30 loss=0.22573421895503998\n",
            "epoch 148 iter 31 loss=0.2777028977870941\n",
            "epoch 148 iter 32 loss=0.25768572092056274\n",
            "epoch 148 iter 33 loss=0.19144569337368011\n",
            "epoch 148 iter 34 loss=0.23774664103984833\n",
            "epoch 148 iter 35 loss=0.19976922869682312\n",
            "epoch 148 iter 36 loss=0.2886849343776703\n",
            "epoch 148 iter 37 loss=0.27182021737098694\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2788.\n",
            "epoch 149 iter 0 loss=0.23028461635112762\n",
            "epoch 149 iter 1 loss=0.21679553389549255\n",
            "epoch 149 iter 2 loss=0.18618722259998322\n",
            "epoch 149 iter 3 loss=0.25391682982444763\n",
            "epoch 149 iter 4 loss=0.19608479738235474\n",
            "epoch 149 iter 5 loss=0.18217909336090088\n",
            "epoch 149 iter 6 loss=0.22592923045158386\n",
            "epoch 149 iter 7 loss=0.24042904376983643\n",
            "epoch 149 iter 8 loss=0.22570349276065826\n",
            "epoch 149 iter 9 loss=0.21663060784339905\n",
            "epoch 149 iter 10 loss=0.17365838587284088\n",
            "epoch 149 iter 11 loss=0.20409394800662994\n",
            "epoch 149 iter 12 loss=0.2864404618740082\n",
            "epoch 149 iter 13 loss=0.28688952326774597\n",
            "epoch 149 iter 14 loss=0.20541398227214813\n",
            "epoch 149 iter 15 loss=0.27405309677124023\n",
            "epoch 149 iter 16 loss=0.23310039937496185\n",
            "epoch 149 iter 17 loss=0.23911844193935394\n",
            "epoch 149 iter 18 loss=0.24223755300045013\n",
            "epoch 149 iter 19 loss=0.25118252635002136\n",
            "epoch 149 iter 20 loss=0.263139933347702\n",
            "epoch 149 iter 21 loss=0.18825656175613403\n",
            "epoch 149 iter 22 loss=0.2191636860370636\n",
            "epoch 149 iter 23 loss=0.20830468833446503\n",
            "epoch 149 iter 24 loss=0.21333390474319458\n",
            "epoch 149 iter 25 loss=0.23898957669734955\n",
            "epoch 149 iter 26 loss=0.2012614607810974\n",
            "epoch 149 iter 27 loss=0.20531462132930756\n",
            "epoch 149 iter 28 loss=0.2306245118379593\n",
            "epoch 149 iter 29 loss=0.25068292021751404\n",
            "epoch 149 iter 30 loss=0.22174246609210968\n",
            "epoch 149 iter 31 loss=0.222035214304924\n",
            "epoch 149 iter 32 loss=0.21612225472927094\n",
            "epoch 149 iter 33 loss=0.20984947681427002\n",
            "epoch 149 iter 34 loss=0.1889396458864212\n",
            "epoch 149 iter 35 loss=0.22072726488113403\n",
            "epoch 149 iter 36 loss=0.2134043276309967\n",
            "epoch 149 iter 37 loss=0.24021512269973755\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2764.\n",
            "epoch 150 iter 0 loss=0.2531437575817108\n",
            "epoch 150 iter 1 loss=0.22562512755393982\n",
            "epoch 150 iter 2 loss=0.17606422305107117\n",
            "epoch 150 iter 3 loss=0.2166486233472824\n",
            "epoch 150 iter 4 loss=0.19479328393936157\n",
            "epoch 150 iter 5 loss=0.2205016016960144\n",
            "epoch 150 iter 6 loss=0.207255020737648\n",
            "epoch 150 iter 7 loss=0.2285853922367096\n",
            "epoch 150 iter 8 loss=0.17933328449726105\n",
            "epoch 150 iter 9 loss=0.25287503004074097\n",
            "epoch 150 iter 10 loss=0.21493779122829437\n",
            "epoch 150 iter 11 loss=0.2229863703250885\n",
            "epoch 150 iter 12 loss=0.21719220280647278\n",
            "epoch 150 iter 13 loss=0.18032486736774445\n",
            "epoch 150 iter 14 loss=0.22677525877952576\n",
            "epoch 150 iter 15 loss=0.22298084199428558\n",
            "epoch 150 iter 16 loss=0.24599231779575348\n",
            "epoch 150 iter 17 loss=0.27043238282203674\n",
            "epoch 150 iter 18 loss=0.22807927429676056\n",
            "epoch 150 iter 19 loss=0.21704988181591034\n",
            "epoch 150 iter 20 loss=0.2587622106075287\n",
            "epoch 150 iter 21 loss=0.2898887097835541\n",
            "epoch 150 iter 22 loss=0.20030303299427032\n",
            "epoch 150 iter 23 loss=0.257045716047287\n",
            "epoch 150 iter 24 loss=0.23304332792758942\n",
            "epoch 150 iter 25 loss=0.17602680623531342\n",
            "epoch 150 iter 26 loss=0.2309938371181488\n",
            "epoch 150 iter 27 loss=0.1896953284740448\n",
            "epoch 150 iter 28 loss=0.21443702280521393\n",
            "epoch 150 iter 29 loss=0.22400613129138947\n",
            "epoch 150 iter 30 loss=0.23065432906150818\n",
            "epoch 150 iter 31 loss=0.1851552128791809\n",
            "epoch 150 iter 32 loss=0.25690966844558716\n",
            "epoch 150 iter 33 loss=0.27996358275413513\n",
            "epoch 150 iter 34 loss=0.21130041778087616\n",
            "epoch 150 iter 35 loss=0.24955779314041138\n",
            "epoch 150 iter 36 loss=0.2829139530658722\n",
            "epoch 150 iter 37 loss=0.1975756734609604\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2761.\n",
            "epoch 151 iter 0 loss=0.29455411434173584\n",
            "epoch 151 iter 1 loss=0.20243483781814575\n",
            "epoch 151 iter 2 loss=0.24294714629650116\n",
            "epoch 151 iter 3 loss=0.2455795705318451\n",
            "epoch 151 iter 4 loss=0.1858227699995041\n",
            "epoch 151 iter 5 loss=0.20553496479988098\n",
            "epoch 151 iter 6 loss=0.27769193053245544\n",
            "epoch 151 iter 7 loss=0.19208455085754395\n",
            "epoch 151 iter 8 loss=0.2508578598499298\n",
            "epoch 151 iter 9 loss=0.2326464056968689\n",
            "epoch 151 iter 10 loss=0.26294320821762085\n",
            "epoch 151 iter 11 loss=0.19468437135219574\n",
            "epoch 151 iter 12 loss=0.18769168853759766\n",
            "epoch 151 iter 13 loss=0.14599424600601196\n",
            "epoch 151 iter 14 loss=0.23126983642578125\n",
            "epoch 151 iter 15 loss=0.22268414497375488\n",
            "epoch 151 iter 16 loss=0.2628152072429657\n",
            "epoch 151 iter 17 loss=0.16834035515785217\n",
            "epoch 151 iter 18 loss=0.25557491183280945\n",
            "epoch 151 iter 19 loss=0.20412316918373108\n",
            "epoch 151 iter 20 loss=0.2211167961359024\n",
            "epoch 151 iter 21 loss=0.22083830833435059\n",
            "epoch 151 iter 22 loss=0.26336193084716797\n",
            "epoch 151 iter 23 loss=0.1735667884349823\n",
            "epoch 151 iter 24 loss=0.25546133518218994\n",
            "epoch 151 iter 25 loss=0.19999036192893982\n",
            "epoch 151 iter 26 loss=0.2789715528488159\n",
            "epoch 151 iter 27 loss=0.19273360073566437\n",
            "epoch 151 iter 28 loss=0.22716458141803741\n",
            "epoch 151 iter 29 loss=0.2436433732509613\n",
            "epoch 151 iter 30 loss=0.21984896063804626\n",
            "epoch 151 iter 31 loss=0.20516006648540497\n",
            "epoch 151 iter 32 loss=0.16417214274406433\n",
            "epoch 151 iter 33 loss=0.21238557994365692\n",
            "epoch 151 iter 34 loss=0.1935364007949829\n",
            "epoch 151 iter 35 loss=0.2253740429878235\n",
            "epoch 151 iter 36 loss=0.22424255311489105\n",
            "epoch 151 iter 37 loss=0.24991631507873535\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2767.\n",
            "epoch 152 iter 0 loss=0.2519541084766388\n",
            "epoch 152 iter 1 loss=0.20128151774406433\n",
            "epoch 152 iter 2 loss=0.18694132566452026\n",
            "epoch 152 iter 3 loss=0.19962681829929352\n",
            "epoch 152 iter 4 loss=0.26292210817337036\n",
            "epoch 152 iter 5 loss=0.1958528459072113\n",
            "epoch 152 iter 6 loss=0.20379316806793213\n",
            "epoch 152 iter 7 loss=0.18908841907978058\n",
            "epoch 152 iter 8 loss=0.16817428171634674\n",
            "epoch 152 iter 9 loss=0.20537813007831573\n",
            "epoch 152 iter 10 loss=0.2846747040748596\n",
            "epoch 152 iter 11 loss=0.2278456836938858\n",
            "epoch 152 iter 12 loss=0.21675299108028412\n",
            "epoch 152 iter 13 loss=0.2569918632507324\n",
            "epoch 152 iter 14 loss=0.17918837070465088\n",
            "epoch 152 iter 15 loss=0.23600569367408752\n",
            "epoch 152 iter 16 loss=0.28031736612319946\n",
            "epoch 152 iter 17 loss=0.2198352962732315\n",
            "epoch 152 iter 18 loss=0.21786251664161682\n",
            "epoch 152 iter 19 loss=0.22851616144180298\n",
            "epoch 152 iter 20 loss=0.20513100922107697\n",
            "epoch 152 iter 21 loss=0.21340693533420563\n",
            "epoch 152 iter 22 loss=0.22116078436374664\n",
            "epoch 152 iter 23 loss=0.22557710111141205\n",
            "epoch 152 iter 24 loss=0.1980920284986496\n",
            "epoch 152 iter 25 loss=0.21588467061519623\n",
            "epoch 152 iter 26 loss=0.2585044205188751\n",
            "epoch 152 iter 27 loss=0.2150137573480606\n",
            "epoch 152 iter 28 loss=0.2126981019973755\n",
            "epoch 152 iter 29 loss=0.17076502740383148\n",
            "epoch 152 iter 30 loss=0.19238999485969543\n",
            "epoch 152 iter 31 loss=0.23622390627861023\n",
            "epoch 152 iter 32 loss=0.23590342700481415\n",
            "epoch 152 iter 33 loss=0.22664622962474823\n",
            "epoch 152 iter 34 loss=0.22084330022335052\n",
            "epoch 152 iter 35 loss=0.21879079937934875\n",
            "epoch 152 iter 36 loss=0.16213053464889526\n",
            "epoch 152 iter 37 loss=0.22135624289512634\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2773.\n",
            "epoch 153 iter 0 loss=0.17669901251792908\n",
            "epoch 153 iter 1 loss=0.2230352759361267\n",
            "epoch 153 iter 2 loss=0.18524670600891113\n",
            "epoch 153 iter 3 loss=0.25316861271858215\n",
            "epoch 153 iter 4 loss=0.2107515186071396\n",
            "epoch 153 iter 5 loss=0.2313772439956665\n",
            "epoch 153 iter 6 loss=0.2836100161075592\n",
            "epoch 153 iter 7 loss=0.22249102592468262\n",
            "epoch 153 iter 8 loss=0.18168237805366516\n",
            "epoch 153 iter 9 loss=0.18456321954727173\n",
            "epoch 153 iter 10 loss=0.2299223691225052\n",
            "epoch 153 iter 11 loss=0.18822580575942993\n",
            "epoch 153 iter 12 loss=0.2470434308052063\n",
            "epoch 153 iter 13 loss=0.1756746768951416\n",
            "epoch 153 iter 14 loss=0.19498933851718903\n",
            "epoch 153 iter 15 loss=0.2287166714668274\n",
            "epoch 153 iter 16 loss=0.2055545449256897\n",
            "epoch 153 iter 17 loss=0.21641919016838074\n",
            "epoch 153 iter 18 loss=0.22778664529323578\n",
            "epoch 153 iter 19 loss=0.23689395189285278\n",
            "epoch 153 iter 20 loss=0.20831981301307678\n",
            "epoch 153 iter 21 loss=0.2511619031429291\n",
            "epoch 153 iter 22 loss=0.23567083477973938\n",
            "epoch 153 iter 23 loss=0.21036438643932343\n",
            "epoch 153 iter 24 loss=0.22059139609336853\n",
            "epoch 153 iter 25 loss=0.24112370610237122\n",
            "epoch 153 iter 26 loss=0.1897885501384735\n",
            "epoch 153 iter 27 loss=0.2529502213001251\n",
            "epoch 153 iter 28 loss=0.19501982629299164\n",
            "epoch 153 iter 29 loss=0.20301462709903717\n",
            "epoch 153 iter 30 loss=0.18877992033958435\n",
            "epoch 153 iter 31 loss=0.17215698957443237\n",
            "epoch 153 iter 32 loss=0.1723196804523468\n",
            "epoch 153 iter 33 loss=0.21824795007705688\n",
            "epoch 153 iter 34 loss=0.19406282901763916\n",
            "epoch 153 iter 35 loss=0.21654707193374634\n",
            "epoch 153 iter 36 loss=0.20723675191402435\n",
            "epoch 153 iter 37 loss=0.19495287537574768\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2808.\n",
            "epoch 154 iter 0 loss=0.22776871919631958\n",
            "epoch 154 iter 1 loss=0.1998835653066635\n",
            "epoch 154 iter 2 loss=0.217690110206604\n",
            "epoch 154 iter 3 loss=0.2326916754245758\n",
            "epoch 154 iter 4 loss=0.23670059442520142\n",
            "epoch 154 iter 5 loss=0.19067104160785675\n",
            "epoch 154 iter 6 loss=0.226729154586792\n",
            "epoch 154 iter 7 loss=0.1725548803806305\n",
            "epoch 154 iter 8 loss=0.20265179872512817\n",
            "epoch 154 iter 9 loss=0.21728567779064178\n",
            "epoch 154 iter 10 loss=0.24692367017269135\n",
            "epoch 154 iter 11 loss=0.23467931151390076\n",
            "epoch 154 iter 12 loss=0.27042481303215027\n",
            "epoch 154 iter 13 loss=0.21451765298843384\n",
            "epoch 154 iter 14 loss=0.21687033772468567\n",
            "epoch 154 iter 15 loss=0.19231131672859192\n",
            "epoch 154 iter 16 loss=0.23814985156059265\n",
            "epoch 154 iter 17 loss=0.23807981610298157\n",
            "epoch 154 iter 18 loss=0.2261144518852234\n",
            "epoch 154 iter 19 loss=0.19789813458919525\n",
            "epoch 154 iter 20 loss=0.25335487723350525\n",
            "epoch 154 iter 21 loss=0.20547963678836823\n",
            "epoch 154 iter 22 loss=0.2506267726421356\n",
            "epoch 154 iter 23 loss=0.19596584141254425\n",
            "epoch 154 iter 24 loss=0.23489752411842346\n",
            "epoch 154 iter 25 loss=0.2023947536945343\n",
            "epoch 154 iter 26 loss=0.22081510722637177\n",
            "epoch 154 iter 27 loss=0.23537790775299072\n",
            "epoch 154 iter 28 loss=0.23723538219928741\n",
            "epoch 154 iter 29 loss=0.17551951110363007\n",
            "epoch 154 iter 30 loss=0.22203542292118073\n",
            "epoch 154 iter 31 loss=0.20843367278575897\n",
            "epoch 154 iter 32 loss=0.18174485862255096\n",
            "epoch 154 iter 33 loss=0.18746230006217957\n",
            "epoch 154 iter 34 loss=0.1954765021800995\n",
            "epoch 154 iter 35 loss=0.19850334525108337\n",
            "epoch 154 iter 36 loss=0.19761790335178375\n",
            "epoch 154 iter 37 loss=0.1754358857870102\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2762.\n",
            "epoch 155 iter 0 loss=0.30158111453056335\n",
            "epoch 155 iter 1 loss=0.22007489204406738\n",
            "epoch 155 iter 2 loss=0.2791047990322113\n",
            "epoch 155 iter 3 loss=0.20135417580604553\n",
            "epoch 155 iter 4 loss=0.28802525997161865\n",
            "epoch 155 iter 5 loss=0.2084919959306717\n",
            "epoch 155 iter 6 loss=0.19448764622211456\n",
            "epoch 155 iter 7 loss=0.18394052982330322\n",
            "epoch 155 iter 8 loss=0.2646690309047699\n",
            "epoch 155 iter 9 loss=0.2404390275478363\n",
            "epoch 155 iter 10 loss=0.2608768045902252\n",
            "epoch 155 iter 11 loss=0.20122966170310974\n",
            "epoch 155 iter 12 loss=0.2112417370080948\n",
            "epoch 155 iter 13 loss=0.23037198185920715\n",
            "epoch 155 iter 14 loss=0.2530287802219391\n",
            "epoch 155 iter 15 loss=0.2137988656759262\n",
            "epoch 155 iter 16 loss=0.2108907252550125\n",
            "epoch 155 iter 17 loss=0.194808229804039\n",
            "epoch 155 iter 18 loss=0.1997653990983963\n",
            "epoch 155 iter 19 loss=0.18123599886894226\n",
            "epoch 155 iter 20 loss=0.21125604212284088\n",
            "epoch 155 iter 21 loss=0.2351628541946411\n",
            "epoch 155 iter 22 loss=0.2261316180229187\n",
            "epoch 155 iter 23 loss=0.1672462821006775\n",
            "epoch 155 iter 24 loss=0.22041884064674377\n",
            "epoch 155 iter 25 loss=0.2346717119216919\n",
            "epoch 155 iter 26 loss=0.22429686784744263\n",
            "epoch 155 iter 27 loss=0.20186276733875275\n",
            "epoch 155 iter 28 loss=0.20327723026275635\n",
            "epoch 155 iter 29 loss=0.20721560716629028\n",
            "epoch 155 iter 30 loss=0.19314052164554596\n",
            "epoch 155 iter 31 loss=0.2203860878944397\n",
            "epoch 155 iter 32 loss=0.20097266137599945\n",
            "epoch 155 iter 33 loss=0.22255434095859528\n",
            "epoch 155 iter 34 loss=0.21210171282291412\n",
            "epoch 155 iter 35 loss=0.2611108124256134\n",
            "epoch 155 iter 36 loss=0.23947490751743317\n",
            "epoch 155 iter 37 loss=0.1340627819299698\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2744.\n",
            "epoch 156 iter 0 loss=0.21708720922470093\n",
            "epoch 156 iter 1 loss=0.24440017342567444\n",
            "epoch 156 iter 2 loss=0.21612009406089783\n",
            "epoch 156 iter 3 loss=0.20105300843715668\n",
            "epoch 156 iter 4 loss=0.1984819918870926\n",
            "epoch 156 iter 5 loss=0.2068069875240326\n",
            "epoch 156 iter 6 loss=0.2023962289094925\n",
            "epoch 156 iter 7 loss=0.20857933163642883\n",
            "epoch 156 iter 8 loss=0.28844746947288513\n",
            "epoch 156 iter 9 loss=0.19300153851509094\n",
            "epoch 156 iter 10 loss=0.21767833828926086\n",
            "epoch 156 iter 11 loss=0.20653694868087769\n",
            "epoch 156 iter 12 loss=0.22566790878772736\n",
            "epoch 156 iter 13 loss=0.230011448264122\n",
            "epoch 156 iter 14 loss=0.26377683877944946\n",
            "epoch 156 iter 15 loss=0.17292897403240204\n",
            "epoch 156 iter 16 loss=0.22206713259220123\n",
            "epoch 156 iter 17 loss=0.17827589809894562\n",
            "epoch 156 iter 18 loss=0.23008544743061066\n",
            "epoch 156 iter 19 loss=0.24267400801181793\n",
            "epoch 156 iter 20 loss=0.23368725180625916\n",
            "epoch 156 iter 21 loss=0.24457842111587524\n",
            "epoch 156 iter 22 loss=0.1869233250617981\n",
            "epoch 156 iter 23 loss=0.2167823761701584\n",
            "epoch 156 iter 24 loss=0.18184934556484222\n",
            "epoch 156 iter 25 loss=0.26668229699134827\n",
            "epoch 156 iter 26 loss=0.22010771930217743\n",
            "epoch 156 iter 27 loss=0.2397056221961975\n",
            "epoch 156 iter 28 loss=0.19688956439495087\n",
            "epoch 156 iter 29 loss=0.2342427372932434\n",
            "epoch 156 iter 30 loss=0.23332710564136505\n",
            "epoch 156 iter 31 loss=0.20978936553001404\n",
            "epoch 156 iter 32 loss=0.19897019863128662\n",
            "epoch 156 iter 33 loss=0.169648677110672\n",
            "epoch 156 iter 34 loss=0.2173570841550827\n",
            "epoch 156 iter 35 loss=0.23517560958862305\n",
            "epoch 156 iter 36 loss=0.26159945130348206\n",
            "epoch 156 iter 37 loss=0.1811574101448059\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2754.\n",
            "epoch 157 iter 0 loss=0.19704203307628632\n",
            "epoch 157 iter 1 loss=0.2190944254398346\n",
            "epoch 157 iter 2 loss=0.21952955424785614\n",
            "epoch 157 iter 3 loss=0.21949149668216705\n",
            "epoch 157 iter 4 loss=0.1751411110162735\n",
            "epoch 157 iter 5 loss=0.19329734146595\n",
            "epoch 157 iter 6 loss=0.20663441717624664\n",
            "epoch 157 iter 7 loss=0.24420687556266785\n",
            "epoch 157 iter 8 loss=0.2523856461048126\n",
            "epoch 157 iter 9 loss=0.16530096530914307\n",
            "epoch 157 iter 10 loss=0.2112237811088562\n",
            "epoch 157 iter 11 loss=0.25526154041290283\n",
            "epoch 157 iter 12 loss=0.2069350779056549\n",
            "epoch 157 iter 13 loss=0.2310141772031784\n",
            "epoch 157 iter 14 loss=0.21835032105445862\n",
            "epoch 157 iter 15 loss=0.2176135629415512\n",
            "epoch 157 iter 16 loss=0.22639837861061096\n",
            "epoch 157 iter 17 loss=0.17970383167266846\n",
            "epoch 157 iter 18 loss=0.22696468234062195\n",
            "epoch 157 iter 19 loss=0.23042453825473785\n",
            "epoch 157 iter 20 loss=0.1809898465871811\n",
            "epoch 157 iter 21 loss=0.1896713674068451\n",
            "epoch 157 iter 22 loss=0.1736748218536377\n",
            "epoch 157 iter 23 loss=0.23060916364192963\n",
            "epoch 157 iter 24 loss=0.22756145894527435\n",
            "epoch 157 iter 25 loss=0.206182062625885\n",
            "epoch 157 iter 26 loss=0.26115503907203674\n",
            "epoch 157 iter 27 loss=0.23942811787128448\n",
            "epoch 157 iter 28 loss=0.19079674780368805\n",
            "epoch 157 iter 29 loss=0.20312151312828064\n",
            "epoch 157 iter 30 loss=0.24699027836322784\n",
            "epoch 157 iter 31 loss=0.21416492760181427\n",
            "epoch 157 iter 32 loss=0.22643135488033295\n",
            "epoch 157 iter 33 loss=0.1860068291425705\n",
            "epoch 157 iter 34 loss=0.2552757263183594\n",
            "epoch 157 iter 35 loss=0.24921464920043945\n",
            "epoch 157 iter 36 loss=0.27586355805397034\n",
            "epoch 157 iter 37 loss=0.16069519519805908\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2776.\n",
            "epoch 158 iter 0 loss=0.19894617795944214\n",
            "epoch 158 iter 1 loss=0.27308836579322815\n",
            "epoch 158 iter 2 loss=0.2165983021259308\n",
            "epoch 158 iter 3 loss=0.17825260758399963\n",
            "epoch 158 iter 4 loss=0.24506396055221558\n",
            "epoch 158 iter 5 loss=0.15888933837413788\n",
            "epoch 158 iter 6 loss=0.22413526475429535\n",
            "epoch 158 iter 7 loss=0.23416469991207123\n",
            "epoch 158 iter 8 loss=0.20691752433776855\n",
            "epoch 158 iter 9 loss=0.17463043332099915\n",
            "epoch 158 iter 10 loss=0.2422039806842804\n",
            "epoch 158 iter 11 loss=0.2102132886648178\n",
            "epoch 158 iter 12 loss=0.2170436531305313\n",
            "epoch 158 iter 13 loss=0.23504388332366943\n",
            "epoch 158 iter 14 loss=0.18818998336791992\n",
            "epoch 158 iter 15 loss=0.1905452460050583\n",
            "epoch 158 iter 16 loss=0.19509944319725037\n",
            "epoch 158 iter 17 loss=0.23401622474193573\n",
            "epoch 158 iter 18 loss=0.2443625032901764\n",
            "epoch 158 iter 19 loss=0.2238859087228775\n",
            "epoch 158 iter 20 loss=0.18243038654327393\n",
            "epoch 158 iter 21 loss=0.20680691301822662\n",
            "epoch 158 iter 22 loss=0.19989821314811707\n",
            "epoch 158 iter 23 loss=0.2379879355430603\n",
            "epoch 158 iter 24 loss=0.179644376039505\n",
            "epoch 158 iter 25 loss=0.21841105818748474\n",
            "epoch 158 iter 26 loss=0.19797717034816742\n",
            "epoch 158 iter 27 loss=0.23909999430179596\n",
            "epoch 158 iter 28 loss=0.27050724625587463\n",
            "epoch 158 iter 29 loss=0.19763073325157166\n",
            "epoch 158 iter 30 loss=0.23755568265914917\n",
            "epoch 158 iter 31 loss=0.20544789731502533\n",
            "epoch 158 iter 32 loss=0.20600080490112305\n",
            "epoch 158 iter 33 loss=0.22541199624538422\n",
            "epoch 158 iter 34 loss=0.16520346701145172\n",
            "epoch 158 iter 35 loss=0.14454834163188934\n",
            "epoch 158 iter 36 loss=0.2168767750263214\n",
            "epoch 158 iter 37 loss=0.2431003600358963\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2742.\n",
            "epoch 159 iter 0 loss=0.21122108399868011\n",
            "epoch 159 iter 1 loss=0.209208145737648\n",
            "epoch 159 iter 2 loss=0.237058624625206\n",
            "epoch 159 iter 3 loss=0.19998806715011597\n",
            "epoch 159 iter 4 loss=0.19095775485038757\n",
            "epoch 159 iter 5 loss=0.19030387699604034\n",
            "epoch 159 iter 6 loss=0.21820297837257385\n",
            "epoch 159 iter 7 loss=0.19421903789043427\n",
            "epoch 159 iter 8 loss=0.20050042867660522\n",
            "epoch 159 iter 9 loss=0.2082962691783905\n",
            "epoch 159 iter 10 loss=0.1822091042995453\n",
            "epoch 159 iter 11 loss=0.21493959426879883\n",
            "epoch 159 iter 12 loss=0.27466195821762085\n",
            "epoch 159 iter 13 loss=0.20091284811496735\n",
            "epoch 159 iter 14 loss=0.22893157601356506\n",
            "epoch 159 iter 15 loss=0.2524356245994568\n",
            "epoch 159 iter 16 loss=0.20092324912548065\n",
            "epoch 159 iter 17 loss=0.19499386847019196\n",
            "epoch 159 iter 18 loss=0.2597479820251465\n",
            "epoch 159 iter 19 loss=0.16979101300239563\n",
            "epoch 159 iter 20 loss=0.2741824686527252\n",
            "epoch 159 iter 21 loss=0.2209795117378235\n",
            "epoch 159 iter 22 loss=0.2249934822320938\n",
            "epoch 159 iter 23 loss=0.22006960213184357\n",
            "epoch 159 iter 24 loss=0.25922808051109314\n",
            "epoch 159 iter 25 loss=0.17403791844844818\n",
            "epoch 159 iter 26 loss=0.21475766599178314\n",
            "epoch 159 iter 27 loss=0.21579666435718536\n",
            "epoch 159 iter 28 loss=0.176323801279068\n",
            "epoch 159 iter 29 loss=0.21661649644374847\n",
            "epoch 159 iter 30 loss=0.2452576458454132\n",
            "epoch 159 iter 31 loss=0.16878017783164978\n",
            "epoch 159 iter 32 loss=0.2384956181049347\n",
            "epoch 159 iter 33 loss=0.2117539942264557\n",
            "epoch 159 iter 34 loss=0.21798327565193176\n",
            "epoch 159 iter 35 loss=0.1791868358850479\n",
            "epoch 159 iter 36 loss=0.209445059299469\n",
            "epoch 159 iter 37 loss=0.16543586552143097\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2811.\n",
            "epoch 160 iter 0 loss=0.22042815387248993\n",
            "epoch 160 iter 1 loss=0.19501151144504547\n",
            "epoch 160 iter 2 loss=0.20272964239120483\n",
            "epoch 160 iter 3 loss=0.1823902726173401\n",
            "epoch 160 iter 4 loss=0.19095297157764435\n",
            "epoch 160 iter 5 loss=0.19540530443191528\n",
            "epoch 160 iter 6 loss=0.21223336458206177\n",
            "epoch 160 iter 7 loss=0.18140123784542084\n",
            "epoch 160 iter 8 loss=0.2272258996963501\n",
            "epoch 160 iter 9 loss=0.2239774614572525\n",
            "epoch 160 iter 10 loss=0.19451436400413513\n",
            "epoch 160 iter 11 loss=0.2731875777244568\n",
            "epoch 160 iter 12 loss=0.1648310273885727\n",
            "epoch 160 iter 13 loss=0.24238459765911102\n",
            "epoch 160 iter 14 loss=0.2067132592201233\n",
            "epoch 160 iter 15 loss=0.2810361087322235\n",
            "epoch 160 iter 16 loss=0.1505039483308792\n",
            "epoch 160 iter 17 loss=0.1864795982837677\n",
            "epoch 160 iter 18 loss=0.18762840330600739\n",
            "epoch 160 iter 19 loss=0.24156953394412994\n",
            "epoch 160 iter 20 loss=0.21829138696193695\n",
            "epoch 160 iter 21 loss=0.20177572965621948\n",
            "epoch 160 iter 22 loss=0.1874355524778366\n",
            "epoch 160 iter 23 loss=0.2512614130973816\n",
            "epoch 160 iter 24 loss=0.2217838168144226\n",
            "epoch 160 iter 25 loss=0.22530607879161835\n",
            "epoch 160 iter 26 loss=0.14625869691371918\n",
            "epoch 160 iter 27 loss=0.22011083364486694\n",
            "epoch 160 iter 28 loss=0.18211059272289276\n",
            "epoch 160 iter 29 loss=0.22590792179107666\n",
            "epoch 160 iter 30 loss=0.22421114146709442\n",
            "epoch 160 iter 31 loss=0.20824937522411346\n",
            "epoch 160 iter 32 loss=0.2017296403646469\n",
            "epoch 160 iter 33 loss=0.2053292691707611\n",
            "epoch 160 iter 34 loss=0.23158515989780426\n",
            "epoch 160 iter 35 loss=0.23229092359542847\n",
            "epoch 160 iter 36 loss=0.2593074142932892\n",
            "epoch 160 iter 37 loss=0.19741511344909668\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2761.\n",
            "epoch 161 iter 0 loss=0.23217269778251648\n",
            "epoch 161 iter 1 loss=0.19338655471801758\n",
            "epoch 161 iter 2 loss=0.23794542253017426\n",
            "epoch 161 iter 3 loss=0.21023668348789215\n",
            "epoch 161 iter 4 loss=0.21866793930530548\n",
            "epoch 161 iter 5 loss=0.2332514524459839\n",
            "epoch 161 iter 6 loss=0.22676153481006622\n",
            "epoch 161 iter 7 loss=0.26054054498672485\n",
            "epoch 161 iter 8 loss=0.22019076347351074\n",
            "epoch 161 iter 9 loss=0.20582568645477295\n",
            "epoch 161 iter 10 loss=0.2312363237142563\n",
            "epoch 161 iter 11 loss=0.2012438029050827\n",
            "epoch 161 iter 12 loss=0.1766030192375183\n",
            "epoch 161 iter 13 loss=0.19365641474723816\n",
            "epoch 161 iter 14 loss=0.19469644129276276\n",
            "epoch 161 iter 15 loss=0.23047031462192535\n",
            "epoch 161 iter 16 loss=0.3064274489879608\n",
            "epoch 161 iter 17 loss=0.2554183602333069\n",
            "epoch 161 iter 18 loss=0.16349467635154724\n",
            "epoch 161 iter 19 loss=0.23237383365631104\n",
            "epoch 161 iter 20 loss=0.22503779828548431\n",
            "epoch 161 iter 21 loss=0.1963367909193039\n",
            "epoch 161 iter 22 loss=0.2323390543460846\n",
            "epoch 161 iter 23 loss=0.2225085347890854\n",
            "epoch 161 iter 24 loss=0.2281782329082489\n",
            "epoch 161 iter 25 loss=0.18115898966789246\n",
            "epoch 161 iter 26 loss=0.17944803833961487\n",
            "epoch 161 iter 27 loss=0.14388664066791534\n",
            "epoch 161 iter 28 loss=0.21692082285881042\n",
            "epoch 161 iter 29 loss=0.2579061686992645\n",
            "epoch 161 iter 30 loss=0.24436794221401215\n",
            "epoch 161 iter 31 loss=0.23332495987415314\n",
            "epoch 161 iter 32 loss=0.19374801218509674\n",
            "epoch 161 iter 33 loss=0.18352502584457397\n",
            "epoch 161 iter 34 loss=0.22154901921749115\n",
            "epoch 161 iter 35 loss=0.22303976118564606\n",
            "epoch 161 iter 36 loss=0.21007540822029114\n",
            "epoch 161 iter 37 loss=0.11644738912582397\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2794.\n",
            "epoch 162 iter 0 loss=0.25624880194664\n",
            "epoch 162 iter 1 loss=0.2137487381696701\n",
            "epoch 162 iter 2 loss=0.2240443080663681\n",
            "epoch 162 iter 3 loss=0.21828162670135498\n",
            "epoch 162 iter 4 loss=0.24783602356910706\n",
            "epoch 162 iter 5 loss=0.25039586424827576\n",
            "epoch 162 iter 6 loss=0.2142365276813507\n",
            "epoch 162 iter 7 loss=0.1790521889925003\n",
            "epoch 162 iter 8 loss=0.21922607719898224\n",
            "epoch 162 iter 9 loss=0.22291120886802673\n",
            "epoch 162 iter 10 loss=0.1778428852558136\n",
            "epoch 162 iter 11 loss=0.2555997669696808\n",
            "epoch 162 iter 12 loss=0.2100110650062561\n",
            "epoch 162 iter 13 loss=0.14693111181259155\n",
            "epoch 162 iter 14 loss=0.2129662036895752\n",
            "epoch 162 iter 15 loss=0.23393677175045013\n",
            "epoch 162 iter 16 loss=0.20019298791885376\n",
            "epoch 162 iter 17 loss=0.19659215211868286\n",
            "epoch 162 iter 18 loss=0.15929360687732697\n",
            "epoch 162 iter 19 loss=0.19993902742862701\n",
            "epoch 162 iter 20 loss=0.18566033244132996\n",
            "epoch 162 iter 21 loss=0.20728309452533722\n",
            "epoch 162 iter 22 loss=0.25204429030418396\n",
            "epoch 162 iter 23 loss=0.21396245062351227\n",
            "epoch 162 iter 24 loss=0.15999504923820496\n",
            "epoch 162 iter 25 loss=0.18298859894275665\n",
            "epoch 162 iter 26 loss=0.1800529658794403\n",
            "epoch 162 iter 27 loss=0.22485223412513733\n",
            "epoch 162 iter 28 loss=0.23707915842533112\n",
            "epoch 162 iter 29 loss=0.18855781853199005\n",
            "epoch 162 iter 30 loss=0.16754838824272156\n",
            "epoch 162 iter 31 loss=0.21597445011138916\n",
            "epoch 162 iter 32 loss=0.26380258798599243\n",
            "epoch 162 iter 33 loss=0.20957601070404053\n",
            "epoch 162 iter 34 loss=0.2613675594329834\n",
            "epoch 162 iter 35 loss=0.19243496656417847\n",
            "epoch 162 iter 36 loss=0.2741795480251312\n",
            "epoch 162 iter 37 loss=0.21678902208805084\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2786.\n",
            "epoch 163 iter 0 loss=0.19750240445137024\n",
            "epoch 163 iter 1 loss=0.25644680857658386\n",
            "epoch 163 iter 2 loss=0.2266390323638916\n",
            "epoch 163 iter 3 loss=0.19768871366977692\n",
            "epoch 163 iter 4 loss=0.211619570851326\n",
            "epoch 163 iter 5 loss=0.22533370554447174\n",
            "epoch 163 iter 6 loss=0.24163955450057983\n",
            "epoch 163 iter 7 loss=0.2190077304840088\n",
            "epoch 163 iter 8 loss=0.1551993042230606\n",
            "epoch 163 iter 9 loss=0.26018860936164856\n",
            "epoch 163 iter 10 loss=0.2360825389623642\n",
            "epoch 163 iter 11 loss=0.19252590835094452\n",
            "epoch 163 iter 12 loss=0.23436987400054932\n",
            "epoch 163 iter 13 loss=0.2342280000448227\n",
            "epoch 163 iter 14 loss=0.1524163782596588\n",
            "epoch 163 iter 15 loss=0.20842832326889038\n",
            "epoch 163 iter 16 loss=0.20353862643241882\n",
            "epoch 163 iter 17 loss=0.27355465292930603\n",
            "epoch 163 iter 18 loss=0.20293426513671875\n",
            "epoch 163 iter 19 loss=0.22162912786006927\n",
            "epoch 163 iter 20 loss=0.22980646789073944\n",
            "epoch 163 iter 21 loss=0.19841448962688446\n",
            "epoch 163 iter 22 loss=0.20918236672878265\n",
            "epoch 163 iter 23 loss=0.20292004942893982\n",
            "epoch 163 iter 24 loss=0.2120225727558136\n",
            "epoch 163 iter 25 loss=0.19562551379203796\n",
            "epoch 163 iter 26 loss=0.15723001956939697\n",
            "epoch 163 iter 27 loss=0.26072150468826294\n",
            "epoch 163 iter 28 loss=0.2516552805900574\n",
            "epoch 163 iter 29 loss=0.21233800053596497\n",
            "epoch 163 iter 30 loss=0.17560243606567383\n",
            "epoch 163 iter 31 loss=0.18557673692703247\n",
            "epoch 163 iter 32 loss=0.21101194620132446\n",
            "epoch 163 iter 33 loss=0.16212259232997894\n",
            "epoch 163 iter 34 loss=0.2027907818555832\n",
            "epoch 163 iter 35 loss=0.17134244740009308\n",
            "epoch 163 iter 36 loss=0.17349357903003693\n",
            "epoch 163 iter 37 loss=0.13888944685459137\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2749.\n",
            "epoch 164 iter 0 loss=0.18527494370937347\n",
            "epoch 164 iter 1 loss=0.19612887501716614\n",
            "epoch 164 iter 2 loss=0.14874449372291565\n",
            "epoch 164 iter 3 loss=0.1830790638923645\n",
            "epoch 164 iter 4 loss=0.27065470814704895\n",
            "epoch 164 iter 5 loss=0.217325359582901\n",
            "epoch 164 iter 6 loss=0.24798257648944855\n",
            "epoch 164 iter 7 loss=0.17342999577522278\n",
            "epoch 164 iter 8 loss=0.1534445434808731\n",
            "epoch 164 iter 9 loss=0.194359689950943\n",
            "epoch 164 iter 10 loss=0.18285410106182098\n",
            "epoch 164 iter 11 loss=0.23773422837257385\n",
            "epoch 164 iter 12 loss=0.20047441124916077\n",
            "epoch 164 iter 13 loss=0.2246582955121994\n",
            "epoch 164 iter 14 loss=0.2016170173883438\n",
            "epoch 164 iter 15 loss=0.16052159667015076\n",
            "epoch 164 iter 16 loss=0.1607787311077118\n",
            "epoch 164 iter 17 loss=0.21857850253582\n",
            "epoch 164 iter 18 loss=0.2146502137184143\n",
            "epoch 164 iter 19 loss=0.23024049401283264\n",
            "epoch 164 iter 20 loss=0.22743763029575348\n",
            "epoch 164 iter 21 loss=0.21185077726840973\n",
            "epoch 164 iter 22 loss=0.24308790266513824\n",
            "epoch 164 iter 23 loss=0.21006079018115997\n",
            "epoch 164 iter 24 loss=0.20136991143226624\n",
            "epoch 164 iter 25 loss=0.19087377190589905\n",
            "epoch 164 iter 26 loss=0.2754257619380951\n",
            "epoch 164 iter 27 loss=0.23201143741607666\n",
            "epoch 164 iter 28 loss=0.22631686925888062\n",
            "epoch 164 iter 29 loss=0.20600612461566925\n",
            "epoch 164 iter 30 loss=0.21744652092456818\n",
            "epoch 164 iter 31 loss=0.18452756106853485\n",
            "epoch 164 iter 32 loss=0.1617685854434967\n",
            "epoch 164 iter 33 loss=0.24494987726211548\n",
            "epoch 164 iter 34 loss=0.20819303393363953\n",
            "epoch 164 iter 35 loss=0.2628202736377716\n",
            "epoch 164 iter 36 loss=0.23724839091300964\n",
            "epoch 164 iter 37 loss=0.17176829278469086\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2824.\n",
            "epoch 165 iter 0 loss=0.18309442698955536\n",
            "epoch 165 iter 1 loss=0.14893746376037598\n",
            "epoch 165 iter 2 loss=0.27870213985443115\n",
            "epoch 165 iter 3 loss=0.18199917674064636\n",
            "epoch 165 iter 4 loss=0.20226813852787018\n",
            "epoch 165 iter 5 loss=0.23290494084358215\n",
            "epoch 165 iter 6 loss=0.2176271378993988\n",
            "epoch 165 iter 7 loss=0.16915757954120636\n",
            "epoch 165 iter 8 loss=0.21402540802955627\n",
            "epoch 165 iter 9 loss=0.20956870913505554\n",
            "epoch 165 iter 10 loss=0.2137705385684967\n",
            "epoch 165 iter 11 loss=0.2218325138092041\n",
            "epoch 165 iter 12 loss=0.2052808701992035\n",
            "epoch 165 iter 13 loss=0.21430660784244537\n",
            "epoch 165 iter 14 loss=0.25145643949508667\n",
            "epoch 165 iter 15 loss=0.23882053792476654\n",
            "epoch 165 iter 16 loss=0.2610194683074951\n",
            "epoch 165 iter 17 loss=0.19932258129119873\n",
            "epoch 165 iter 18 loss=0.23575355112552643\n",
            "epoch 165 iter 19 loss=0.2104651778936386\n",
            "epoch 165 iter 20 loss=0.23103122413158417\n",
            "epoch 165 iter 21 loss=0.19420909881591797\n",
            "epoch 165 iter 22 loss=0.16536667943000793\n",
            "epoch 165 iter 23 loss=0.1869223713874817\n",
            "epoch 165 iter 24 loss=0.19248948991298676\n",
            "epoch 165 iter 25 loss=0.22953343391418457\n",
            "epoch 165 iter 26 loss=0.16088375449180603\n",
            "epoch 165 iter 27 loss=0.16675537824630737\n",
            "epoch 165 iter 28 loss=0.16530871391296387\n",
            "epoch 165 iter 29 loss=0.19190716743469238\n",
            "epoch 165 iter 30 loss=0.23346976935863495\n",
            "epoch 165 iter 31 loss=0.25633007287979126\n",
            "epoch 165 iter 32 loss=0.20562031865119934\n",
            "epoch 165 iter 33 loss=0.16406819224357605\n",
            "epoch 165 iter 34 loss=0.21224604547023773\n",
            "epoch 165 iter 35 loss=0.18506301939487457\n",
            "epoch 165 iter 36 loss=0.21781222522258759\n",
            "epoch 165 iter 37 loss=0.228986918926239\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2758.\n",
            "epoch 166 iter 0 loss=0.19234950840473175\n",
            "epoch 166 iter 1 loss=0.18567800521850586\n",
            "epoch 166 iter 2 loss=0.16817793250083923\n",
            "epoch 166 iter 3 loss=0.1956091672182083\n",
            "epoch 166 iter 4 loss=0.2350969910621643\n",
            "epoch 166 iter 5 loss=0.16953599452972412\n",
            "epoch 166 iter 6 loss=0.20569762587547302\n",
            "epoch 166 iter 7 loss=0.1925755739212036\n",
            "epoch 166 iter 8 loss=0.2634516954421997\n",
            "epoch 166 iter 9 loss=0.18912367522716522\n",
            "epoch 166 iter 10 loss=0.18010009825229645\n",
            "epoch 166 iter 11 loss=0.20357483625411987\n",
            "epoch 166 iter 12 loss=0.2277245968580246\n",
            "epoch 166 iter 13 loss=0.21794414520263672\n",
            "epoch 166 iter 14 loss=0.18138165771961212\n",
            "epoch 166 iter 15 loss=0.23404893279075623\n",
            "epoch 166 iter 16 loss=0.20999687910079956\n",
            "epoch 166 iter 17 loss=0.23360149562358856\n",
            "epoch 166 iter 18 loss=0.22654767334461212\n",
            "epoch 166 iter 19 loss=0.2466438114643097\n",
            "epoch 166 iter 20 loss=0.2742254436016083\n",
            "epoch 166 iter 21 loss=0.32480984926223755\n",
            "epoch 166 iter 22 loss=0.46436575055122375\n",
            "epoch 166 iter 23 loss=0.3811276853084564\n",
            "epoch 166 iter 24 loss=0.7601234316825867\n",
            "epoch 166 iter 25 loss=0.4225012958049774\n",
            "epoch 166 iter 26 loss=0.39114683866500854\n",
            "epoch 166 iter 27 loss=0.37896090745925903\n",
            "epoch 166 iter 28 loss=0.6195788979530334\n",
            "epoch 166 iter 29 loss=0.5079783201217651\n",
            "epoch 166 iter 30 loss=0.2932884693145752\n",
            "epoch 166 iter 31 loss=1.21685791015625\n",
            "epoch 166 iter 32 loss=0.4227152168750763\n",
            "epoch 166 iter 33 loss=0.6844429969787598\n",
            "epoch 166 iter 34 loss=0.43317702412605286\n",
            "epoch 166 iter 35 loss=0.584475576877594\n",
            "epoch 166 iter 36 loss=0.35705676674842834\n",
            "epoch 166 iter 37 loss=0.39283210039138794\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2047.\n",
            "epoch 167 iter 0 loss=1.1214686632156372\n",
            "epoch 167 iter 1 loss=0.6571801900863647\n",
            "epoch 167 iter 2 loss=0.6572926640510559\n",
            "epoch 167 iter 3 loss=0.5279514193534851\n",
            "epoch 167 iter 4 loss=0.8080368041992188\n",
            "epoch 167 iter 5 loss=0.5655831098556519\n",
            "epoch 167 iter 6 loss=0.5669143795967102\n",
            "epoch 167 iter 7 loss=0.44111740589141846\n",
            "epoch 167 iter 8 loss=0.5208215117454529\n",
            "epoch 167 iter 9 loss=0.44518089294433594\n",
            "epoch 167 iter 10 loss=0.5142175555229187\n",
            "epoch 167 iter 11 loss=0.4111201763153076\n",
            "epoch 167 iter 12 loss=0.5594411492347717\n",
            "epoch 167 iter 13 loss=0.3956559896469116\n",
            "epoch 167 iter 14 loss=0.6595974564552307\n",
            "epoch 167 iter 15 loss=0.33922767639160156\n",
            "epoch 167 iter 16 loss=0.3682318925857544\n",
            "epoch 167 iter 17 loss=0.3957787752151489\n",
            "epoch 167 iter 18 loss=0.5552850365638733\n",
            "epoch 167 iter 19 loss=0.7065720558166504\n",
            "epoch 167 iter 20 loss=0.41872814297676086\n",
            "epoch 167 iter 21 loss=0.4460252523422241\n",
            "epoch 167 iter 22 loss=0.5985170006752014\n",
            "epoch 167 iter 23 loss=0.5608460307121277\n",
            "epoch 167 iter 24 loss=0.4022446274757385\n",
            "epoch 167 iter 25 loss=0.3643888533115387\n",
            "epoch 167 iter 26 loss=0.4234575927257538\n",
            "epoch 167 iter 27 loss=0.3272748589515686\n",
            "epoch 167 iter 28 loss=0.4004039168357849\n",
            "epoch 167 iter 29 loss=0.39443331956863403\n",
            "epoch 167 iter 30 loss=0.3381907045841217\n",
            "epoch 167 iter 31 loss=0.3379706144332886\n",
            "epoch 167 iter 32 loss=0.5387876033782959\n",
            "epoch 167 iter 33 loss=0.7312444448471069\n",
            "epoch 167 iter 34 loss=0.3549004793167114\n",
            "epoch 167 iter 35 loss=0.562505841255188\n",
            "epoch 167 iter 36 loss=0.3212684690952301\n",
            "epoch 167 iter 37 loss=0.41105830669403076\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2549.\n",
            "epoch 168 iter 0 loss=0.43226683139801025\n",
            "epoch 168 iter 1 loss=0.24894553422927856\n",
            "epoch 168 iter 2 loss=0.3529801070690155\n",
            "epoch 168 iter 3 loss=0.3658061921596527\n",
            "epoch 168 iter 4 loss=0.37207990884780884\n",
            "epoch 168 iter 5 loss=0.4126077890396118\n",
            "epoch 168 iter 6 loss=0.33262690901756287\n",
            "epoch 168 iter 7 loss=0.2659355700016022\n",
            "epoch 168 iter 8 loss=0.31188052892684937\n",
            "epoch 168 iter 9 loss=0.5471553206443787\n",
            "epoch 168 iter 10 loss=0.37210410833358765\n",
            "epoch 168 iter 11 loss=0.28520140051841736\n",
            "epoch 168 iter 12 loss=0.3503338098526001\n",
            "epoch 168 iter 13 loss=0.33675241470336914\n",
            "epoch 168 iter 14 loss=0.2852623462677002\n",
            "epoch 168 iter 15 loss=0.29622894525527954\n",
            "epoch 168 iter 16 loss=0.21308571100234985\n",
            "epoch 168 iter 17 loss=0.3390175700187683\n",
            "epoch 168 iter 18 loss=0.23816931247711182\n",
            "epoch 168 iter 19 loss=0.28602829575538635\n",
            "epoch 168 iter 20 loss=0.31676068902015686\n",
            "epoch 168 iter 21 loss=0.2804502844810486\n",
            "epoch 168 iter 22 loss=0.27987200021743774\n",
            "epoch 168 iter 23 loss=0.27881714701652527\n",
            "epoch 168 iter 24 loss=0.3127347230911255\n",
            "epoch 168 iter 25 loss=0.35436609387397766\n",
            "epoch 168 iter 26 loss=0.2617349922657013\n",
            "epoch 168 iter 27 loss=0.23054102063179016\n",
            "epoch 168 iter 28 loss=0.4388956129550934\n",
            "epoch 168 iter 29 loss=0.22852109372615814\n",
            "epoch 168 iter 30 loss=0.37156063318252563\n",
            "epoch 168 iter 31 loss=0.2151867151260376\n",
            "epoch 168 iter 32 loss=0.2754702568054199\n",
            "epoch 168 iter 33 loss=0.26865312457084656\n",
            "epoch 168 iter 34 loss=0.22438643872737885\n",
            "epoch 168 iter 35 loss=0.2842564284801483\n",
            "epoch 168 iter 36 loss=0.26952776312828064\n",
            "epoch 168 iter 37 loss=0.2604779899120331\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2697.\n",
            "epoch 169 iter 0 loss=0.2689823508262634\n",
            "epoch 169 iter 1 loss=0.2582430839538574\n",
            "epoch 169 iter 2 loss=0.31209516525268555\n",
            "epoch 169 iter 3 loss=0.24630485475063324\n",
            "epoch 169 iter 4 loss=0.25276562571525574\n",
            "epoch 169 iter 5 loss=0.2832082211971283\n",
            "epoch 169 iter 6 loss=0.26287704706192017\n",
            "epoch 169 iter 7 loss=0.26672348380088806\n",
            "epoch 169 iter 8 loss=0.2068231999874115\n",
            "epoch 169 iter 9 loss=0.21714596450328827\n",
            "epoch 169 iter 10 loss=0.24972808361053467\n",
            "epoch 169 iter 11 loss=0.2400372177362442\n",
            "epoch 169 iter 12 loss=0.33132314682006836\n",
            "epoch 169 iter 13 loss=0.30148375034332275\n",
            "epoch 169 iter 14 loss=0.28790557384490967\n",
            "epoch 169 iter 15 loss=0.502600371837616\n",
            "epoch 169 iter 16 loss=0.25938236713409424\n",
            "epoch 169 iter 17 loss=0.31643611192703247\n",
            "epoch 169 iter 18 loss=0.3483354449272156\n",
            "epoch 169 iter 19 loss=0.46411725878715515\n",
            "epoch 169 iter 20 loss=0.3863854706287384\n",
            "epoch 169 iter 21 loss=0.5266430974006653\n",
            "epoch 169 iter 22 loss=0.4048558473587036\n",
            "epoch 169 iter 23 loss=0.3430410921573639\n",
            "epoch 169 iter 24 loss=0.446289598941803\n",
            "epoch 169 iter 25 loss=0.3443271815776825\n",
            "epoch 169 iter 26 loss=0.28764456510543823\n",
            "epoch 169 iter 27 loss=0.36970260739326477\n",
            "epoch 169 iter 28 loss=0.28796425461769104\n",
            "epoch 169 iter 29 loss=0.3096000552177429\n",
            "epoch 169 iter 30 loss=0.31572574377059937\n",
            "epoch 169 iter 31 loss=0.2575457692146301\n",
            "epoch 169 iter 32 loss=0.33985236287117004\n",
            "epoch 169 iter 33 loss=0.41299644112586975\n",
            "epoch 169 iter 34 loss=0.19917361438274384\n",
            "epoch 169 iter 35 loss=0.27405986189842224\n",
            "epoch 169 iter 36 loss=0.2292655110359192\n",
            "epoch 169 iter 37 loss=0.21664294600486755\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2654.\n",
            "epoch 170 iter 0 loss=0.28456926345825195\n",
            "epoch 170 iter 1 loss=0.27279654145240784\n",
            "epoch 170 iter 2 loss=0.2934190034866333\n",
            "epoch 170 iter 3 loss=0.23265457153320312\n",
            "epoch 170 iter 4 loss=0.2586117386817932\n",
            "epoch 170 iter 5 loss=0.24289700388908386\n",
            "epoch 170 iter 6 loss=0.3906151056289673\n",
            "epoch 170 iter 7 loss=0.20044715702533722\n",
            "epoch 170 iter 8 loss=0.2331218123435974\n",
            "epoch 170 iter 9 loss=0.2638600170612335\n",
            "epoch 170 iter 10 loss=0.3037683963775635\n",
            "epoch 170 iter 11 loss=0.2264648824930191\n",
            "epoch 170 iter 12 loss=0.29786229133605957\n",
            "epoch 170 iter 13 loss=0.23133572936058044\n",
            "epoch 170 iter 14 loss=0.24174095690250397\n",
            "epoch 170 iter 15 loss=0.25567781925201416\n",
            "epoch 170 iter 16 loss=0.21788297593593597\n",
            "epoch 170 iter 17 loss=0.23512479662895203\n",
            "epoch 170 iter 18 loss=0.21461685001850128\n",
            "epoch 170 iter 19 loss=0.3101290464401245\n",
            "epoch 170 iter 20 loss=0.2770942449569702\n",
            "epoch 170 iter 21 loss=0.26003608107566833\n",
            "epoch 170 iter 22 loss=0.26359501481056213\n",
            "epoch 170 iter 23 loss=0.22440728545188904\n",
            "epoch 170 iter 24 loss=0.20074211061000824\n",
            "epoch 170 iter 25 loss=0.2239152044057846\n",
            "epoch 170 iter 26 loss=0.4434014558792114\n",
            "epoch 170 iter 27 loss=0.24174745380878448\n",
            "epoch 170 iter 28 loss=0.2697182297706604\n",
            "epoch 170 iter 29 loss=0.2381923496723175\n",
            "epoch 170 iter 30 loss=0.21822208166122437\n",
            "epoch 170 iter 31 loss=0.2558196783065796\n",
            "epoch 170 iter 32 loss=0.31136929988861084\n",
            "epoch 170 iter 33 loss=0.2973267138004303\n",
            "epoch 170 iter 34 loss=0.30624493956565857\n",
            "epoch 170 iter 35 loss=0.28618475794792175\n",
            "epoch 170 iter 36 loss=0.23203304409980774\n",
            "epoch 170 iter 37 loss=0.33230525255203247\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2741.\n",
            "epoch 171 iter 0 loss=0.3246469795703888\n",
            "epoch 171 iter 1 loss=0.24031494557857513\n",
            "epoch 171 iter 2 loss=0.34692686796188354\n",
            "epoch 171 iter 3 loss=0.20349931716918945\n",
            "epoch 171 iter 4 loss=0.23822711408138275\n",
            "epoch 171 iter 5 loss=0.27886971831321716\n",
            "epoch 171 iter 6 loss=0.22407838702201843\n",
            "epoch 171 iter 7 loss=0.24154850840568542\n",
            "epoch 171 iter 8 loss=0.18085229396820068\n",
            "epoch 171 iter 9 loss=0.2522662878036499\n",
            "epoch 171 iter 10 loss=0.22910091280937195\n",
            "epoch 171 iter 11 loss=0.24045442044734955\n",
            "epoch 171 iter 12 loss=0.2154257744550705\n",
            "epoch 171 iter 13 loss=0.20138825476169586\n",
            "epoch 171 iter 14 loss=0.2750074565410614\n",
            "epoch 171 iter 15 loss=0.26723235845565796\n",
            "epoch 171 iter 16 loss=0.2025170922279358\n",
            "epoch 171 iter 17 loss=0.25929972529411316\n",
            "epoch 171 iter 18 loss=0.31462571024894714\n",
            "epoch 171 iter 19 loss=0.20567284524440765\n",
            "epoch 171 iter 20 loss=0.2507709562778473\n",
            "epoch 171 iter 21 loss=0.26603734493255615\n",
            "epoch 171 iter 22 loss=0.21002626419067383\n",
            "epoch 171 iter 23 loss=0.2785343825817108\n",
            "epoch 171 iter 24 loss=0.22691719233989716\n",
            "epoch 171 iter 25 loss=0.2100098580121994\n",
            "epoch 171 iter 26 loss=0.19289542734622955\n",
            "epoch 171 iter 27 loss=0.22697396576404572\n",
            "epoch 171 iter 28 loss=0.24289505183696747\n",
            "epoch 171 iter 29 loss=0.25977542996406555\n",
            "epoch 171 iter 30 loss=0.21417857706546783\n",
            "epoch 171 iter 31 loss=0.25293049216270447\n",
            "epoch 171 iter 32 loss=0.24623894691467285\n",
            "epoch 171 iter 33 loss=0.2041001170873642\n",
            "epoch 171 iter 34 loss=0.26992589235305786\n",
            "epoch 171 iter 35 loss=0.23199103772640228\n",
            "epoch 171 iter 36 loss=0.1838042438030243\n",
            "epoch 171 iter 37 loss=0.1979038268327713\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2826.\n",
            "epoch 172 iter 0 loss=0.2267301380634308\n",
            "epoch 172 iter 1 loss=0.14859920740127563\n",
            "epoch 172 iter 2 loss=0.19176796078681946\n",
            "epoch 172 iter 3 loss=0.1944151222705841\n",
            "epoch 172 iter 4 loss=0.24971270561218262\n",
            "epoch 172 iter 5 loss=0.2661927044391632\n",
            "epoch 172 iter 6 loss=0.2668688893318176\n",
            "epoch 172 iter 7 loss=0.21743641793727875\n",
            "epoch 172 iter 8 loss=0.21652045845985413\n",
            "epoch 172 iter 9 loss=0.23711352050304413\n",
            "epoch 172 iter 10 loss=0.2092979997396469\n",
            "epoch 172 iter 11 loss=0.2204817831516266\n",
            "epoch 172 iter 12 loss=0.23790901899337769\n",
            "epoch 172 iter 13 loss=0.2590179741382599\n",
            "epoch 172 iter 14 loss=0.18040108680725098\n",
            "epoch 172 iter 15 loss=0.25588709115982056\n",
            "epoch 172 iter 16 loss=0.24887987971305847\n",
            "epoch 172 iter 17 loss=0.18941949307918549\n",
            "epoch 172 iter 18 loss=0.2522629499435425\n",
            "epoch 172 iter 19 loss=0.2343667447566986\n",
            "epoch 172 iter 20 loss=0.23700176179409027\n",
            "epoch 172 iter 21 loss=0.24551911652088165\n",
            "epoch 172 iter 22 loss=0.27343425154685974\n",
            "epoch 172 iter 23 loss=0.18622763454914093\n",
            "epoch 172 iter 24 loss=0.3035131096839905\n",
            "epoch 172 iter 25 loss=0.273185670375824\n",
            "epoch 172 iter 26 loss=0.196458101272583\n",
            "epoch 172 iter 27 loss=0.2220166176557541\n",
            "epoch 172 iter 28 loss=0.2054625153541565\n",
            "epoch 172 iter 29 loss=0.28083547949790955\n",
            "epoch 172 iter 30 loss=0.21850834786891937\n",
            "epoch 172 iter 31 loss=0.22739757597446442\n",
            "epoch 172 iter 32 loss=0.22979003190994263\n",
            "epoch 172 iter 33 loss=0.211361825466156\n",
            "epoch 172 iter 34 loss=0.20274047553539276\n",
            "epoch 172 iter 35 loss=0.2397994101047516\n",
            "epoch 172 iter 36 loss=0.23189696669578552\n",
            "epoch 172 iter 37 loss=0.31592777371406555\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2747.\n",
            "epoch 173 iter 0 loss=0.22707556188106537\n",
            "epoch 173 iter 1 loss=0.2645338475704193\n",
            "epoch 173 iter 2 loss=0.23335781693458557\n",
            "epoch 173 iter 3 loss=0.22810794413089752\n",
            "epoch 173 iter 4 loss=0.19357624650001526\n",
            "epoch 173 iter 5 loss=0.24657736718654633\n",
            "epoch 173 iter 6 loss=0.25201478600502014\n",
            "epoch 173 iter 7 loss=0.2379259616136551\n",
            "epoch 173 iter 8 loss=0.1949504315853119\n",
            "epoch 173 iter 9 loss=0.20655278861522675\n",
            "epoch 173 iter 10 loss=0.22383971512317657\n",
            "epoch 173 iter 11 loss=0.23563526570796967\n",
            "epoch 173 iter 12 loss=0.19176210463047028\n",
            "epoch 173 iter 13 loss=0.2190919667482376\n",
            "epoch 173 iter 14 loss=0.21435590088367462\n",
            "epoch 173 iter 15 loss=0.21543844044208527\n",
            "epoch 173 iter 16 loss=0.25365862250328064\n",
            "epoch 173 iter 17 loss=0.2790065109729767\n",
            "epoch 173 iter 18 loss=0.24364647269248962\n",
            "epoch 173 iter 19 loss=0.2070445865392685\n",
            "epoch 173 iter 20 loss=0.20515213906764984\n",
            "epoch 173 iter 21 loss=0.18364092707633972\n",
            "epoch 173 iter 22 loss=0.21145838499069214\n",
            "epoch 173 iter 23 loss=0.21084493398666382\n",
            "epoch 173 iter 24 loss=0.2269243448972702\n",
            "epoch 173 iter 25 loss=0.19992966949939728\n",
            "epoch 173 iter 26 loss=0.24110306799411774\n",
            "epoch 173 iter 27 loss=0.17902742326259613\n",
            "epoch 173 iter 28 loss=0.25162723660469055\n",
            "epoch 173 iter 29 loss=0.217719167470932\n",
            "epoch 173 iter 30 loss=0.1689973622560501\n",
            "epoch 173 iter 31 loss=0.21285393834114075\n",
            "epoch 173 iter 32 loss=0.14230024814605713\n",
            "epoch 173 iter 33 loss=0.18255966901779175\n",
            "epoch 173 iter 34 loss=0.21895037591457367\n",
            "epoch 173 iter 35 loss=0.18907929956912994\n",
            "epoch 173 iter 36 loss=0.19110895693302155\n",
            "epoch 173 iter 37 loss=0.20639880001544952\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2782.\n",
            "epoch 174 iter 0 loss=0.23867647349834442\n",
            "epoch 174 iter 1 loss=0.21593773365020752\n",
            "epoch 174 iter 2 loss=0.20328696072101593\n",
            "epoch 174 iter 3 loss=0.2404947131872177\n",
            "epoch 174 iter 4 loss=0.2239234745502472\n",
            "epoch 174 iter 5 loss=0.22354136407375336\n",
            "epoch 174 iter 6 loss=0.16037209331989288\n",
            "epoch 174 iter 7 loss=0.18658703565597534\n",
            "epoch 174 iter 8 loss=0.24798239767551422\n",
            "epoch 174 iter 9 loss=0.17347189784049988\n",
            "epoch 174 iter 10 loss=0.2106654793024063\n",
            "epoch 174 iter 11 loss=0.17460940778255463\n",
            "epoch 174 iter 12 loss=0.18484210968017578\n",
            "epoch 174 iter 13 loss=0.19215801358222961\n",
            "epoch 174 iter 14 loss=0.2335232049226761\n",
            "epoch 174 iter 15 loss=0.1558791995048523\n",
            "epoch 174 iter 16 loss=0.16619758307933807\n",
            "epoch 174 iter 17 loss=0.1951858103275299\n",
            "epoch 174 iter 18 loss=0.2116909921169281\n",
            "epoch 174 iter 19 loss=0.25361067056655884\n",
            "epoch 174 iter 20 loss=0.23989363014698029\n",
            "epoch 174 iter 21 loss=0.20838944613933563\n",
            "epoch 174 iter 22 loss=0.2666302025318146\n",
            "epoch 174 iter 23 loss=0.2265782207250595\n",
            "epoch 174 iter 24 loss=0.18989263474941254\n",
            "epoch 174 iter 25 loss=0.2024233639240265\n",
            "epoch 174 iter 26 loss=0.2565074563026428\n",
            "epoch 174 iter 27 loss=0.23123221099376678\n",
            "epoch 174 iter 28 loss=0.20676454901695251\n",
            "epoch 174 iter 29 loss=0.19827678799629211\n",
            "epoch 174 iter 30 loss=0.1701219379901886\n",
            "epoch 174 iter 31 loss=0.20502209663391113\n",
            "epoch 174 iter 32 loss=0.19087499380111694\n",
            "epoch 174 iter 33 loss=0.18517769873142242\n",
            "epoch 174 iter 34 loss=0.18438643217086792\n",
            "epoch 174 iter 35 loss=0.21246856451034546\n",
            "epoch 174 iter 36 loss=0.2003277838230133\n",
            "epoch 174 iter 37 loss=0.15086022019386292\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2814.\n",
            "epoch 175 iter 0 loss=0.23693934082984924\n",
            "epoch 175 iter 1 loss=0.1906413733959198\n",
            "epoch 175 iter 2 loss=0.1752244085073471\n",
            "epoch 175 iter 3 loss=0.1884627342224121\n",
            "epoch 175 iter 4 loss=0.2236253023147583\n",
            "epoch 175 iter 5 loss=0.1656150221824646\n",
            "epoch 175 iter 6 loss=0.2553962767124176\n",
            "epoch 175 iter 7 loss=0.23380276560783386\n",
            "epoch 175 iter 8 loss=0.20021848380565643\n",
            "epoch 175 iter 9 loss=0.18323703110218048\n",
            "epoch 175 iter 10 loss=0.20096462965011597\n",
            "epoch 175 iter 11 loss=0.22404390573501587\n",
            "epoch 175 iter 12 loss=0.19837212562561035\n",
            "epoch 175 iter 13 loss=0.20264121890068054\n",
            "epoch 175 iter 14 loss=0.2138429880142212\n",
            "epoch 175 iter 15 loss=0.1894397735595703\n",
            "epoch 175 iter 16 loss=0.1729239672422409\n",
            "epoch 175 iter 17 loss=0.17587468028068542\n",
            "epoch 175 iter 18 loss=0.1957065761089325\n",
            "epoch 175 iter 19 loss=0.22238965332508087\n",
            "epoch 175 iter 20 loss=0.1616196185350418\n",
            "epoch 175 iter 21 loss=0.20012256503105164\n",
            "epoch 175 iter 22 loss=0.1912418007850647\n",
            "epoch 175 iter 23 loss=0.22557035088539124\n",
            "epoch 175 iter 24 loss=0.16314443945884705\n",
            "epoch 175 iter 25 loss=0.25234103202819824\n",
            "epoch 175 iter 26 loss=0.15320728719234467\n",
            "epoch 175 iter 27 loss=0.20222634077072144\n",
            "epoch 175 iter 28 loss=0.185627281665802\n",
            "epoch 175 iter 29 loss=0.2373419553041458\n",
            "epoch 175 iter 30 loss=0.21119488775730133\n",
            "epoch 175 iter 31 loss=0.23471537232398987\n",
            "epoch 175 iter 32 loss=0.20487351715564728\n",
            "epoch 175 iter 33 loss=0.224449023604393\n",
            "epoch 175 iter 34 loss=0.23213420808315277\n",
            "epoch 175 iter 35 loss=0.20755067467689514\n",
            "epoch 175 iter 36 loss=0.22878658771514893\n",
            "epoch 175 iter 37 loss=0.19510780274868011\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2778.\n",
            "epoch 176 iter 0 loss=0.16708506643772125\n",
            "epoch 176 iter 1 loss=0.2002442181110382\n",
            "epoch 176 iter 2 loss=0.16669079661369324\n",
            "epoch 176 iter 3 loss=0.15314503014087677\n",
            "epoch 176 iter 4 loss=0.17747440934181213\n",
            "epoch 176 iter 5 loss=0.25704917311668396\n",
            "epoch 176 iter 6 loss=0.19529135525226593\n",
            "epoch 176 iter 7 loss=0.21048596501350403\n",
            "epoch 176 iter 8 loss=0.19894441962242126\n",
            "epoch 176 iter 9 loss=0.21068906784057617\n",
            "epoch 176 iter 10 loss=0.2071664035320282\n",
            "epoch 176 iter 11 loss=0.22660453617572784\n",
            "epoch 176 iter 12 loss=0.19046147167682648\n",
            "epoch 176 iter 13 loss=0.1623189002275467\n",
            "epoch 176 iter 14 loss=0.19264085590839386\n",
            "epoch 176 iter 15 loss=0.22196722030639648\n",
            "epoch 176 iter 16 loss=0.23639610409736633\n",
            "epoch 176 iter 17 loss=0.2069029062986374\n",
            "epoch 176 iter 18 loss=0.2525444030761719\n",
            "epoch 176 iter 19 loss=0.21006625890731812\n",
            "epoch 176 iter 20 loss=0.19315356016159058\n",
            "epoch 176 iter 21 loss=0.20788104832172394\n",
            "epoch 176 iter 22 loss=0.1983787715435028\n",
            "epoch 176 iter 23 loss=0.16644102334976196\n",
            "epoch 176 iter 24 loss=0.20103994011878967\n",
            "epoch 176 iter 25 loss=0.20251834392547607\n",
            "epoch 176 iter 26 loss=0.25664207339286804\n",
            "epoch 176 iter 27 loss=0.20149387419223785\n",
            "epoch 176 iter 28 loss=0.1870317906141281\n",
            "epoch 176 iter 29 loss=0.19339197874069214\n",
            "epoch 176 iter 30 loss=0.2580289840698242\n",
            "epoch 176 iter 31 loss=0.1870097517967224\n",
            "epoch 176 iter 32 loss=0.19633349776268005\n",
            "epoch 176 iter 33 loss=0.19787302613258362\n",
            "epoch 176 iter 34 loss=0.2245682328939438\n",
            "epoch 176 iter 35 loss=0.19856710731983185\n",
            "epoch 176 iter 36 loss=0.19447116553783417\n",
            "epoch 176 iter 37 loss=0.22842320799827576\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2804.\n",
            "epoch 177 iter 0 loss=0.1768849641084671\n",
            "epoch 177 iter 1 loss=0.2319057583808899\n",
            "epoch 177 iter 2 loss=0.18378612399101257\n",
            "epoch 177 iter 3 loss=0.21235381066799164\n",
            "epoch 177 iter 4 loss=0.2155006378889084\n",
            "epoch 177 iter 5 loss=0.22291535139083862\n",
            "epoch 177 iter 6 loss=0.18154770135879517\n",
            "epoch 177 iter 7 loss=0.17578865587711334\n",
            "epoch 177 iter 8 loss=0.18786630034446716\n",
            "epoch 177 iter 9 loss=0.20206044614315033\n",
            "epoch 177 iter 10 loss=0.24248164892196655\n",
            "epoch 177 iter 11 loss=0.26017045974731445\n",
            "epoch 177 iter 12 loss=0.2471805214881897\n",
            "epoch 177 iter 13 loss=0.2137586623430252\n",
            "epoch 177 iter 14 loss=0.20852185785770416\n",
            "epoch 177 iter 15 loss=0.19549797475337982\n",
            "epoch 177 iter 16 loss=0.1956646740436554\n",
            "epoch 177 iter 17 loss=0.22483976185321808\n",
            "epoch 177 iter 18 loss=0.15463250875473022\n",
            "epoch 177 iter 19 loss=0.2143602967262268\n",
            "epoch 177 iter 20 loss=0.23248423635959625\n",
            "epoch 177 iter 21 loss=0.18617647886276245\n",
            "epoch 177 iter 22 loss=0.18491463363170624\n",
            "epoch 177 iter 23 loss=0.1663716584444046\n",
            "epoch 177 iter 24 loss=0.17828962206840515\n",
            "epoch 177 iter 25 loss=0.18956075608730316\n",
            "epoch 177 iter 26 loss=0.19186623394489288\n",
            "epoch 177 iter 27 loss=0.2055651843547821\n",
            "epoch 177 iter 28 loss=0.23501849174499512\n",
            "epoch 177 iter 29 loss=0.18579351902008057\n",
            "epoch 177 iter 30 loss=0.17572255432605743\n",
            "epoch 177 iter 31 loss=0.19364289939403534\n",
            "epoch 177 iter 32 loss=0.22558735311031342\n",
            "epoch 177 iter 33 loss=0.22801177203655243\n",
            "epoch 177 iter 34 loss=0.20257343351840973\n",
            "epoch 177 iter 35 loss=0.16977989673614502\n",
            "epoch 177 iter 36 loss=0.18962684273719788\n",
            "epoch 177 iter 37 loss=0.15464870631694794\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2810.\n",
            "epoch 178 iter 0 loss=0.17730167508125305\n",
            "epoch 178 iter 1 loss=0.15251034498214722\n",
            "epoch 178 iter 2 loss=0.21373321115970612\n",
            "epoch 178 iter 3 loss=0.19895413517951965\n",
            "epoch 178 iter 4 loss=0.23246029019355774\n",
            "epoch 178 iter 5 loss=0.19957706332206726\n",
            "epoch 178 iter 6 loss=0.17895463109016418\n",
            "epoch 178 iter 7 loss=0.22192402184009552\n",
            "epoch 178 iter 8 loss=0.20411048829555511\n",
            "epoch 178 iter 9 loss=0.17683692276477814\n",
            "epoch 178 iter 10 loss=0.19749248027801514\n",
            "epoch 178 iter 11 loss=0.20559027791023254\n",
            "epoch 178 iter 12 loss=0.18408982455730438\n",
            "epoch 178 iter 13 loss=0.20960693061351776\n",
            "epoch 178 iter 14 loss=0.2280844897031784\n",
            "epoch 178 iter 15 loss=0.16400495171546936\n",
            "epoch 178 iter 16 loss=0.17950230836868286\n",
            "epoch 178 iter 17 loss=0.19585490226745605\n",
            "epoch 178 iter 18 loss=0.13174796104431152\n",
            "epoch 178 iter 19 loss=0.19955214858055115\n",
            "epoch 178 iter 20 loss=0.2346276491880417\n",
            "epoch 178 iter 21 loss=0.23791348934173584\n",
            "epoch 178 iter 22 loss=0.1653929054737091\n",
            "epoch 178 iter 23 loss=0.18461823463439941\n",
            "epoch 178 iter 24 loss=0.1987123340368271\n",
            "epoch 178 iter 25 loss=0.20450691878795624\n",
            "epoch 178 iter 26 loss=0.19954955577850342\n",
            "epoch 178 iter 27 loss=0.18923768401145935\n",
            "epoch 178 iter 28 loss=0.2042119950056076\n",
            "epoch 178 iter 29 loss=0.24855606257915497\n",
            "epoch 178 iter 30 loss=0.20590713620185852\n",
            "epoch 178 iter 31 loss=0.2378395050764084\n",
            "epoch 178 iter 32 loss=0.2078571915626526\n",
            "epoch 178 iter 33 loss=0.23384195566177368\n",
            "epoch 178 iter 34 loss=0.20736734569072723\n",
            "epoch 178 iter 35 loss=0.20419970154762268\n",
            "epoch 178 iter 36 loss=0.2543809413909912\n",
            "epoch 178 iter 37 loss=0.15899153053760529\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2784.\n",
            "epoch 179 iter 0 loss=0.22035056352615356\n",
            "epoch 179 iter 1 loss=0.17536340653896332\n",
            "epoch 179 iter 2 loss=0.1806672066450119\n",
            "epoch 179 iter 3 loss=0.2479228675365448\n",
            "epoch 179 iter 4 loss=0.22405417263507843\n",
            "epoch 179 iter 5 loss=0.22394916415214539\n",
            "epoch 179 iter 6 loss=0.18185921013355255\n",
            "epoch 179 iter 7 loss=0.22391723096370697\n",
            "epoch 179 iter 8 loss=0.17386476695537567\n",
            "epoch 179 iter 9 loss=0.19354434311389923\n",
            "epoch 179 iter 10 loss=0.1822107881307602\n",
            "epoch 179 iter 11 loss=0.205325648188591\n",
            "epoch 179 iter 12 loss=0.20189234614372253\n",
            "epoch 179 iter 13 loss=0.22314265370368958\n",
            "epoch 179 iter 14 loss=0.19076672196388245\n",
            "epoch 179 iter 15 loss=0.17298604547977448\n",
            "epoch 179 iter 16 loss=0.1555512696504593\n",
            "epoch 179 iter 17 loss=0.17643925547599792\n",
            "epoch 179 iter 18 loss=0.19136521220207214\n",
            "epoch 179 iter 19 loss=0.19357343018054962\n",
            "epoch 179 iter 20 loss=0.21225322782993317\n",
            "epoch 179 iter 21 loss=0.20126569271087646\n",
            "epoch 179 iter 22 loss=0.17559219896793365\n",
            "epoch 179 iter 23 loss=0.25134146213531494\n",
            "epoch 179 iter 24 loss=0.20693495869636536\n",
            "epoch 179 iter 25 loss=0.17215277254581451\n",
            "epoch 179 iter 26 loss=0.1886904388666153\n",
            "epoch 179 iter 27 loss=0.22116582095623016\n",
            "epoch 179 iter 28 loss=0.20206108689308167\n",
            "epoch 179 iter 29 loss=0.18186107277870178\n",
            "epoch 179 iter 30 loss=0.206918403506279\n",
            "epoch 179 iter 31 loss=0.20896565914154053\n",
            "epoch 179 iter 32 loss=0.1944734901189804\n",
            "epoch 179 iter 33 loss=0.21333466470241547\n",
            "epoch 179 iter 34 loss=0.19600225985050201\n",
            "epoch 179 iter 35 loss=0.17666707932949066\n",
            "epoch 179 iter 36 loss=0.16342705488204956\n",
            "epoch 179 iter 37 loss=0.26136910915374756\n",
            "Begin testing\n",
            "Eval result: mIoU 0.2786.\n",
            "The final mIoU is : 0.2828.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A prediction example by using the baseline:\n",
        "\n",
        "![test2.jpg](data:image/jpeg;base64,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)![test1.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "rnJBjS-Hli40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. FLOPs"
      ],
      "metadata": {
        "id": "9FlshC7yryJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  #The code from https://cloudstor.aarnet.edu.au/plus/s/PcSc67ZncTSQP0E can be used to count flops\n",
        "  #Download the code.\n",
        "  !wget -c https://cloudstor.aarnet.edu.au/plus/s/hXo1dK9SZqiEVn9/download\n",
        "  !mv download FLOPs_counter.py"
      ],
      "metadata": {
        "id": "C_D3Xsvu467x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   from FLOPs_counter import print_model_parm_flops\n",
        "   input = torch.randn(1, 3, 375, 1242) # Modifying the size (3, 375, 1242) is ***NOT*** allowed. \n",
        "\n",
        "   #Get the network and its FLOPs\n",
        "   model = SegNetwork(n_class=19)\n",
        "   print_model_parm_flops(model, input, detail=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5fUBat44-hT",
        "outputId": "8e914f13-738c-4a26-b7d7-b05c4eeb4681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " + Number of FLOPs: 132.85G\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Segmentation",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}